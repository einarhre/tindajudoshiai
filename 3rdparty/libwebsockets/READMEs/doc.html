<h2>Libwebsockets API introduction</h2>

<p>Libwebsockets covers a lot of interesting features for people making embedded servers or clients</p>

<ul>
<li>HTTP(S) serving and client operation</li>
<li>HTTP/2 support for serving and client operation</li>
<li>WS(S) serving and client operation</li>
<li>HTTP(S) apis for file transfer and upload</li>
<li>HTTP 1 + 2 POST form handling (including multipart / file upload)</li>
<li>cookie-based sessions</li>
<li>account management (including registration, email verification, lost pw etc)</li>
<li>strong SSL / TLS  PFS support (A+ on SSLlabs test)</li>
<li>ssh server integration</li>
<li>serving gzipped files directly from inside zip files, without conversion</li>
<li>support for linux, bsd, windows etc... and very small nonlinux targets like ESP32</li>
</ul>

<p>Please note you just need in include libwebsockets.h.  It includes all the individual
includes in /usr/include/libwebsockets/ itself.</p>

<p>You can browse by api category <a href="modules.html">here</a></p>

<p>A collection of READMEs for build, coding, lwsws etc are <a href="pages.html">here</a></p>

<h1>Notes about building lws</h1>

<p>@section cm Introduction to CMake</p>

<p>CMake is a multi-platform build tool that can generate build files for many
different target platforms. See more info at http://www.cmake.org</p>

<p>CMake also allows/recommends you to do "out of source"-builds, that is,
the build files are separated from your sources, so there is no need to
create elaborate clean scripts to get a clean source tree, instead you
simply remove your build directory.</p>

<p>Libwebsockets has been tested to build successfully on the following platforms
with SSL support (for OpenSSL/wolfSSL/BoringSSL):</p>

<ul>
<li>Windows (Visual Studio)</li>
<li>Windows (MinGW)</li>
<li>Linux (x86 and ARM)</li>
<li>OSX</li>
<li>NetBSD</li>
</ul>

<p>@section build1 Building the library and test apps</p>

<p>The project settings used by CMake to generate the platform specific build
files is called <a href="../CMakeLists.txt">CMakeLists.txt</a>. CMake then uses one of its "Generators" to
output a Visual Studio project or Make file for instance. To see a list of
the available generators for your platform, simply run the "cmake" command.</p>

<p>Note that by default OpenSSL will be linked, if you don't want SSL support
see below on how to toggle compile options.</p>

<p>@section bu Building on Unix:</p>

<ol>
<li><p>Install CMake 2.8 or greater: http://cmake.org/cmake/resources/software.html
(Most Unix distributions comes with a packaged version also)</p></li>
<li><p>Install OpenSSL.</p></li>
<li><p>Generate the build files (default is Make files):
<code>
    $ cd /path/to/src
    $ mkdir build
    $ cd build
    $ cmake ..
</code></p></li>
<li><p>Finally you can build using the generated Makefile:
<code>
$ make &amp;&amp; sudo make install
</code>
<strong>NOTE</strong>: The <code>build/`` directory can have any name and be located anywhere
on your filesystem, and that the argument</code>..` given to cmake is simply
the source directory of <strong>libwebsockets</strong> containing the <a href="../CMakeLists.txt">CMakeLists.txt</a>
project file. All examples in this file assumes you use ".."</p></li>
</ol>

<p><strong>NOTE2</strong>:
A common option you may want to give is to set the install path, same
as --prefix= with autotools.  It defaults to /usr/local.
You can do this by, eg
<code>
    $ cmake -DCMAKE_INSTALL_PREFIX:PATH=/usr .
</code></p>

<p><strong>NOTE3</strong>:
On machines that want libraries in lib64, you can also add the
following to the cmake line
<code>
    -DLIB_SUFFIX=64
</code></p>

<p><strong>NOTE4</strong>:
If you are building against a non-distro OpenSSL (eg, in order to get
access to ALPN support only in newer OpenSSL versions) the nice way to
express that in one cmake command is eg,
<code>
    $ cmake .. -DOPENSSL_ROOT_DIR=/usr/local/ssl \
         -DCMAKE_INCLUDE_DIRECTORIES_PROJECT_BEFORE=/usr/local/ssl \
         -DLWS_WITH_HTTP2=1
</code></p>

<p>When you run the test apps using non-distro SSL, you have to force them
to use your libs, not the distro ones
<code>
    $ LD_LIBRARY_PATH=/usr/local/ssl/lib libwebsockets-test-server --ssl
</code></p>

<p>To get it to build on latest openssl (2016-04-10) it needed this approach
<code>
    cmake .. -DLWS_WITH_HTTP2=1 -DLWS_OPENSSL_INCLUDE_DIRS=/usr/local/include/openssl -DLWS_OPENSSL_LIBRARIES="/usr/local/lib64/libssl.so;/usr/local/lib64/libcrypto.so"
</code></p>

<p>Mac users have reported</p>

<p><code>
 $ export OPENSSL_ROOT_DIR=/usr/local/Cellar/openssl/1.0.2k; cmake ..; make -j4
</code></p>

<p>worked for them when using "homebrew" OpenSSL</p>

<p><strong>NOTE5</strong>:
To build with debug info and _DEBUG for lower priority debug messages
compiled in, use
<code>
    $ cmake .. -DCMAKE_BUILD_TYPE=DEBUG
</code></p>

<p><strong>NOTE6</strong>
To build on Solaris the linker needs to be informed to use lib socket
and libnsl, and only builds in 64bit mode.</p>

<p><code>bash
    $ cmake .. -DCMAKE_C_FLAGS=-m64 -DCMAKE_EXE_LINKER_FLAGS="-lsocket -lnsl"
</code></p>

<p><strong>NOTE7</strong></p>

<p>Build and test flow against boringssl.  Notice <code>LWS_WITH_GENHASH</code> is currently
unavailable with boringssl due to their removing the necessary apis.</p>

<p>Build current HEAD boringssl</p>

<p><code>
 $ cd /projects
 $ git clone https://boringssl.googlesource.com/boringssl
 $ cd boringssl
 $ mkdir build
 $ cd build
 $ cmake ..  -DBUILD_SHARED_LIBS=1
 $ make -j8
</code></p>

<p>Build and test lws against it</p>

<p><code>
 $ cd /projects/libwebsockets/build
 $ cmake .. -DOPENSSL_LIBRARIES="/projects/boringssl/build/ssl/libssl.so;\
   /projects/boringssl/build/crypto/libcrypto.so" \
   -DOPENSSL_INCLUDE_DIRS=/projects/boringssl/include \
   -DLWS_WITH_BORINGSSL=1 -DCMAKE_BUILD_TYPE=DEBUG
 $ make -j8 &amp;&amp; sudo make install
 $ LD_PRELOAD="/projects/boringssl/build/ssl/libssl.so \
   /projects/boringssl/build/crypto/libcrypto.so" \
   /usr/local/bin/libwebsockets-test-server -s
</code></p>

<ol>
<li>Finally you can build using the generated Makefile:</li>
</ol>

<p><code>bash
    $ make
</code></p>

<p>@section lcap Linux Capabilities</p>

<p>On Linux, lws now lets you retain selected root capabilities when dropping
privileges.  If libcap-dev or similar package is installed providing
sys/capabilities.h, and libcap or similar package is installed providing
libcap.so, CMake will enable the capability features.</p>

<p>The context creation info struct .caps[] and .count_caps members can then
be set by user code to enable selected root capabilities to survive the
transition to running under an unprivileged user.</p>

<p>@section cmq Quirk of cmake</p>

<p>When changing cmake options, for some reason the only way to get it to see the
changes sometimes is delete the contents of your build directory and do the
cmake from scratch.</p>

<p>deleting build/CMakeCache.txt may be enough.</p>

<p>@section cmw Building on Windows (Visual Studio)</p>

<ol>
<li><p>Install CMake 2.6 or greater: http://cmake.org/cmake/resources/software.html</p></li>
<li><p>Install OpenSSL binaries. https://wiki.openssl.org/index.php/Binaries</p>

<p>(<strong>NOTE</strong>: Preferably in the default location to make it easier for CMake to find them)</p>

<p><strong>NOTE2</strong>: 
Be sure that OPENSSL_CONF environment variable is defined and points at 
<OpenSSL install location>\bin\openssl.cfg</p></li>
<li><p>Generate the Visual studio project by opening the Visual Studio cmd prompt:</p></li>
</ol>

<p><code>
    cd &lt;path to src&gt;
    md build
    cd build
    cmake -G "Visual Studio 10" ..
</code></p>

<p>(<strong>NOTE</strong>: There is also a cmake-gui available on Windows if you prefer that)</p>

<p><strong>NOTE2</strong>:
   See this link to find out the version number corresponding to your Visual Studio edition:
   http://superuser.com/a/194065</p>

<ol>
<li><p>Now you should have a generated Visual Studio Solution in  your
<code>&lt;path to src&gt;/build</code> directory, which can be used to build.</p></li>
<li><p>Some additional deps may be needed</p>

<ul>
<li>iphlpapi.lib</li>
<li>psapi.lib</li>
<li>userenv.lib</li>
</ul></li>
<li><p>If you're using libuv, you must make sure to compile libuv with the same multithread-dll / Mtd attributes as libwebsockets itself</p></li>
</ol>

<p>@section cmwmgw Building on Windows (MinGW)</p>

<ol>
<li><p>Install MinGW</p>

<p>For Fedora, it's, eg, <code>dnf install mingw64-gcc</code></p></li>
<li><p>Install current CMake package</p>

<p>For Fedora, it's <code>dnf install cmake</code></p></li>
<li><p>Instal mingw-built OpenSSL pieces</p>

<p>For Fedora, it's <code>mingw64-openssl.noarch mingw64-openssl-static.noarch</code></p>

<p>mingw64-cmake as described below will auto-find the libs and includes
for build.  But to execute the apps, they either need to go into the same
<code>/usr/x86_64-w64-mingw32/sys-root/mingw/bin/</code> as the dlls are installed to,
or the dlls have to be copied into the same dir as your app executable.</p></li>
<li><p>Generate the build files (default is Make files) using MSYS shell.</p>

<p>For Fedora, they provide a <code>mingw64-cmake</code> wrapper in the package
<code>mingw64-filesystem</code>, with this you can run that instead of cmake directly
and don't have to get involved with setting the cmake generator.</p>

<p>Otherwise doing it by hand is like this:</p></li>
</ol>

<p><code>
    $ cd /drive/path/to/src
    $ mkdir build
    $ cd build
    $ cmake -G "MSYS Makefiles" -DCMAKE_INSTALL_PREFIX=C:/MinGW ..
</code></p>

<p>To generate build files allowing to create libwebsockets binaries with debug information
   set the CMAKE<em>BUILD</em>TYPE flag to DEBUG:
<code>
    $ cmake -G "MSYS Makefiles" -DCMAKE_INSTALL_PREFIX=C:/MinGW -DCMAKE_BUILD_TYPE=DEBUG ..
</code>
5. Finally you can build using the generated Makefile and get the results deployed into your MinGW installation:</p>

<p><code>
    $ make &amp;&amp; make install
</code></p>

<p>@section distro Selecting CMake options useful for distros</p>

<p>Distro packagers should select the CMake option "LWS<em>WITH</em>DISTRO_RECOMMENDED",
which selects common additional options like support for various event libraries,
plugins and lwsws.</p>

<p>@section ssllib Choosing Your TLS Poison</p>

<ul>
<li><p>If you are really restricted on memory, code size, or don't care about TLS
speed, mbedTLS is a good choice: <code>cmake .. -DLWS_WITH_MBEDTLS=1</code></p></li>
<li><p>If cpu and memory is not super restricted and you care about TLS speed,
OpenSSL or a directly compatible variant like Boring SSL is a good choice.</p></li>
</ul>

<p>Just building lws against stock Fedora OpenSSL or stock Fedora mbedTLS, for
SSL handhake mbedTLS takes ~36ms and OpenSSL takes ~1ms on the same x86<em>64
build machine here, with everything else the same.  Over the 144 connections of
h2spec compliance testing for example, this ends up completing in 400ms for
OpenSSL and 5.5sec for mbedTLS on x86</em>64.  In other words mbedTLS is very slow
compared to OpenSSL under the (fairly typical) conditions I tested it.</p>

<p>This isn't an inefficiency in the mbedtls interface implementation, it's just
mbedTLS doing the crypto much slower than OpenSSL, which has accelerated
versions of common crypto operations it automatically uses for platforms
supporting it.  As of Oct 2017 mbedTLS itself has no such optimizations for any
platform that I could find.  It's just pure C running on the CPU.</p>

<p>Lws supports both almost the same, so instead of taking my word for it you are
invited to try it both ways and see which the results (including, eg, binary
size and memory usage as well as speed) suggest you use.</p>

<p>NOTE: one major difference with mbedTLS is it does not load the system trust
store by default.  That has advantages and disadvantages, but the disadvantage
is you must provide the CA cert to lws built against mbedTLS for it to be able
to validate it, ie, use -A with the test client.  The minimal test clients
have the CA cert for warmcat.com and libwebsockets.org and use it if they see
they were built with mbedTLS.</p>

<p>@section optee Building for OP-TEE</p>

<p>OP-TEE is a "Secure World" Trusted Execution Environment.</p>

<p>Although lws is only part of the necessary picture to have an https-enabled
TA, it does support OP-TEE as a platform and if you provide the other
pieces, does work very well.</p>

<p>Select it in cmake with <code>-DLWS_PLAT_OPTEE=1</code></p>

<p>@section cmco Setting compile options</p>

<p>To set compile time flags you can either use one of the CMake gui applications
or do it via the command line.</p>

<p>@subsection cmcocl Command line</p>

<p>To list available options (omit the H if you don't want the help text):</p>

<pre><code>cmake -LH ..
</code></pre>

<p>Then to set an option and build (for example turn off SSL support):</p>

<pre><code>cmake -DLWS_WITH_SSL=0 ..
</code></pre>

<p>or
    cmake -DLWS<em>WITH</em>SSL:BOOL=OFF ..</p>

<p>@subsection cmcoug Unix GUI</p>

<p>If you have a curses-enabled build you simply type:
(not all packages include this, my debian install does not for example).</p>

<pre><code>ccmake
</code></pre>

<p>@subsection cmcowg Windows GUI</p>

<p>On windows CMake comes with a gui application:
    Start -> Programs -> CMake -> CMake (cmake-gui)</p>

<p>@section wolf wolfSSL/CyaSSL replacement for OpenSSL</p>

<p>wolfSSL/CyaSSL is a lightweight SSL library targeted at embedded systems:
https://www.wolfssl.com/wolfSSL/Products-wolfssl.html</p>

<p>It contains a OpenSSL compatibility layer which makes it possible to pretty
much link to it instead of OpenSSL, giving a much smaller footprint.</p>

<p><strong>NOTE</strong>: wolfssl needs to be compiled using the <code>--enable-opensslextra</code> flag for
this to work.</p>

<p>@section wolf1 Compiling libwebsockets with wolfSSL</p>

<p><code>
    cmake .. -DLWS_WITH_WOLFSSL=1 \
         -DLWS_WOLFSSL_INCLUDE_DIRS=/path/to/wolfssl \
         -DLWS_WOLFSSL_LIBRARIES=/path/to/wolfssl/wolfssl.a ..
</code></p>

<p><strong>NOTE</strong>: On windows use the .lib file extension for <code>LWS_WOLFSSL_LIBRARIES</code> instead.</p>

<p>@section cya Compiling libwebsockets with CyaSSL</p>

<p><code>
    cmake .. -DLWS_WITH_CYASSL=1 \
         -DLWS_CYASSL_INCLUDE_DIRS=/path/to/cyassl \
         -DLWS_CYASSL_LIBRARIES=/path/to/wolfssl/cyassl.a ..
</code></p>

<p><strong>NOTE</strong>: On windows use the .lib file extension for <code>LWS_CYASSL_LIBRARIES</code> instead.</p>

<p>@section gzip Selecting GZIP or MINIZ</p>

<p>By default lws supports gzip when compression is needed.  But you can tell it to use
MINIZ instead by using <code>-DLWS_WITH_MINIZ=1</code>.</p>

<p>For native build cmake will try to find an existing libminiz.so or .a and build
against that and the found includes automatically.</p>

<p>For cross-build or building against local miniz, you need the following kind of
cmake to tell it where to get miniz</p>

<p><code>
cmake .. -DLWS_WITH_MINIZ=1 -DLWS_WITH_ZIP_FOPS=1 -DMINIZ_INCLUDE_DIRS="/projects/miniz;/projects/miniz/build" -DMINIZ_LIBRARIES=/projects/miniz/build/libminiz.so.2.1.0
</code></p>

<p>@section esp32 Building for ESP32</p>

<p>Building for ESP32 requires the ESP-IDF framework. It can be built under Linux, OSX or Windows (MSYS2).</p>

<ol>
<li>Install ESP-IDF, follow the getting started guide here - http://esp-idf.readthedocs.io/en/latest/get-started/</li>
<li>Set ESP-IDF to last known working version (assuming ESP-IDF is in <code>~/esp/esp-idf</code>) :
<code>
cd ~/esp/esp-idf
git checkout 0c50b65a34cd6b3954f7435193411a88adb49cb0
git submodule update --recursive
</code></li>
<li>Add <code>libwebsockets</code> as a submodule in the <code>components</code> folder of your ESP-IDF project:
<code>
git submodule add https://github.com/warmcat/libwebsockets.git components/libwebsockets
</code></li>
<li>If on Windows (MSYS2) you will need to install CMake in the MSYS2 environment:
<code>
pacman -S mingw-w64-i686-cmake
</code>
If you're on Linux or OSX ensure CMake version is at least 3.7.</li>
</ol>

<p>@section extplugins Building plugins outside of lws itself</p>

<p>The directory ./plugin-standalone/ shows how easy it is to create plugins
outside of lws itself.  First build lws itself with -DLWS<em>WITH</em>PLUGINS,
then use the same flow to build the standalone plugin
<code>
    cd ./plugin-standalone
    mkdir build
    cd build
    cmake ..
    make &amp;&amp; sudo make install
</code></p>

<p>if you changed the default plugin directory when you built lws, you must
also give the same arguments to cmake here (eg,
<code>-DCMAKE_INSTALL_PREFIX:PATH=/usr/something/else...</code> )</p>

<p>Otherwise if you run lwsws or libwebsockets-test-server-v2.0, it will now
find the additional plugin "libprotocol<em>example</em>standalone.so"
<code>
    lwsts[21257]:   Plugins:
    lwsts[21257]:    libprotocol_dumb_increment.so
    lwsts[21257]:    libprotocol_example_standalone.so
    lwsts[21257]:    libprotocol_lws_mirror.so
    lwsts[21257]:    libprotocol_lws_server_status.so
    lwsts[21257]:    libprotocol_lws_status.so
</code>
If you have multiple vhosts, you must enable plugins at the vhost
additionally, discovered plugins are not enabled automatically for security
reasons.  You do this using info->pvo or for lwsws, in the JSON config.</p>

<p>@section http2rp Reproducing HTTP/2 tests</p>

<p>Enable <code>-DLWS_WITH_HTTP2=1</code> in cmake to build with http/2 support enabled.</p>

<p>You must have built and be running lws against a version of openssl that has
ALPN.  At the time of writing, recent distros have started upgrading to OpenSSL
1.1+ that supports this already.  You'll know it's right by seeing</p>

<p><code>
    lwsts[4752]:  Compiled with OpenSSL support
    lwsts[4752]:  Using SSL mode
    lwsts[4752]:  HTTP2 / ALPN enabled
</code>
at lws startup.</p>

<p>Recent Firefox and Chrome also support HTTP/2 by ALPN, so these should just work
with the test server running in -s / ssl mode.</p>

<p>For testing with nghttp client:</p>

<p><code>
    $ nghttp -nvas https://localhost:7681/test.html
</code></p>

<p>Testing with h2spec (https://github.com/summerwind/h2spec)</p>

<p><code>
        $ h2spec  -h 127.0.0.1 -p 7681 -t -k -v -o 1
</code></p>

<p>```
145 tests, 145 passed, 0 skipped, 0 failed</p>

<p>```</p>

<p>@section coverage Automated Coverage Testing</p>

<p>./test-apps/attack.sh contains scripted tests that are the basis
of the automated test coverage assessment available for gcc and clang.</p>

<p>To reproduce</p>

<p>$ cd build
 $ cmake .. -DLWS<em>WITH</em>GCOV=1 -DCMAKE<em>BUILD</em>TYPE=DEBUG
 $ ../scripts/build-gcov.sh
 $ ../test-apps/attack.sh
 $ ../scripts/gcov.sh
...
Lines executed:51.24% of 8279</p>

<p>@section windowsprebuilt Using Windows binary builds on Appveyor</p>

<p>The CI builds on Appveyor now produce usable binary outputs.  Visit</p>

<p><a href="https://ci.appveyor.com/project/lws-team/libwebsockets">lws on Appveyor</a></p>

<p>and select one of the builds, then click on ARTIFACTS at the top right.  The zip file
want to be unpacked into <code>C:\Program Files (x86)/libwebsockets</code>, after that, you should be able to run the test server, by running it from <code>bin/Release/libwebsockets-test-server.exe</code> and opening a browser on http://127.0.0.1:7681</p>

<p>@section cross Cross compiling</p>

<p>To enable cross-compiling <strong>libwebsockets</strong> using CMake you need to create
a "Toolchain file" that you supply to CMake when generating your build files.
CMake will then use the cross compilers and build paths specified in this file
to look for dependencies and such.</p>

<p><strong>Libwebsockets</strong> includes an example toolchain file <a href="../contrib/cross-arm-linux-gnueabihf.cmake">cross-arm-linux-gnueabihf.cmake</a>
you can use as a starting point.</p>

<p>The commandline to configure for cross with this would look like
<code>
    $ cmake .. -DCMAKE_INSTALL_PREFIX:PATH=/usr/lib/my-cross-root \
         -DCMAKE_TOOLCHAIN_FILE=../contrib/cross-arm-linux-gnueabihf.cmake \
         -DLWS_WITHOUT_EXTENSIONS=1 -DLWS_WITH_SSL=0 \
         -DLWS_WITH_ZIP_FOPS=0 -DLWS_WITH_ZLIB=0
</code>
The example shows how to build with no external cross lib dependencies, you
need to provide the cross libraries otherwise.</p>

<p><strong>NOTE</strong>: start from an EMPTY build directory if you had a non-cross build in there
    before the settings will be cached and your changes ignored.
    Delete <code>build/CMakeCache.txt</code> at least before trying a new cmake config
    to ensure you are really building the options you think you are.</p>

<p>Additional information on cross compilation with CMake:
    http://www.vtk.org/Wiki/CMake<em>Cross</em>Compiling</p>

<p>@section cross_example Complex Cross compiling example</p>

<p>Here are step by step instructions for cross-building the external projects needed for lws with lwsws + mbedtls as an example.</p>

<p>In the example, my toolchain lives in <code>/projects/aist-tb/arm-tc</code> and is named <code>arm-linux-gnueabihf</code>.  So you will need to adapt those to where your toolchain lives and its name where you see them here.</p>

<p>Likewise I do all this in /tmp but it has no special meaning, you can adapt that to somewhere else.</p>

<p>All "foreign" cross-built binaries are sent into <code>/tmp/cross</code> so they cannot be confused for 'native' x86_64 stuff on your host machine in /usr/[local/]....</p>

<h2>Prepare the cmake toolchain file</h2>

<p>1) <code>cd /tmp</code></p>

<p>2) <code>wget -O mytoolchainfile https://raw.githubusercontent.com/warmcat/libwebsockets/master/contrib/cross-arm-linux-gnueabihf.cmake</code> </p>

<p>3) Edit <code>/tmp/mytoolchainfile</code> adapting <code>CROSS_PATH</code>, <code>CMAKE_C_COMPILER</code> and <code>CMAKE_CXX_COMPILER</code> to reflect your toolchain install dir and path to your toolchain C and C++ compilers respectively.  For my case:</p>

<p><code>
set(CROSS_PATH /projects/aist-tb/arm-tc/)
set(CMAKE_C_COMPILER "${CROSS_PATH}/bin/arm-linux-gnueabihf-gcc")
set(CMAKE_CXX_COMPILER "${CROSS_PATH}/bin/arm-linux-gnueabihf-g++")
</code></p>

<h2>1/4: Building libuv cross:</h2>

<p>1) <code>export PATH=/projects/aist-tb/arm-tc/bin:$PATH</code>  Notice there is a <strong>/bin</strong> on the end of the toolchain path</p>

<p>2) <code>cd /tmp ; mkdir cross</code> we will put the cross-built libs in /tmp/cross</p>

<p>3) <code>git clone https://github.com/libuv/libuv.git</code> get libuv</p>

<p>4) <code>cd libuv</code></p>

<p>5) <code>./autogen.sh</code></p>

<p><code>
+ libtoolize --copy
libtoolize: putting auxiliary files in '.'.
libtoolize: copying file './ltmain.sh'
libtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.
libtoolize: copying file 'm4/libtool.m4'
libtoolize: copying file 'm4/ltoptions.m4'
libtoolize: copying file 'm4/ltsugar.m4'
libtoolize: copying file 'm4/ltversion.m4'
libtoolize: copying file 'm4/lt~obsolete.m4'
+ aclocal -I m4
+ autoconf
+ automake --add-missing --copy
configure.ac:38: installing './ar-lib'
configure.ac:25: installing './compile'
configure.ac:22: installing './config.guess'
configure.ac:22: installing './config.sub'
configure.ac:21: installing './install-sh'
configure.ac:21: installing './missing'
Makefile.am: installing './depcomp'
</code>
If it has problems, you will need to install <code>automake</code>, <code>libtool</code> etc.</p>

<p>6) <code>./configure  --host=arm-linux-gnueabihf --prefix=/tmp/cross</code></p>

<p>7) <code>make &amp;&amp; make install</code> this will install to <code>/tmp/cross/...</code></p>

<p>8) <code>file /tmp/cross/lib/libuv.so.1.0.0</code>  Check it's really built for ARM
<code>
/tmp/cross/lib/libuv.so.1.0.0: ELF 32-bit LSB shared object, ARM, EABI5 version 1 (SYSV), dynamically linked, BuildID[sha1]=cdde0bc945e51db6001a9485349c035baaec2b46, with debug_info, not stripped
</code></p>

<h2>2/4: Building zlib cross</h2>

<p>1) <code>cd /tmp</code></p>

<p>2) <code>git clone https://github.com/madler/zlib.git</code></p>

<p>3) <code>CC=arm-linux-gnueabihf-gcc ./configure --prefix=/tmp/cross</code>
<code>
Checking for shared library support...
Building shared library libz.so.1.2.11 with arm-linux-gnueabihf-gcc.
Checking for size_t... Yes.
Checking for off64_t... Yes.
Checking for fseeko... Yes.
Checking for strerror... Yes.
Checking for unistd.h... Yes.
Checking for stdarg.h... Yes.
Checking whether to use vs[n]printf() or s[n]printf()... using vs[n]printf().
Checking for vsnprintf() in stdio.h... Yes.
Checking for return value of vsnprintf()... Yes.
Checking for attribute(visibility) support... Yes.
</code></p>

<p>4)  <code>make &amp;&amp; make install</code>
<code>
arm-linux-gnueabihf-gcc -O3 -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -I. -c -o example.o test/example.c
...
rm -f /tmp/cross/include/zlib.h /tmp/cross/include/zconf.h
cp zlib.h zconf.h /tmp/cross/include
chmod 644 /tmp/cross/include/zlib.h /tmp/cross/include/zconf.h
</code></p>

<p>5) <code>file /tmp/cross/lib/libz.so.1.2.11</code>  This is just to confirm we built an ARM lib as expected
<code>
/tmp/cross/lib/libz.so.1.2.11: ELF 32-bit LSB shared object, ARM, EABI5 version 1 (SYSV), dynamically linked, BuildID[sha1]=6f8ffef84389b1417d2fd1da1bd0c90f748f300d, with debug_info, not stripped
</code></p>

<h2>3/4: Building mbedtls cross</h2>

<p>1) <code>cd /tmp</code></p>

<p>2) <code>git clone https://github.com/ARMmbed/mbedtls.git</code></p>

<p>3) <code>cd mbedtls ; mkdir build ; cd build</code></p>

<p>3) <code>cmake .. -DCMAKE_TOOLCHAIN_FILE=/tmp/mytoolchainfile -DCMAKE_INSTALL_PREFIX:PATH=/tmp/cross -DCMAKE_BUILD_TYPE=RELEASE -DUSE_SHARED_MBEDTLS_LIBRARY=1</code>  mbedtls also uses cmake, so you can simply reuse the toolchain file you used for libwebsockets.  That is why you shouldn't put project-specific options in the toolchain file, it should just describe the toolchain.</p>

<p>4) <code>make &amp;&amp; make install</code></p>

<p>5) <code>file /tmp/cross/lib/libmbedcrypto.so.2.6.0</code>
<code>
/tmp/cross/lib/libmbedcrypto.so.2.6.0: ELF 32-bit LSB shared object, ARM, EABI5 version 1 (SYSV), dynamically linked, BuildID[sha1]=bcca195e78bd4fd2fb37f36ab7d72d477d609d87, with debug_info, not stripped
</code></p>

<h2>4/4: Building libwebsockets with everything</h2>

<p>1) <code>cd /tmp</code></p>

<p>2) <code>git clone ssh://git@github.com/warmcat/libwebsockets</code></p>

<p>3) <code>cd libwebsockets ; mkdir build ; cd build</code></p>

<p>4)  (this is all one line on the commandline)
<code>
cmake .. -DCMAKE_TOOLCHAIN_FILE=/tmp/mytoolchainfile \
-DCMAKE_INSTALL_PREFIX:PATH=/tmp/cross \
-DLWS_WITH_LWSWS=1 \
-DLWS_WITH_MBEDTLS=1 \
-DLWS_MBEDTLS_LIBRARIES="/tmp/cross/lib/libmbedcrypto.so;/tmp/cross/lib/libmbedtls.so;/tmp/cross/lib/libmbedx509.so" \
-DLWS_MBEDTLS_INCLUDE_DIRS=/tmp/cross/include \
-DLWS_LIBUV_LIBRARIES=/tmp/cross/lib/libuv.so \
-DLWS_LIBUV_INCLUDE_DIRS=/tmp/cross/include \
-DLWS_ZLIB_LIBRARIES=/tmp/cross/lib/libz.so \
-DLWS_ZLIB_INCLUDE_DIRS=/tmp/cross/include
</code></p>

<p>3) <code>make &amp;&amp; make install</code></p>

<p>4) <code>file /tmp/cross/lib/libwebsockets.so.11</code>
<code>
/tmp/cross/lib/libwebsockets.so.11: ELF 32-bit LSB shared object, ARM, EABI5 version 1 (SYSV), dynamically linked, BuildID[sha1]=81e59c6534f8e9629a9fc9065c6e955ce96ca690, with debug_info, not stripped
</code></p>

<p>5) <code>arm-linux-gnueabihf-objdump -p /tmp/cross/lib/libwebsockets.so.11 | grep NEEDED</code>  Confirm that the lws library was linked against everything we expect (libm / libc are provided by your toolchain)
<code>
  NEEDED               libz.so.1
  NEEDED               libmbedcrypto.so.0
  NEEDED               libmbedtls.so.10
  NEEDED               libmbedx509.so.0
  NEEDED               libuv.so.1
  NEEDED               libm.so.6
  NEEDED               libc.so.6
</code></p>

<p>You will also find the lws test apps in <code>/tmp/cross/bin</code>... to run lws on the target you will need to copy the related things from /tmp/cross... all the .so from /tmp/cross/lib and anything from /tmp/cross/bin you want.</p>

<p>@section mem Memory efficiency</p>

<p>Embedded server-only configuration without extensions (ie, no compression
on websocket connections), but with full v13 websocket features and http
server, built on ARM Cortex-A9:</p>

<p>Update at 8dac94d (2013-02-18)
```
    $ ./configure --without-client --without-extensions --disable-debug --without-daemonize</p>

<pre><code>Context Creation, 1024 fd limit[2]:   16720 (includes 12 bytes per fd)
Per-connection [3]:                      72 bytes, +1328 during headers

.text   .rodata .data   .bss
11512   2784    288 4
</code></pre>

<p>```
This shows the impact of the major configuration with/without options at
13ba5bbc633ea962d46d using Ubuntu ARM on a PandaBoard ES.</p>

<p>These are accounting for static allocations from the library elf, there are
additional dynamic allocations via malloc.  These are a bit old now but give
the right idea for relative "expense" of features.</p>

<p>Static allocations, ARM9</p>

<p>|                                | .text   | .rodata | .data | .bss |
|--------------------------------|---------|---------|-------|------|
| All (no without)               | 35024   | 9940    | 336   | 4104 |
| without client                 | 25684   | 7144    | 336   | 4104 |
| without client, exts           | 21652   | 6288    | 288   | 4104 |
| without client, exts, debug[1] | 19756   | 3768    | 288   | 4104 |
| without server                 | 30304   | 8160    | 336   | 4104 |
| without server, exts           | 25382   | 7204    | 288   | 4104 |
| without server, exts, debug[1] | 23712   | 4256    | 288   | 4104 |</p>

<p>[1] <code>--disable-debug</code> only removes messages below <code>lwsl_notice</code>.  Since that is
the default logging level the impact is not noticeable, error, warn and notice
logs are all still there.</p>

<p>[2] <code>1024</code> fd per process is the default limit (set by ulimit) in at least Fedora
and Ubuntu.  You can make significant savings tailoring this to actual expected
peak fds, ie, at a limit of <code>20</code>, context creation allocation reduces to <code>4432 +
240 = 4672</code>)</p>

<p>[3] known header content is freed after connection establishment</p>

<h2>Need for CI</h2>

<p>Generally if we're adding something that's supposed to work ongoing, the stuff
should be exercised in CI (at least Travis).</p>

<p>If there are few users for a particular feature, experience has shown that
refactors or other upheaval can easily break it into a state of uselessness
without anyone noticing until later.</p>

<p>Therefore here's a description of how to add something to the CI tests... this
is certainly a nonproductive PITA and I have never been thanked for the work
involved.  But if the promise of the various features working is going to
remain alive, it's necessary to include CI test where possible with new
nontrivial code.</p>

<h2>Integration points</h2>

<h3>cmake</h3>

<p><code>.travis.yml</code> maps the various test activities to CMake options needed.</p>

<h3>including dependent packages into travis</h3>

<p>See <code>./scripts/travis_install.sh</code></p>

<h3>performing prepared test actions</h3>

<p>See <code>./scripts/travis_control.sh</code></p>

<h1>Notes about coding with lws</h1>

<p>@section era Old lws and lws v2.0</p>

<p>Originally lws only supported the "manual" method of handling everything in the
user callback found in test-server.c / test-server-http.c.</p>

<p>Since v2.0, the need for most or all of this manual boilerplate has been
eliminated: the protocols[0] http stuff is provided by a generic lib export
<code>lws_callback_http_dummy()</code>.  You can serve parts of your filesystem at part of
the URL space using mounts, the dummy http callback will do the right thing.</p>

<p>It's much preferred to use the "automated" v2.0 type scheme, because it's less
code and it's easier to support.</p>

<p>The minimal examples all use the modern, recommended way.</p>

<p>If you just need generic serving capability, without the need to integrate lws
to some other app, consider not writing any server code at all, and instead use
the generic server <code>lwsws</code>, and writing your special user code in a standalone
"plugin".  The server is configured for mounts etc using JSON, see
./READMEs/README.lwsws.md.</p>

<p>Although the "plugins" are dynamically loaded if you use lwsws or lws built
with libuv, actually they may perfectly well be statically included if that
suits your situation better, eg, ESP32 test server, where the platform does
not support processes or dynamic loading, just #includes the plugins
one after the other and gets the same benefit from the same code.</p>

<p>Isolating and collating the protocol code in one place also makes it very easy
to maintain and understand.</p>

<p>So it if highly recommended you put your protocol-specific code into the
form of a "plugin" at the source level, even if you have no immediate plan to
use it dynamically-loaded.</p>

<p>@section writeable Only send data when socket writeable</p>

<p>You should only send data on a websocket connection from the user callback
<code>LWS_CALLBACK_SERVER_WRITEABLE</code> (or <code>LWS_CALLBACK_CLIENT_WRITEABLE</code> for
clients).</p>

<p>If you want to send something, do NOT just send it but request a callback
when the socket is writeable using</p>

<ul>
<li><p><code>lws_callback_on_writable(wsi)</code> for a specific <code>wsi</code>, or</p></li>
<li><p><code>lws_callback_on_writable_all_protocol(protocol)</code> for all connections
using that protocol to get a callback when next writeable.</p></li>
</ul>

<p>Usually you will get called back immediately next time around the service
loop, but if your peer is slow or temporarily inactive the callback will be
delayed accordingly.  Generating what to write and sending it should be done
in the ...WRITEABLE callback.</p>

<p>See the test server code for an example of how to do this.</p>

<p>Otherwise evolved libs like libuv get this wrong, they will allow you to "send"
anything you want but it only uses up your local memory (and costs you
memcpys) until the socket can actually accept it.  It is much better to regulate
your send action by the downstream peer readiness to take new data in the first
place, avoiding all the wasted buffering.</p>

<p>Libwebsockets' concept is that the downstream peer is truly the boss, if he,
or our connection to him, cannot handle anything new, we should not generate
anything new for him.  This is how unix shell piping works, you may have
`cat a.txt | grep xyz > remote", but actually that does not cat anything from
a.txt while remote cannot accept anything new. </p>

<p>@section oneper Only one lws_write per WRITEABLE callback</p>

<p>From v2.5, lws strictly enforces only one lws_write() per WRITEABLE callback.</p>

<p>You will receive a message about "Illegal back-to-back write of ... detected"
if there is a second lws_write() before returning to the event loop.</p>

<p>This is because with http/2, the state of the network connection carrying a
wsi is unrelated to any state of the wsi.  The situation on http/1 where a
new request implied a new tcp connection and new SSL buffer, so you could
assume some window for writes is no longer true.  Any lws_write() can fail
and be buffered for completion by lws; it will be auto-completed by the
event loop.</p>

<p>Note that if you are handling your own http responses, writing the headers
needs to be done with a separate lws_write() from writing any payload.  That
means after writing the headers you must call <code>lws_callback_on_writable(wsi)</code>
and send any payload from the writable callback.</p>

<p>@section otherwr Do not rely on only your own WRITEABLE requests appearing</p>

<p>Libwebsockets may generate additional <code>LWS_CALLBACK_CLIENT_WRITEABLE</code> events
if it met network conditions where it had to buffer your send data internally.</p>

<p>So your code for <code>LWS_CALLBACK_CLIENT_WRITEABLE</code> needs to own the decision
about what to send, it can't assume that just because the writeable callback
came something is ready to send.</p>

<p>It's quite possible you get an 'extra' writeable callback at any time and
just need to <code>return 0</code> and wait for the expected callback later.</p>

<p>@section dae Daemonization</p>

<p>There's a helper api <code>lws_daemonize</code> built by default that does everything you
need to daemonize well, including creating a lock file.  If you're making
what's basically a daemon, just call this early in your init to fork to a
headless background process and exit the starting process.</p>

<p>Notice stdout, stderr, stdin are all redirected to /dev/null to enforce your
daemon is headless, so you'll need to sort out alternative logging, by, eg,
syslog via <code>lws_set_log_level(..., lwsl_emit_syslog)</code>.</p>

<p>@section conns Maximum number of connections</p>

<p>The maximum number of connections the library can deal with is decided when
it starts by querying the OS to find out how many file descriptors it is
allowed to open (1024 on Fedora for example).  It then allocates arrays that
allow up to that many connections, minus whatever other file descriptors are
in use by the user code.</p>

<p>If you want to restrict that allocation, or increase it, you can use ulimit or
similar to change the available number of file descriptors, and when restarted
<strong>libwebsockets</strong> will adapt accordingly.</p>

<p>@section peer<em>limits optional LWS</em>WITH<em>PEER</em>LIMITS</p>

<p>If you select <code>LWS_WITH_PEER_LIMITS</code> at cmake, then lws will track peer IPs
and monitor how many connections and ah resources they are trying to use
at one time.  You can choose to limit these at context creation time, using
<code>info.ip_limit_ah</code> and <code>info.ip_limit_wsi</code>.</p>

<p>Note that although the ah limit is 'soft', ie, the connection will just wait
until the IP is under the ah limit again before attaching a new ah, the
wsi limit is 'hard', lws will drop any additional connections from the
IP until it's under the limit again.</p>

<p>If you use these limits, you should consider multiple clients may simultaneously
try to access the site through NAT, etc.  So the limits should err on the side
of being generous, while still making it impossible for one IP to exhaust
all the server resources.</p>

<p>@section evtloop Libwebsockets is singlethreaded</p>

<p>Libwebsockets works in a serialized event loop, in a single thread.  It supports
the default poll() backend, and libuv, libev, and libevent event loop
libraries that also take this locking-free, nonblocking event loop approach that
is not threadsafe.  There are several advantages to this technique, but one
disadvantage, it doesn't integrate easily if there are multiple threads that
want to use libwebsockets.</p>

<p>However integration to multithreaded apps is possible if you follow some guidelines.</p>

<p>1) Aside from two APIs, directly calling lws apis from other threads is not allowed.</p>

<p>2) If you want to keep a list of live wsi, you need to use lifecycle callbacks on
the protocol in the service thread to manage the list, with your own locking.
Typically you use an ESTABLISHED callback to add ws wsi to your list and a CLOSED
callback to remove them.</p>

<p>3) LWS regulates your write activity by being able to let you know when you may
write more on a connection.  That reflects the reality that you cannot succeed to
send data to a peer that has no room for it, so you should not generate or buffer
write data until you know the peer connection can take more.</p>

<p>Other libraries pretend that the guy doing the writing is the boss who decides
what happens, and absorb as much as you want to write to local buffering.  That does
not scale to a lot of connections, because it will exhaust your memory and waste
time copying data around in memory needlessly.</p>

<p>The truth is the receiver, along with the network between you, is the boss who
decides what will happen.  If he stops accepting data, no data will move.  LWS is
designed to reflect that.</p>

<p>If you have something to send, you call <code>lws_callback_on_writable()</code> on the
connection, and when it is writeable, you will get a <code>LWS_CALLBACK_SERVER_WRITEABLE</code>
callback, where you should generate the data to send and send it with <code>lws_write()</code>.</p>

<p>You cannot send data using <code>lws_write()</code> outside of the WRITEABLE callback.</p>

<p>4) For multithreaded apps, this corresponds to a need to be able to provoke the
<code>lws_callback_on_writable()</code> action and to wake the service thread from its event
loop wait (sleeping in <code>poll()</code> or <code>epoll()</code> or whatever).  The rules above
mean directly sending data on the connection from another thread is out of the
question.</p>

<p>Therefore the two apis mentioned above that may be used from another thread are</p>

<ul>
<li><p>For LWS using the default poll() event loop, <code>lws_callback_on_writable()</code></p></li>
<li><p>For LWS using libuv/libev/libevent event loop, <code>lws_cancel_service()</code></p></li>
</ul>

<p>If you are using the default poll() event loop, one "foreign thread" at a time may
call <code>lws_callback_on_writable()</code> directly for a wsi.  You need to use your own
locking around that to serialize multiple thread access to it.</p>

<p>If you implement LWS<em>CALLBACK</em>GET<em>THREAD</em>ID in protocols[0], then LWS will detect
when it has been called from a foreign thread and automatically use
<code>lws_cancel_service()</code> to additionally wake the service loop from its wait.</p>

<p>For libuv/libev/libevent event loop, they cannot handle being called from other
threads.  So there is a slightly different scheme, you may call <code>lws_cancel_service()</code> 
to force the event loop to end immediately.  This then broadcasts a callback (in the
service thread context) <code>LWS_CALLBACK_EVENT_WAIT_CANCELLED</code>, to all protocols on all
vhosts, where you can perform your own locking and walk a list of wsi that need
<code>lws_callback_on_writable()</code> calling on them.</p>

<p><code>lws_cancel_service()</code> is very cheap to call.</p>

<p>5) The obverse of this truism about the receiver being the boss is the case where
we are receiving.  If we get into a situation we actually can't usefully
receive any more, perhaps because we are passing the data on and the guy we want
to send to can't receive any more, then we should "turn off RX" by using the
RX flow control API, <code>lws_rx_flow_control(wsi, 0)</code>.  When something happens where we
can accept more RX, (eg, we learn our onward connection is writeable) we can call
it again to re-enable it on the incoming wsi.</p>

<p>LWS stops calling back about RX immediately you use flow control to disable RX, it
buffers the data internally if necessary.  So you will only see RX when you can
handle it.  When flow control is disabled, LWS stops taking new data in... this makes
the situation known to the sender by TCP "backpressure", the tx window fills and the
sender finds he cannot write any more to the connection.</p>

<p>See the mirror protocol implementations for example code.</p>

<p>If you need to service other socket or file descriptors as well as the
websocket ones, you can combine them together with the websocket ones
in one poll loop, see "External Polling Loop support" below, and
still do it all in one thread / process context.  If the need is less
architectural, you can also create RAW mode client and serving sockets; this
is how the lws plugin for the ssh server works.</p>

<p>@section anonprot Working without a protocol name</p>

<p>Websockets allows connections to negotiate without a protocol name...
in that case by default it will bind to the first protocol in your
vhost protocols[] array.</p>

<p>You can tell the vhost to use a different protocol by attaching a
pvo (per-vhost option) to the </p>

<p>```
/*
 * this sets a per-vhost, per-protocol option name:value pair
 * the effect is to set this protocol to be the default one for the vhost,
 * ie, selected if no Protocol: header is sent with the ws upgrade.
 */</p>

<p>static const struct lws<em>protocol</em>vhost<em>options pvo</em>opt = {
    NULL,
    NULL,
    "default",
    "1"
};</p>

<p>static const struct lws<em>protocol</em>vhost<em>options pvo = {
    NULL,
    &amp;pvo</em>opt,
    "my-protocol",
    ""
};</p>

<p>...</p>

<pre><code>context_info.pvo = &amp;pvo;
</code></pre>

<p>...</p>

<p>```</p>

<p>Will select "my-protocol" from your protocol list (even if it came
in by plugin) as being the target of client connections that don't
specify a protocol.</p>

<p>@section closing Closing connections from the user side</p>

<p>When you want to close a connection, you do it by returning <code>-1</code> from a
callback for that connection.</p>

<p>You can provoke a callback by calling <code>lws_callback_on_writable</code> on
the wsi, then notice in the callback you want to close it and just return -1.
But usually, the decision to close is made in a callback already and returning
-1 is simple.</p>

<p>If the socket knows the connection is dead, because the peer closed or there
was an affirmitive network error like a FIN coming, then <strong>libwebsockets</strong>  will
take care of closing the connection automatically.</p>

<p>If you have a silently dead connection, it's possible to enter a state where
the send pipe on the connection is choked but no ack will ever come, so the
dead connection will never become writeable.  To cover that, you can use TCP
keepalives (see later in this document) or pings.</p>

<p>@section gzip Serving from inside a zip file</p>

<p>Lws now supports serving gzipped files from inside a zip container.  Thanks to
Per Bothner for contributing the code.</p>

<p>This has the advtantage that if the client can accept GZIP encoding, lws can
simply send the gzip-compressed file from inside the zip file with no further
processing, saving time and bandwidth.</p>

<p>In the case the client can't understand gzip compression, lws automatically
decompressed the file and sends it normally.</p>

<p>Clients with limited storage and RAM will find this useful; the memory needed
for the inflate case is constrained so that only one input buffer at a time
is ever in memory.</p>

<p>To use this feature, ensure LWS<em>WITH</em>ZIP_FOPS is enabled at CMake.</p>

<p><code>libwebsockets-test-server-v2.0</code> includes a mount using this technology
already, run that test server and navigate to http://localhost:7681/ziptest/candide.html</p>

<p>This will serve the book Candide in html, together with two jpgs, all from
inside a .zip file in /usr/[local/]share-libwebsockets-test-server/candide.zip</p>

<p>Usage is otherwise automatic, if you arrange a mount that points to the zipfile,
eg, "/ziptest" -> "mypath/test.zip", then URLs like <code>/ziptest/index.html</code> will be
servied from <code>index.html</code> inside <code>mypath/test.zip</code></p>

<p>@section frags Fragmented messages</p>

<p>To support fragmented messages you need to check for the final
frame of a message with <code>lws_is_final_fragment</code>. This
check can be combined with <code>libwebsockets_remaining_packet_payload</code>
to gather the whole contents of a message, eg:</p>

<p>```
        case LWS<em>CALLBACK</em>RECEIVE:
        {
            Client * const client = (Client *)user;
            const size<em>t remaining = lws</em>remaining<em>packet</em>payload(wsi);</p>

<pre><code>        if (!remaining &amp;&amp; lws_is_final_fragment(wsi)) {
            if (client-&gt;HasFragments()) {
                client-&gt;AppendMessageFragment(in, len, 0);
                in = (void *)client-&gt;GetMessage();
                len = client-&gt;GetMessageLength();
            }

            client-&gt;ProcessMessage((char *)in, len, wsi);
            client-&gt;ResetMessage();
        } else
            client-&gt;AppendMessageFragment(in, len, remaining);
    }
    break;
</code></pre>

<p>```</p>

<p>The test app libwebsockets-test-fraggle sources also show how to
deal with fragmented messages.</p>

<p>@section debuglog Debug Logging</p>

<p>Also using <code>lws_set_log_level</code> api you may provide a custom callback to actually
emit the log string.  By default, this points to an internal emit function
that sends to stderr.  Setting it to <code>NULL</code> leaves it as it is instead.</p>

<p>A helper function <code>lwsl_emit_syslog()</code> is exported from the library to simplify
logging to syslog.  You still need to use <code>setlogmask</code>, <code>openlog</code> and <code>closelog</code>
in your user code.</p>

<p>The logging apis are made available for user code.</p>

<ul>
<li><code>lwsl_err(...)</code></li>
<li><code>lwsl_warn(...)</code></li>
<li><code>lwsl_notice(...)</code></li>
<li><code>lwsl_info(...)</code></li>
<li><code>lwsl_debug(...)</code></li>
</ul>

<p>The difference between notice and info is that notice will be logged by default
whereas info is ignored by default.</p>

<p>If you are not building with _DEBUG defined, ie, without this</p>

<p><code>
    $ cmake .. -DCMAKE_BUILD_TYPE=DEBUG
</code></p>

<p>then log levels below notice do not actually get compiled in.</p>

<p>@section asan Building with ASAN</p>

<p>Under GCC you can select for the build to be instrumented with the Address
Sanitizer, using <code>cmake .. -DCMAKE_BUILD_TYPE=DEBUG -DLWS_WITH_ASAN=1</code>.  LWS is routinely run during development with valgrind, but ASAN is capable of finding different issues at runtime, like operations which are not strictly defined in the C
standard and depend on platform behaviours.</p>

<p>Run your application like this</p>

<p><code>
    $ sudo ASAN_OPTIONS=verbosity=2:halt_on_error=1  /usr/local/bin/lwsws
</code></p>

<p>and attach gdb to catch the place it halts.</p>

<p>@section extpoll External Polling Loop support</p>

<p><strong>libwebsockets</strong> maintains an internal <code>poll()</code> array for all of its
sockets, but you can instead integrate the sockets into an
external polling array.  That's needed if <strong>libwebsockets</strong> will
cooperate with an existing poll array maintained by another
server.</p>

<p>Three callbacks <code>LWS_CALLBACK_ADD_POLL_FD</code>, <code>LWS_CALLBACK_DEL_POLL_FD</code>
and <code>LWS_CALLBACK_CHANGE_MODE_POLL_FD</code> appear in the callback for protocol 0
and allow interface code to manage socket descriptors in other poll loops.</p>

<p>You can pass all pollfds that need service to <code>lws_service_fd()</code>, even
if the socket or file does not belong to <strong>libwebsockets</strong> it is safe.</p>

<p>If <strong>libwebsocket</strong> handled it, it zeros the pollfd <code>revents</code> field before returning.
So you can let <strong>libwebsockets</strong> try and if <code>pollfd-&gt;revents</code> is nonzero on return,
you know it needs handling by your code.</p>

<p>Also note that when integrating a foreign event loop like libev or libuv where
it doesn't natively use poll() semantics, and you must return a fake pollfd
reflecting the real event:</p>

<ul>
<li><p>be sure you set .events to .revents value as well in the synthesized pollfd</p></li>
<li><p>check the built-in support for the event loop if possible (eg, ./lib/libuv.c)
to see how it interfaces to lws</p></li>
<li><p>use LWS<em>POLLHUP / LWS</em>POLLIN / LWS_POLLOUT from libwebsockets.h to avoid
losing windows compatibility</p></li>
</ul>

<p>You also need to take care about "forced service" somehow... these are cases
where the network event was consumed, incoming data was all read, for example,
but the work arising from it was not completed.  There will not be any more
network event to trigger the remaining work, Eg, we read compressed data, but
we did not use up all the decompressed data before returning to the event loop
because we had to write some of it.</p>

<p>Lws provides an API to determine if anyone is waiting for forced service,
<code>lws_service_adjust_timeout(context, 1, tsi)</code>, normally tsi is 0.  If it returns
0, then at least one connection has pending work you can get done by calling
<code>lws_service_tsi(context, -1, tsi)</code>, again normally tsi is 0.</p>

<p>For eg, the default poll() event loop, or libuv/ev/event, lws does this
checking for you and handles it automatically.  But in the external polling
loop case, you must do it explicitly.  Handling it after every normal service
triggered by the external poll fd should be enough, since the situations needing
it are initially triggered by actual network events.</p>

<p>An example of handling it is shown in the test-server code specific to
external polling.</p>

<p>@section cpp Using with in c++ apps</p>

<p>The library is ready for use by C++ apps.  You can get started quickly by
copying the test server</p>

<p><code>
    $ cp test-apps/test-server.c test.cpp
</code></p>

<p>and building it in C++ like this</p>

<p><code>
    $ g++ -DINSTALL_DATADIR=\"/usr/share\" -ocpptest test.cpp -lwebsockets
</code></p>

<p><code>INSTALL_DATADIR</code> is only needed because the test server uses it as shipped, if
you remove the references to it in your app you don't need to define it on
the g++ line either.</p>

<p>@section headerinfo Availability of header information</p>

<p>HTTP Header information is managed by a pool of "ah" structs.  These are a
limited resource so there is pressure to free the headers and return the ah to
the pool for reuse.</p>

<p>For that reason header information on HTTP connections that get upgraded to
websockets is lost after the ESTABLISHED callback.  Anything important that
isn't processed by user code before then should be copied out for later.</p>

<p>For HTTP connections that don't upgrade, header info remains available the
whole time.</p>

<p>@section http2compat Code Requirements for HTTP/2 compatibility</p>

<p>Websocket connections only work over http/1, so there is nothing special to do
when you want to enable -DLWS<em>WITH</em>HTTP2=1.</p>

<p>The internal http apis already follow these requirements and are compatible with
http/2 already.  So if you use stuff like mounts and serve stuff out of the
filesystem, there's also nothing special to do.</p>

<p>However if you are getting your hands dirty with writing response headers, or
writing bulk data over http/2, you need to observe these rules so that it will
work over both http/1.x and http/2 the same.</p>

<p>1) LWS<em>PRE requirement applies on ALL lws</em>write().  For http/1, you don't have
to take care of LWS<em>PRE for http data, since it is just sent straight out.
For http/2, it will write up to LWS</em>PRE bytes behind the buffer start to create
the http/2 frame header.</p>

<p>This has implications if you treated the input buffer to lws_write() as const...
it isn't any more with http/2, up to 9 bytes behind the buffer will be trashed.</p>

<p>2) Headers are encoded using a sophisticated scheme in http/2.  The existing
header access apis are already made compatible for incoming headers,
for outgoing headers you must:</p>

<ul>
<li><p>observe the LWS_PRE buffer requirement mentioned above</p></li>
<li><p>Use <code>lws_add_http_header_status()</code> to add the transaction status (200 etc)</p></li>
<li><p>use lws apis <code>lws_add_http_header_by_name()</code> and <code>lws_add_http_header_by_token()</code>
to put the headers into the buffer (these will translate what is actually
written to the buffer depending on if the connection is in http/2 mode or not)</p></li>
<li><p>use the <code>lws api lws_finalize_http_header()</code> api after adding the last
response header</p></li>
<li><p>write the header using lws_write(..., <code>LWS_WRITE_HTTP_HEADERS</code>);</p>

<p>3) http/2 introduces per-stream transmit credit... how much more you can send
on a stream is decided by the peer.  You start off with some amount, as the
stream sends stuff lws will reduce your credit accordingly, when it reaches
zero, you must not send anything further until lws receives "more credit" for
that stream the peer.  Lws will suppress writable callbacks if you hit 0 until
more credit for the stream appears, and lws built-in file serving (via mounts
etc) already takes care of observing the tx credit restrictions.  However if
you write your own code that wants to send http data, you must consult the
<code>lws_get_peer_write_allowance()</code> api to find out the state of your tx credit.
For http/1, it will always return (size_t)-1, ie, no limit.</p>

<p>This is orthogonal to the question of how much space your local side's kernel
will make to buffer your send data on that connection.  So although the result
from <code>lws_get_peer_write_allowance()</code> is "how much you can send" logically,
and may be megabytes if the peer allows it, you should restrict what you send
at one time to whatever your machine will generally accept in one go, and
further reduce that amount if <code>lws_get_peer_write_allowance()</code> returns
something smaller.  If it returns 0, you should not consume or send anything
and return having asked for callback on writable, it will only come back when
more tx credit has arrived for your stream.</p>

<p>4) Header names with captital letters are illegal in http/2.  Header names in
http/1 are case insensitive.  So if you generate headers by name, change all
your header name strings to lower-case to be compatible both ways.</p>

<p>5) Chunked Transfer-encoding is illegal in http/2, http/2 peers will actively
reject it.  Lws takes care of removing the header and converting CGIs that
emit chunked into unchunked automatically for http/2 connections.</p></li>
</ul>

<p>If you follow these rules, your code will automatically work with both http/1.x
and http/2.</p>

<p>@section ka TCP Keepalive</p>

<p>It is possible for a connection which is not being used to send to die
silently somewhere between the peer and the side not sending.  In this case
by default TCP will just not report anything and you will never get any more
incoming data or sign the link is dead until you try to send.</p>

<p>To deal with getting a notification of that situation, you can choose to
enable TCP keepalives on all <strong>libwebsockets</strong> sockets, when you create the
context.</p>

<p>To enable keepalive, set the ka<em>time member of the context creation parameter
struct to a nonzero value (in seconds) at context creation time.  You should
also fill ka</em>probes and ka_interval in that case.</p>

<p>With keepalive enabled, the TCP layer will send control packets that should
stimulate a response from the peer without affecting link traffic.  If the
response is not coming, the socket will announce an error at <code>poll()</code> forcing
a close.</p>

<p>Note that BSDs don't support keepalive time / probes / interval per-socket
like Linux does.  On those systems you can enable keepalive by a nonzero
value in <code>ka_time</code>, but the systemwide kernel settings for the time / probes/
interval are used, regardless of what nonzero value is in <code>ka_time</code>.</p>

<p>@section sslopt Optimizing SSL connections</p>

<p>There's a member <code>ssl_cipher_list</code> in the <code>lws_context_creation_info</code> struct
which allows the user code to restrict the possible cipher selection at
context-creation time.</p>

<p>You might want to look into that to stop the ssl peers selecting a cipher which
is too computationally expensive.  To use it, point it to a string like</p>

<pre><code>`"RC4-MD5:RC4-SHA:AES128-SHA:AES256-SHA:HIGH:!DSS:!aNULL"`
</code></pre>

<p>if left <code>NULL</code>, then the "DEFAULT" set of ciphers are all possible to select.</p>

<p>You can also set it to <code>"ALL"</code> to allow everything (including insecure ciphers).</p>

<p>@section sslcerts Passing your own cert information direct to SSL_CTX</p>

<p>For most users it's enough to pass the SSL certificate and key information by
giving filepaths to the info.ssl<em>cert</em>filepath and info.ssl<em>private</em>key_filepath
members when creating the vhost.</p>

<p>If you want to control that from your own code instead, you can do so by leaving
the related info members NULL, and setting the info.options flag
LWS<em>SERVER</em>OPTION<em>CREATE</em>VHOST<em>SSL</em>CTX at vhost creation time.  That will create
the vhost SSL<em>CTX without any certificate, and allow you to use the callback
LWS</em>CALLBACK<em>OPENSSL</em>LOAD<em>EXTRA</em>SERVER<em>VERIFY</em>CERTS to add your certificate to
the SSL<em>CTX directly.  The vhost SSL</em>CTX * is in the user parameter in that
callback.</p>

<p>@section clientasync Async nature of client connections</p>

<p>When you call <code>lws_client_connect_info(..)</code> and get a <code>wsi</code> back, it does not
mean your connection is active.  It just means it started trying to connect.</p>

<p>Your client connection is actually active only when you receive
<code>LWS_CALLBACK_CLIENT_ESTABLISHED</code> for it.</p>

<p>There's a 5 second timeout for the connection, and it may give up or die for
other reasons, if any of that happens you'll get a
<code>LWS_CALLBACK_CLIENT_CONNECTION_ERROR</code> callback on protocol 0 instead for the
<code>wsi</code>.</p>

<p>After attempting the connection and getting back a non-<code>NULL</code> <code>wsi</code> you should
loop calling <code>lws_service()</code> until one of the above callbacks occurs.</p>

<p>As usual, see <a href="../test-apps/test-client.c">test-client.c</a> for example code.</p>

<p>Notice that the client connection api tries to progress the connection
somewhat before returning.  That means it's possible to get callbacks like
CONNECTION_ERROR on the new connection before your user code had a chance to
get the wsi returned to identify it (in fact if the connection did fail early,
NULL will be returned instead of the wsi anyway).</p>

<p>To avoid that problem, you can fill in <code>pwsi</code> in the client connection info
struct to point to a struct lws that get filled in early by the client
connection api with the related wsi.  You can then check for that in the
callback to confirm the identity of the failing client connection.</p>

<p>@section fileapi Lws platform-independent file access apis</p>

<p>lws now exposes his internal platform file abstraction in a way that can be
both used by user code to make it platform-agnostic, and be overridden or
subclassed by user code.  This allows things like handling the URI "directory
space" as a virtual filesystem that may or may not be backed by a regular
filesystem.  One example use is serving files from inside large compressed
archive storage without having to unpack anything except the file being
requested.</p>

<p>The test server shows how to use it, basically the platform-specific part of
lws prepares a file operations structure that lives in the lws context.</p>

<p>The user code can get a pointer to the file operations struct</p>

<p><code>
    LWS_VISIBLE LWS_EXTERN struct lws_plat_file_ops *
        `lws_get_fops`(struct lws_context *context);
</code></p>

<p>and then can use helpers to also leverage these platform-independent
file handling apis</p>

<p><code>``
    lws_fop_fd_t
</code>lws<em>plat</em>file<em>open<code>(struct lws_plat_file_ops *fops, const char *filename,
               lws_fop_flags_t *flags)
    int
</code>lws</em>plat<em>file</em>close`(lws<em>fop</em>fd<em>t fop</em>fd)</p>

<pre><code>unsigned long
`lws_plat_file_seek_cur`(lws_fop_fd_t fop_fd, lws_fileofs_t offset)

int
`lws_plat_file_read`(lws_fop_fd_t fop_fd, lws_filepos_t *amount,
       uint8_t *buf, lws_filepos_t len)

int
`lws_plat_file_write`(lws_fop_fd_t fop_fd, lws_filepos_t *amount,
       uint8_t *buf, lws_filepos_t len )
</code></pre>

<p>```</p>

<p>Generic helpers are provided which provide access to generic fops information or
call through to the above fops</p>

<p>```
lws<em>filepos</em>t
lws<em>vfs</em>tell(lws<em>fop</em>fd<em>t fop</em>fd);</p>

<p>lws<em>filepos</em>t
lws<em>vfs</em>get<em>length(lws</em>fop<em>fd</em>t fop_fd);</p>

<p>uint32<em>t
lws</em>vfs<em>get</em>mod<em>time(lws</em>fop<em>fd</em>t fop_fd);</p>

<p>lws<em>fileofs</em>t
lws<em>vfs</em>file<em>seek</em>set(lws<em>fop</em>fd<em>t fop</em>fd, lws<em>fileofs</em>t offset);</p>

<p>lws<em>fileofs</em>t
lws<em>vfs</em>file<em>seek</em>end(lws<em>fop</em>fd<em>t fop</em>fd, lws<em>fileofs</em>t offset);
```</p>

<p>The user code can also override or subclass the file operations, to either
wrap or replace them.  An example is shown in test server.</p>

<h3>Changes from v2.1 and before fops</h3>

<p>There are several changes:</p>

<p>1) Pre-2.2 fops directly used platform file descriptors.  Current fops returns and accepts a wrapper type lws<em>fop</em>fd_t which is a pointer to a malloc'd struct containing information specific to the filesystem implementation.</p>

<p>2) Pre-2.2 fops bound the fops to a wsi.  This is completely removed, you just give a pointer to the fops struct that applies to this file when you open it.  Afterwards, the operations in the fops just need the lws<em>fop</em>fd_t returned from the open.</p>

<p>3) Everything is wrapped in typedefs.  See lws-plat-unix.c for examples of how to implement.</p>

<p>4) Position in the file, File Length, and a copy of Flags left after open are now generically held in the fop_fd.
VFS implementation must set and manage this generic information now.  See the implementations in lws-plat-unix.c for
examples.</p>

<p>5) The file length is no longer set at a pointer provided by the open() fop.  The api <code>lws_vfs_get_length()</code> is provided to
get the file length after open.</p>

<p>6) If your file namespace is virtual, ie, is not reachable by platform fops directly, you must set LWS<em>FOP</em>FLAG_VIRTUAL
on the flags during open.</p>

<p>7) There is an optional <code>mod_time</code> uint32<em>t member in the generic fop</em>fd.  If you are able to set it during open, you
should indicate it by setting <code>LWS_FOP_FLAG_MOD_TIME_VALID</code> on the flags.</p>

<p>@section rawfd RAW file descriptor polling</p>

<p>LWS allows you to include generic platform file descriptors in the lws service / poll / event loop.</p>

<p>Open your fd normally and then</p>

<p>```
    lws<em>sock</em>file<em>fd</em>type u;</p>

<pre><code>u.filefd = your_open_file_fd;

if (!lws_adopt_descriptor_vhost(vhost, 0, u,
                "protocol-name-to-bind-to",
                optional_wsi_parent_or_NULL)) {
    // failed
}

// OK
</code></pre>

<p>```</p>

<p>A wsi is created for the file fd that acts like other wsi, you will get these
callbacks on the named protocol</p>

<p><code>
    LWS_CALLBACK_RAW_ADOPT_FILE
    LWS_CALLBACK_RAW_RX_FILE
    LWS_CALLBACK_RAW_WRITEABLE_FILE
    LWS_CALLBACK_RAW_CLOSE_FILE
</code></p>

<p>starting with LWS<em>CALLBACK</em>RAW<em>ADOPT</em>FILE.</p>

<p>The minimal example <code>raw/minimal-raw-file</code> demonstrates how to use it.</p>

<p><code>protocol-lws-raw-test</code> plugin also provides a method for testing this with
<code>libwebsockets-test-server-v2.0</code>:</p>

<p>The plugin creates a FIFO on your system called "/tmp/lws-test-raw"</p>

<p>You can feed it data through the FIFO like this</p>

<p><code>
  $ sudo sh -c "echo hello &gt; /tmp/lws-test-raw"
</code></p>

<p>This plugin simply prints the data.  But it does it through the lws event
loop / service poll.</p>

<p>@section rawsrvsocket RAW server socket descriptor polling</p>

<p>You can also enable your vhost to accept RAW socket connections, in addition to
HTTP[s] and WS[s].  If the first bytes written on the connection are not a
valid HTTP method, then the connection switches to RAW mode.</p>

<p>This is disabled by default, you enable it by setting the <code>.options</code> flag
LWS<em>SERVER</em>OPTION<em>FALLBACK</em>TO<em>APPLY</em>LISTEN<em>ACCEPT</em>CONFIG, and setting
<code>.listen_accept_role</code> to <code>"raw-skt"</code> when creating the vhost.</p>

<p>RAW mode socket connections receive the following callbacks</p>

<p><code>
    LWS_CALLBACK_RAW_ADOPT
    LWS_CALLBACK_RAW_RX
    LWS_CALLBACK_RAW_WRITEABLE
    LWS_CALLBACK_RAW_CLOSE
</code></p>

<p>You can control which protocol on your vhost handles these RAW mode
incoming connections by setting the vhost info struct's <code>.listen_accept_protocol</code>
to the vhost protocol name to use.</p>

<p><code>protocol-lws-raw-test</code> plugin provides a method for testing this with
<code>libwebsockets-test-server-v2.0</code>:</p>

<p>Run libwebsockets-test-server-v2.0 and connect to it by telnet, eg</p>

<p><code>
    $ telnet 127.0.0.1 7681
</code></p>

<p>type something that isn't a valid HTTP method and enter, before the
connection times out.  The connection will switch to RAW mode using this
protocol, and pass the unused rx as a raw RX callback.</p>

<p>The test protocol echos back what was typed on telnet to telnet.</p>

<p>@section rawclientsocket RAW client socket descriptor polling</p>

<p>You can now also open RAW socket connections in client mode.</p>

<p>Follow the usual method for creating a client connection, but set the
<code>info.method</code> to "RAW".  When the connection is made, the wsi will be
converted to RAW mode and operate using the same callbacks as the
server RAW sockets described above.</p>

<p>The libwebsockets-test-client supports this using raw:// URLS.  To
test, open a netcat listener in one window</p>

<p><code>
 $ nc -l 9999
</code></p>

<p>and in another window, connect to it using the test client</p>

<p><code>
 $ libwebsockets-test-client raw://127.0.0.1:9999
</code></p>

<p>The connection should succeed, and text typed in the netcat window (including a CRLF)
will be received in the client.</p>

<p>@section rawudp RAW UDP socket integration</p>

<p>Lws provides an api to create, optionally bind, and adopt a RAW UDP
socket (RAW here means an uninterpreted normal UDP socket, not a
"raw socket").</p>

<p><code>
LWS_VISIBLE LWS_EXTERN struct lws *
lws_create_adopt_udp(struct lws_vhost *vhost, int port, int flags,
             const char *protocol_name, struct lws *parent_wsi);
</code></p>

<p><code>flags</code> should be <code>LWS_CAUDP_BIND</code> if the socket will receive packets.</p>

<p>The callbacks <code>LWS_CALLBACK_RAW_ADOPT</code>, <code>LWS_CALLBACK_RAW_CLOSE</code>,
<code>LWS_CALLBACK_RAW_RX</code> and <code>LWS_CALLBACK_RAW_WRITEABLE</code> apply to the
wsi.  But UDP is different than TCP in some fundamental ways.</p>

<p>For receiving on a UDP connection, data becomes available at
<code>LWS_CALLBACK_RAW_RX</code> as usual, but because there is no specific
connection with UDP, it is necessary to also get the source address of
the data separately, using <code>struct lws_udp * lws_get_udp(wsi)</code>.
You should take a copy of the <code>struct lws_udp</code> itself (not the
pointer) and save it for when you want to write back to that peer.</p>

<p>Writing is also a bit different for UDP.  By default, the system has no
idea about the receiver state and so asking for a <code>callback_on_writable()</code>
always believes that the socket is writeable... the callback will
happen next time around the event loop.</p>

<p>With UDP, there is no single "connection".  You need to write with sendto() and
direct the packets to a specific destination.  To return packets to a
peer who sent something earlier and you copied his <code>struct lws_udp</code>, you
use the .sa and .salen members as the last two parameters of the sendto().</p>

<p>The kernel may not accept to buffer / write everything you wanted to send.
So you are responsible to watch the result of sendto() and resend the
unsent part next time (which may involve adding new protocol headers to
the remainder depending on what you are doing).</p>

<p>@section ecdh ECDH Support</p>

<p>ECDH Certs are now supported.  Enable the CMake option</p>

<pre><code>cmake .. -DLWS_SSL_SERVER_WITH_ECDH_CERT=1
</code></pre>

<p><strong>and</strong> the info->options flag</p>

<pre><code>LWS_SERVER_OPTION_SSL_ECDH
</code></pre>

<p>to build in support and select it at runtime.</p>

<p>@section sslinfo SSL info callbacks</p>

<p>OpenSSL allows you to receive callbacks for various events defined in a
bitmask in openssl/ssl.h.  The events include stuff like TLS Alerts.</p>

<p>By default, lws doesn't register for these callbacks.</p>

<p>However if you set the info.ssl<em>info</em>event<em>mask to nonzero (ie, set some
of the bits in it like <code>SSL_CB_ALERT</code> at vhost creation time, then
connections to that vhost will call back using LWS</em>CALLBACK<em>SSL</em>INFO
for the wsi, and the <code>in</code> parameter will be pointing to a struct of
related args:</p>

<p><code>
struct lws_ssl_info {
    int where;
    int ret;
};
</code></p>

<p>The default callback handler in lws has a handler for LWS<em>CALLBACK</em>SSL_INFO
which prints the related information,  You can test it using the switch
-S -s  on <code>libwebsockets-test-server-v2.0</code>.</p>

<p>Returning nonzero from the callback will close the wsi.</p>

<p>@section smp SMP / Multithreaded service</p>

<p>SMP support is integrated into LWS without any internal threading.  It's
very simple to use, libwebsockets-test-server-pthread shows how to do it,
use -j n argument there to control the number of service threads up to 32.</p>

<p>Two new members are added to the info struct</p>

<pre><code>unsigned int count_threads;
unsigned int fd_limit_per_thread;
</code></pre>

<p>leave them at the default 0 to get the normal singlethreaded service loop.</p>

<p>Set count_threads to n to tell lws you will have n simultaneous service threads
operating on the context.</p>

<p>There is still a single listen socket on one port, no matter how many
service threads.</p>

<p>When a connection is made, it is accepted by the service thread with the least
connections active to perform load balancing.</p>

<p>The user code is responsible for spawning n threads running the service loop
associated to a specific tsi (Thread Service Index, 0 .. n - 1).  See
the libwebsockets-test-server-pthread for how to do.</p>

<p>If you leave fd<em>limit</em>per_thread at 0, then the process limit of fds is shared
between the service threads; if you process was allowed 1024 fds overall then
each thread is limited to 1024 / n.</p>

<p>You can set fd<em>limit</em>per_thread to a nonzero number to control this manually, eg
the overall supported fd limit is less than the process allowance.</p>

<p>You can control the context basic data allocation for multithreading from Cmake
using -DLWS<em>MAX</em>SMP=, if not given it's set to 1.  The serv_buf allocation
for the threads (currently 4096) is made at runtime only for active threads.</p>

<p>Because lws will limit the requested number of actual threads supported
according to LWS<em>MAX</em>SMP, there is an api lws<em>get</em>count_threads(context) to
discover how many threads were actually allowed when the context was created.</p>

<p>See the test-server-pthreads.c sample for how to use.</p>

<p>@section smplocking SMP Locking Helpers</p>

<p>Lws provide a set of pthread mutex helpers that reduce to no code or
variable footprint in the case that LWS<em>MAX</em>SMP == 1.</p>

<p>Define your user mutex like this</p>

<p><code>
    lws_pthread_mutex(name);
</code></p>

<p>If LWS<em>MAX</em>SMP > 1, this produces <code>pthread_mutex_t name;</code>.  In the case
LWS<em>MAX</em>SMP == 1, it produces nothing.</p>

<p>Likewise these helpers for init, destroy, lock and unlock</p>

<p><code>
    void lws_pthread_mutex_init(pthread_mutex_t *lock)
    void lws_pthread_mutex_destroy(pthread_mutex_t *lock)
    void lws_pthread_mutex_lock(pthread_mutex_t *lock)
    void lws_pthread_mutex_unlock(pthread_mutex_t *lock)
</code></p>

<p>resolve to nothing if LWS<em>MAX</em>SMP == 1, otherwise produce the equivalent
pthread api.</p>

<p>pthreads is required in lws only if LWS<em>MAX</em>SMP > 1.</p>

<p>@section libevuv libev / libuv / libevent support</p>

<p>You can select either or both</p>

<pre><code>-DLWS_WITH_LIBEV=1
-DLWS_WITH_LIBUV=1
-DLWS_WITH_LIBEVENT=1
</code></pre>

<p>at cmake configure-time.  The user application may use one of the
context init options flags</p>

<pre><code>LWS_SERVER_OPTION_LIBEV
LWS_SERVER_OPTION_LIBUV
LWS_SERVER_OPTION_LIBEVENT
</code></pre>

<p>to indicate it will use one of the event libraries at runtime.</p>

<p>libev has some problems, its headers conflict with libevent, they both define
critical constants like EV_READ to different values.  Attempts
to discuss clearing that up with libevent and libev did not get anywhere useful.</p>

<p>In addition building anything with libev using gcc spews warnings, the
maintainer is aware of this for many years, and blames gcc.  We worked
around this by disabling -Werror on the parts of lws that use libev.</p>

<p>For these reasons and the response I got trying to raise these issues with
them, if you have a choice about event loop, I would gently encourage you
to avoid libev.  Where lws uses an event loop itself, eg in lwsws, we use
libuv.</p>

<p>@section extopts Extension option control from user code</p>

<p>User code may set per-connection extension options now, using a new api
<code>lws_set_extension_option()</code>.</p>

<p>This should be called from the ESTABLISHED callback like this
<code>
     lws_set_extension_option(wsi, "permessage-deflate",
                              "rx_buf_size", "12"); /* 1 &lt;&lt; 12 */
</code></p>

<p>If the extension is not active (missing or not negotiated for the
connection, or extensions are disabled on the library) the call is
just returns -1.  Otherwise the connection's extension has its
named option changed.</p>

<p>The extension may decide to alter or disallow the change, in the
example above permessage-deflate restricts the size of his rx
output buffer also considering the protocol's rx<em>buf</em>size member.</p>

<p>@section httpsclient Client connections as HTTP[S] rather than WS[S]</p>

<p>You may open a generic http client connection using the same
struct lws<em>client</em>connect_info used to create client ws[s]
connections.</p>

<p>To stay in http[s], set the optional info member "method" to
point to the string "GET" instead of the default NULL.</p>

<p>After the server headers are processed, when payload from the
server is available the callback LWS<em>CALLBACK</em>RECEIVE<em>CLIENT</em>HTTP
will be made.</p>

<p>You can choose whether to process the data immediately, or
queue a callback when an outgoing socket is writeable to provide
flow control, and process the data in the writable callback.</p>

<p>Either way you use the api <code>lws_http_client_read()</code> to access the
data, eg</p>

<p>```
    case LWS<em>CALLBACK</em>RECEIVE<em>CLIENT</em>HTTP:
        {
            char buffer[1024 + LWS<em>PRE];
            char *px = buffer + LWS</em>PRE;
            int lenx = sizeof(buffer) - LWS_PRE;</p>

<pre><code>        lwsl_notice("LWS_CALLBACK_RECEIVE_CLIENT_HTTP\n");

        /*
         * Often you need to flow control this by something
         * else being writable.  In that case call the api
         * to get a callback when writable here, and do the
         * pending client read in the writeable callback of
         * the output.
         */
        if (lws_http_client_read(wsi, &amp;px, &amp;lenx) &lt; 0)
            return -1;
        while (lenx--)
            putchar(*px++);
    }
    break;
</code></pre>

<p>```</p>

<p>Notice that if you will use SSL client connections on a vhost, you must
prepare the client SSL context for the vhost after creating the vhost, since
this is not normally done if the vhost was set up to listen / serve.  Call
the api lws<em>init</em>vhost<em>client</em>ssl() to also allow client SSL on the vhost.</p>

<p>@section clipipe Pipelining Client Requests to same host</p>

<p>If you are opening more client requests to the same host and port, you
can give the flag LCCSCF_PIPELINE on <code>info.ssl_connection</code> to indicate
you wish to pipeline them.</p>

<p>Without the flag, the client connections will occur concurrently using a
socket and tls wrapper if requested for each connection individually.
That is fast, but resource-intensive.</p>

<p>With the flag, lws will queue subsequent client connections on the first
connection to the same host and port.  When it has confirmed from the
first connection that pipelining / keep-alive is supported by the server,
it lets the queued client pipeline connections send their headers ahead
of time to create a pipeline of requests on the server side.</p>

<p>In this way only one tcp connection and tls wrapper is required to transfer
all the transactions sequentially.  It takes a little longer but it
can make a significant difference to resources on both sides.</p>

<p>If lws learns from the first response header that keepalive is not possible,
then it marks itself with that information and detaches any queued clients
to make their own individual connections as a fallback.</p>

<p>Lws can also intelligently combine multiple ongoing client connections to
the same host and port into a single http/2 connection with multiple
streams if the server supports it.</p>

<p>Unlike http/1 pipelining, with http/2 the client connections all occur
simultaneously using h2 stream multiplexing inside the one tcp + tls
connection.</p>

<p>You can turn off the h2 client support either by not building lws with
<code>-DLWS_WITH_HTTP2=1</code> or giving the <code>LCCSCF_NOT_H2</code> flag in the client
connection info struct <code>ssl_connection</code> member.</p>

<p>@section vhosts Using lws vhosts</p>

<p>If you set LWS<em>SERVER</em>OPTION<em>EXPLICIT</em>VHOSTS options flag when you create
your context, it won't create a default vhost using the info struct
members for compatibility.  Instead you can call lws<em>create</em>vhost()
afterwards to attach one or more vhosts manually.</p>

<p><code>
    LWS_VISIBLE struct lws_vhost *
    lws_create_vhost(struct lws_context *context,
             struct lws_context_creation_info *info);
</code></p>

<p>lws<em>create</em>vhost() uses the same info struct as lws<em>create</em>context(),
it ignores members related to context and uses the ones meaningful
for vhost (marked with VH in libwebsockets.h).</p>

<p><code>
    struct lws_context_creation_info {
        int port;                   /* VH */
        const char *iface;              /* VH */
        const struct lws_protocols *protocols;      /* VH */
        const struct lws_extension *extensions;     /* VH */
    ...
</code></p>

<p>When you attach the vhost, if the vhost's port already has a listen socket
then both vhosts share it and use SNI (is SSL in use) or the Host: header
from the client to select the right one.  Or if no other vhost already
listening the a new listen socket is created.</p>

<p>There are some new members but mainly it's stuff you used to set at
context creation time.</p>

<p>@section sni How lws matches hostname or SNI to a vhost</p>

<p>LWS first strips any trailing :port number.</p>

<p>Then it tries to find an exact name match for a vhost listening on the correct
port, ie, if SNI or the Host: header provided abc.com:1234, it will match on a
vhost named abc.com that is listening on port 1234.</p>

<p>If there is no exact match, lws will consider wildcard matches, for example
if cats.abc.com:1234 is provided by the client by SNI or Host: header, it will
accept a vhost "abc.com" listening on port 1234.  If there was a better, exact,
match, it will have been chosen in preference to this.</p>

<p>Connections with SSL will still have the client go on to check the
certificate allows wildcards and error out if not.</p>

<p>@section mounts Using lws mounts on a vhost</p>

<p>The last argument to lws<em>create</em>vhost() lets you associate a linked
list of lws<em>http</em>mount structures with that vhost's URL 'namespace', in
a similar way that unix lets you mount filesystems into areas of your /
filesystem how you like and deal with the contents transparently.</p>

<p>```
    struct lws<em>http</em>mount {
        struct lws<em>http</em>mount <em>mount_next;
        const char *mountpoint; /</em> mountpoint in http pathspace, eg, "/" <em>/
        const char *origin; /</em> path to be mounted, eg, "/var/www/warmcat.com" <em>/
        const char *def; /</em> default target, eg, "index.html" */</p>

<pre><code>    struct lws_protocol_vhost_options *cgienv;

    int cgi_timeout;
    int cache_max_age;

    unsigned int cache_reusable:1;
    unsigned int cache_revalidate:1;
    unsigned int cache_intermediaries:1;

    unsigned char origin_protocol;
    unsigned char mountpoint_len;
};
</code></pre>

<p>```</p>

<p>The last mount structure should have a NULL mount_next, otherwise it should
point to the 'next' mount structure in your list.</p>

<p>Both the mount structures and the strings must persist until the context is
destroyed, since they are not copied but used in place.</p>

<p><code>.origin_protocol</code> should be one of</p>

<p><code>
    enum {
        LWSMPRO_HTTP,
        LWSMPRO_HTTPS,
        LWSMPRO_FILE,
        LWSMPRO_CGI,
        LWSMPRO_REDIR_HTTP,
        LWSMPRO_REDIR_HTTPS,
        LWSMPRO_CALLBACK,
    };
</code></p>

<ul>
<li><p>LWSMPRO_FILE is used for mapping url namespace to a filesystem directory and
serve it automatically.</p></li>
<li><p>LWSMPRO_CGI associates the url namespace with the given CGI executable, which
runs when the URL is accessed and the output provided to the client.</p></li>
<li><p>LWSMPRO<em>REDIR</em>HTTP and LWSMPRO<em>REDIR</em>HTTPS auto-redirect clients to the given
origin URL.</p></li>
<li><p>LWSMPRO_CALLBACK causes the http connection to attach to the callback
associated with the named protocol (which may be a plugin).</p></li>
</ul>

<p>@section mountcallback Operation of LWSMPRO_CALLBACK mounts</p>

<p>The feature provided by CALLBACK type mounts is binding a part of the URL
namespace to a named protocol callback handler.</p>

<p>This allows protocol plugins to handle areas of the URL namespace.  For example
in test-server-v2.0.c, the URL area "/formtest" is associated with the plugin
providing "protocol-post-demo" like this</p>

<p><code>
    static const struct lws_http_mount mount_post = {
        NULL,       /* linked-list pointer to next*/
        "/formtest",        /* mountpoint in URL namespace on this vhost */
        "protocol-post-demo",   /* handler */
        NULL,   /* default filename if none given */
        NULL,
        0,
        0,
        0,
        0,
        0,
        LWSMPRO_CALLBACK,   /* origin points to a callback */
        9,          /* strlen("/formtest"), ie length of the mountpoint */
    };
</code></p>

<p>Client access to /formtest[anything] will be passed to the callback registered
with the named protocol, which in this case is provided by a protocol plugin.</p>

<p>Access by all methods, eg, GET and POST are handled by the callback.</p>

<p>protocol-post-demo deals with accepting and responding to the html form that
is in the test server HTML.</p>

<p>When a connection accesses a URL related to a CALLBACK type mount, the
connection protocol is changed until the next access on the connection to a
URL outside the same CALLBACK mount area.  User space on the connection is
arranged to be the size of the new protocol user space allocation as given in
the protocol struct.</p>

<p>This allocation is only deleted / replaced when the connection accesses a
URL region with a different protocol (or the default protocols[0] if no
CALLBACK area matches it).</p>

<p>This "binding connection to a protocol" lifecycle in managed by
<code>LWS_CALLBACK_HTTP_BIND_PROTOCOL</code> and <code>LWS_CALLBACK_HTTP_DROP_PROTOCOL</code>.
Because of HTTP/1.1 connection pipelining, one connection may perform
many transactions, each of which may map to different URLs and need
binding to different protocols.  So these messages are used to
create the binding of the wsi to your protocol including any
allocations, and to destroy the binding, at which point you should
destroy any related allocations.</p>

<p>@section BINDTODEV SO<em>BIND</em>TO_DEVICE</p>

<p>The .bind_iface flag in the context / vhost creation struct lets you
declare that you want all traffic for listen and transport on that
vhost to be strictly bound to the network interface named in .iface.</p>

<p>This Linux-only feature requires SO<em>BIND</em>TO<em>DEVICE, which in turn
requires CAP</em>NET_RAW capability... root has this capability.</p>

<p>However this feature needs to apply the binding also to accepted
sockets during normal operation, which implies the server must run
the whole time as root.</p>

<p>You can avoid this by using the Linux capabilities feature to have
the unprivileged user inherit just the CAP<em>NET</em>RAW capability.</p>

<p>You can confirm this with the test server</p>

<p><code>
 $ sudo /usr/local/bin/libwebsockets-test-server -u agreen -i eno1 -k
</code></p>

<p>The part that ensures the capability is inherited by the unprivileged
user is</p>

<p>```</p>

<h1>if defined(LWS<em>HAVE</em>SYS<em>CAPABILITY</em>H) &amp;&amp; defined(LWS<em>HAVE</em>LIBCAP)</h1>

<pre><code>                    info.caps[0] = CAP_NET_RAW;
                    info.count_caps = 1;
</code></pre>

<h1>endif</h1>

<p>```</p>

<p>@section dim Dimming webpage when connection lost</p>

<p>The lws test plugins' html provides useful feedback on the webpage about if it
is still connected to the server, by greying out the page if not.  You can
also add this to your own html easily</p>

<ul>
<li><p>include lws-common.js from your HEAD section</p>

<p>\<script src="/lws-common.js">\</script></p></li>
<li><p>dim the page during initialization, in a script section on your page</p>

<p>lws<em>gray</em>out(true,{'zindex':'499'});</p></li>
<li><p>in your ws onOpen(), remove the dimming</p>

<p>lws<em>gray</em>out(false);</p></li>
<li><p>in your ws onClose(), reapply the dimming</p>

<p>lws<em>gray</em>out(true,{'zindex':'499'});</p></li>
</ul>

<p>@section errstyle Styling http error pages</p>

<p>In the code, http errors should be handled by <code>lws_return_http_status()</code>.</p>

<p>There are basically two ways... the vhost can be told to redirect to an "error
page" URL in response to specifically a 404... this is controlled by the
context / vhost info struct (<code>struct lws_context_creation_info</code>) member
<code>.error_document_404</code>... if non-null the client is redirected to this string.</p>

<p>If it wasn't redirected, then the response code html is synthesized containing
the user-selected text message and attempts to pull in <code>/error.css</code> for styling.</p>

<p>If this file exists, it can be used to style the error page.  See 
https://libwebsockets.org/git/badrepo for an example of what can be done (
and https://libwebsockets.org/error.css for the corresponding css).</p>

<h2>Using Content Security Policy (CSP)</h2>

<h3>What is it?</h3>

<p>Modern browsers have recently implemented a new feature providing
a sort of "selinux for your web page".  If the server sends some
new headers describing the security policy for the content, then
the browser strictly enforces it.</p>

<h3>Why would we want to do that?</h3>

<p>Scripting on webpages is pretty universal, sometimes the scripts
come from third parties, and sometimes attackers find a way to
inject scripts into the DOM, eg, through scripts in content.</p>

<p>CSP lets the origin server define what is legitimate for the page it
served and everything else is denied.</p>

<p>The CSP for warmcat.com and libwebsockets.org looks like this,
I removed a handful of whitelisted image sources like travis
status etc for clarity...</p>

<p><code>
"content-security-policy": "default-src 'none'; img-src 'self' data:; script-src 'self'; font-src 'self'; style-src 'self'; connect-src 'self'; frame-ancestors 'none'; base-uri 'none';",
"x-content-type-options": "nosniff",
"x-xss-protection": "1; mode=block",
"x-frame-options": "deny",
"referrer-policy": "no-referrer"
</code></p>

<p>The result of this is the browser won't let the site content be iframed, and it
will reject any inline styles or inline scripts.  Fonts, css, ajax, ws and
images are only allowed to come from 'self', ie, the server that served the
page.  You may inject your script, or deceptive styles: it won't run or be shown.</p>

<p>Because inline scripts are banned, the usual methods for XSS are dead;
the attacker can't even load js from another server.  So these rules
provide a very significant increase in client security.</p>

<h3>Implications of strict CSP</h3>

<p>Halfhearted CSP isn't worth much.  The only useful approach is to start
with <code>default-src 'none'</code> which disables everything, and then whitelist the
minimum needed for the pages to operate.</p>

<p>"Minimum needed for the pages to operate" doesn't mean defeat the protections
necessary so everything in the HTML can stay the same... it means adapt the
pages to want the minimum and then enable the minimum.</p>

<p>The main point is segregation of styles and script away from the content, in
files referenced in the document <code>&lt;head&gt;</code> section, along these lines:</p>

<p><code>
&lt;head&gt;
 &lt;meta charset=utf-8 http-equiv="Content-Language" content="en"/&gt;
 &lt;link rel="stylesheet" type="text/css" href="test.css"/&gt;
 &lt;script type='text/javascript' src="/lws-common.js"&gt;&lt;/script&gt;
 &lt;script type='text/javascript' src='test.js'&gt;&lt;/script&gt;
 &lt;title&gt;Minimal Websocket test app&lt;/title&gt;
&lt;/head&gt;
</code></p>

<h4>Inline styles must die</h4>

<p>All styling must go in one or more <code>.css</code> file(s) best served by the same
server... while you can whitelist other sources in the CSP if you have to,
unless you control that server as well, you are allowing whoever gains
access to that server access to your users.</p>

<p>Inline styles are no longer allowed (eg, "style='font-size:120%'" in the
HTML)... they must be replaced by reference to one or more CSS class, which
in this case includes "font-size:120%".  This has always been the best
practice anyway, and your pages will be cleaner and more maintainable.</p>

<h4>Inline scripts must die</h4>

<p>Inline scripts need to be placed in a <code>.js</code> file and loaded in the page head
section, again it should only be from the server that provided the page.</p>

<p>Then, any kind of inline script, yours or injected or whatever, will be
completely rejected by the browser.</p>

<h4>onXXX must be replaced by eventListener</h4>

<p>Inline <code>onclick()</code> etc are kinds of inline scripting and are banned.</p>

<p>Modern browsers have offered a different system called <a href="https://developer.mozilla.org/en-US/docs/Web/API/EventListener">"EventListener" for
a while</a>
which allows binding of events to DOM elements in JS.</p>

<p>A bunch of different named events are possible to listen on, commonly the
<code>.js</code> file will ask for one or both of</p>

<p>```
window.addEventListener("load", function() {
...
}, false);</p>

<p>document.addEventListener("DOMContentLoaded", function() {
...
}, false);
```</p>

<p>These give the JS a way to trigger when either everything on the page has
been "loaded" or the DOM has been populated from the initial HTML.  These
can set up other event listeners on the DOM objects and aftwards the
events will drive what happens on the page from user interaction and / or
timers etc.</p>

<p>If you have <code>onclick</code> in your HTML today, you would replace it with an id
for the HTML element, then eg in the DOMContentLoaded event listener,
apply </p>

<p><code>
   document.getElementById("my-id").addEventListener("click", function() {
   ...
   }, false);
</code></p>

<p>ie the .js file becomes the only place with the "business logic" of the
elements mentioned in the HTML, applied at runtime.</p>

<h4>Do you really need external sources?</h4>

<p>Do your scripts and fonts really need to come from external sources?
If your caching policy is liberal, they are not actually that expensive
to serve once and then the user is using his local copy for the next
days.</p>

<p>Some external sources are marked as anti-privacy in modern browsers, meaning
they track your users, in turn meaning if your site refers to them, you
will lose your green padlock in the browser.  If the content license allows
it, hosting them on "self", ie, the same server that provided the HTML,
will remove that problem.</p>

<p>Bringing in scripts from external sources is actually quite scary from the
security perspective.  If someone hacks the <code>ajax.googleapis.com</code> site to serve
a hostile, modified jquery, half the Internet will instantly
become malicious.  However if you serve it yourself, unless your server
was specifically targeted you know it will continue to serve what you
expect.</p>

<p>Since these scripts are usually sent with cache control headers for local
caching duration of 1 year, the cost of serving them yourself under the same
conditions is small but your susceptibility to attack is reduced to only taking
care of your own server.  And there is a privacy benefit that google is not
informed of your users' IPs and activities on your site.</p>

<h2>Contributing to lws</h2>

<h3>How to contribute</h3>

<p>Sending a patch with a bug report is very welcome.</p>

<p>For nontrivial problems, it's probably best to discuss on the mailing list,
or on github if you prefer, how to best solve it.</p>

<p>However your contribution is coming is fine:</p>

<ul>
<li><p>paste a <code>git diff</code></p></li>
<li><p>send a patch series by mail or mailing list</p></li>
<li><p>paste in a github issue</p></li>
<li><p>github PR</p></li>
</ul>

<p>are all OK.</p>

<h3>Coding Standards</h3>

<p>Code should look roughly like the existing code, which follows linux kernel
coding style.</p>

<p>If there are non-functional problems I will clean them out when I apply the
patch.</p>

<p>If there are functional problems (eg broken error paths etc) if they are
small compared to the working part I will also clean them.  If there are
larger problems, or consequences to the patch will have to discuss how to
solve them with a retry.</p>

<h3>Funding specific work</h3>

<p>If there is a feature you wish was supported in lws, consider paying for the
work to be done.  The maintainer is a consultant and if we can agree the
task, you can quickly get a high quality result that does just what you need,
maintained ongoing along with the rest of lws.</p>

<h1>Lws Crypto Apis</h1>

<h2>Overview</h2>

<p><img src="/doc-assets/lws-crypto-overview.svg" alt="lws crypto overview" title="" /></p>

<p>Lws provides a "generic" crypto layer on top of both OpenSSL and
compatible tls library, and mbedtls.  Using this layer, your code
can work without any changes on both types of tls library crypto
backends... it's as simple as rebuilding lws with <code>-DLWS_WITH_MBEDTLS=0</code>
or <code>=1</code> at cmake.</p>

<p>The generic layer can be used directly (as in, eg, the sshd plugin),
or via another layer on top, which processes JOSE JSON objects using
JWS (JSON Web Signatures), JWK (JSON Web Keys), and JWE (JSON Web
Encryption).</p>

<p>The <code>JW</code> apis use the generic apis (<code>lws_genrsa_</code>, etc) to get the crypto tasks
done, so anything they can do you can also get done using the generic apis.
The main difference is that with the generic apis, you must instantiate the
correct types and use type-specfic apis.  With the <code>JW</code> apis, there is only
one interface for all operations, with the details hidden in the api and
controlled by the JSON objects.</p>

<p>Because of this, the <code>JW</code> apis are often preferred because they give you
"crypto agility" cheaply... to change your crypto to another supported algorithm
once it's working, you literally just change your JSON defining the keys and
JWE or JWS algorithm.  (It's up to you to define your policy for which
combinations are acceptable by querying the parsed JW structs).</p>

<h2>Crypto supported in generic layer</h2>

<h3>Generic Hash</h3>

<ul>
<li>SHA1</li>
<li>SHA256</li>
<li>SHA384</li>
<li>SHA512</li>
</ul>

<h3>Generic HMAC</h3>

<ul>
<li>SHA256</li>
<li>SHA384</li>
<li>SHA512</li>
</ul>

<h3>Generic AES</h3>

<ul>
<li>CBC</li>
<li>CFB128</li>
<li>CFB8</li>
<li>CTR</li>
<li>ECB</li>
<li>OFB</li>
<li>XTS</li>
<li>GCM</li>
<li>KW (Key Wrap)</li>
</ul>

<h3>Generic RSA</h3>

<ul>
<li>PKCS 1.5</li>
<li>OAEP / PSS</li>
</ul>

<h3>Generic EC</h3>

<ul>
<li>ECDH</li>
<li>ECDSA</li>
<li>P256 / P384 / P521 (sic) curves</li>
</ul>

<h2>Using the generic layer</h2>

<p>All the necessary includes are part of <code>libwebsockets.h</code>.</p>

<p>Enable <code>-DLWS_WITH_GENCRYPTO=1</code> at cmake.</p>

<p>|api|header|Functionality|
|---|---|---|
|genhash|<a href="https://libwebsockets.org/git/libwebsockets/tree/include/libwebsockets/lws-genhash.h">./include/libwebsockets/lws-genhash.h</a>|Provides SHA1 + SHA2 hashes and hmac|
|genrsa|<a href="https://libwebsockets.org/git/libwebsockets/tree/include/libwebsockets/lws-genrsa.h">./include/libwebsockets/lws-genrsa.h</a>|Provides RSA encryption, decryption, signing, verification, key generation and creation|
|genaes|<a href="https://libwebsockets.org/git/libwebsockets/tree/include/libwebsockets/lws-genaes.h">./include/libwebsockets/lws-genaes.h</a>|Provides AES in all common variants for encryption and decryption|
|genec|<a href="https://libwebsockets.org/git/libwebsockets/tree/include/libwebsockets/lws-genec.h">./include/libwebsockets/lws-genec.h</a>|Provides Elliptic Curve for encryption, decryption, signing, verification, key generation and creation|
|x509|<a href="https://libwebsockets.org/git/libwebsockets/tree/include/libwebsockets/lws-x509.h">./include/libwebsockets/lws-x509.h</a>|Apis for X.509 Certificate loading, parsing, and stack verification, plus JWK key extraction from PEM X.509 certificate / private key|</p>

<p>Unit tests for these apis, which serve as usage examples, can be found in <a href="https://libwebsockets.org/git/libwebsockets/tree/minimal-examples/api-tests/api-test-gencrypto">./minimal-examples/api-tests/api-test-gencrypto</a></p>

<h3>Keys in the generic layer</h3>

<p>The necessary types and defines are brought in by <code>libwebsockets.h</code>.</p>

<p>Keys are represented only by an array of <code>struct lws_jwk_elements</code>... the
length of the array is defined by the cipher... it's one of</p>

<p>|key elements count|definition|
|---|---|
|<code>LWS_COUNT_OCT_KEY_ELEMENTS</code>|1|
|<code>LWS_COUNT_RSA_KEY_ELEMENTS</code>|8|
|<code>LWS_COUNT_EC_KEY_ELEMENTS</code>|4|
|<code>LWS_COUNT_AES_KEY_ELEMENTS</code>|1|</p>

<p><code>struct lws_jwk_elements</code> is a simple pointer / length combination used to
store arbitrary octets that make up the key element's binary representation.</p>

<h2>Using the JOSE layer</h2>

<p>The JOSE (JWK / JWS / JWE) stuff is a crypto-agile JSON-based layer
that uses the gencrypto support underneath.</p>

<p>"Crypto Agility" means the JSON structs include information about the
algorithms and ciphers used in that particular object, making it easy to
upgrade system crypto strength or cycle keys over time while supporting a
transitional period where the old and new keys or algorithms + ciphers
are also valid.</p>

<p>Uniquely lws generic support means the JOSE stuff also has "tls library
agility", code written to the lws generic or JOSE apis is completely unchanged
even if the underlying tls library changes between OpenSSL and mbedtls, meaning
sharing code between server and client sides is painless.</p>

<p>All the necessary includes are part of <code>libwebsockets.h</code>.</p>

<p>Enable <code>-DLWS_WITH_JOSE=1</code> at CMake.</p>

<p>|api|header|Functionality|
|---|---|---|
|JOSE|<a href="https://libwebsockets.org/git/libwebsockets/tree/include/libwebsockets/lws-jose.h">./include/libwebsockets/lws-jose.h</a>|Provides crypto agility for JWS / JWE|
|JWE|<a href="https://libwebsockets.org/git/libwebsockets/tree/include/libwebsockets/lws-jwe.h">./include/libwebsockets/lws-jwe.h</a>|Provides Encryption and Decryption services for RFC7516 JWE JSON|
|JWS|<a href="https://libwebsockets.org/git/libwebsockets/tree/include/libwebsockets/lws-jws.h">./include/libwebsockets/lws-jws.h</a>|Provides signature and verifcation services for RFC7515 JWS JSON|
|JWK|<a href="https://libwebsockets.org/git/libwebsockets/tree/include/libwebsockets/lws-jwk.h">./include/libwebsockets/lws-jwk.h</a>|Provides signature and verifcation services for RFC7517 JWK JSON, both "keys" arrays and singletons|</p>

<p>Minimal examples are provided in the form of commandline tools for JWK / JWS / JWE / x509 handling:</p>

<ul>
<li><a href="https://libwebsockets.org/git/libwebsockets/tree/minimal-examples/crypto/minimal-crypto-jwk">JWK minimal example</a></li>
<li><a href="https://libwebsockets.org/git/libwebsockets/tree/minimal-examples/crypto/minimal-crypto-jws">JWS minimal example</a></li>
<li><a href="https://libwebsockets.org/git/libwebsockets/tree/minimal-examples/crypto/minimal-crypto-jwe">JWE minimal example</a></li>
<li><a href="https://libwebsockets.org/git/libwebsockets/tree/minimal-examples/crypto/minimal-crypto-x509">X509 minimal example</a></li>
</ul>

<p>Unit tests for these apis, which serve as usage examples, can be found in <a href="https://libwebsockets.org/git/libwebsockets/tree/minimal-examples/api-tests/api-test-jose">./minimal-examples/api-tests/api-test-jose</a></p>

<h2>Crypto supported in the JOSE layer</h2>

<p>The JOSE RFCs define specific short names for different algorithms</p>

<h3>JWS</h3>

<p>|JSOE name|Hash|Signature|
---|---|---
|RS256, RS384, RS512|SHA256/384/512|RSA
|ES256, ES384, ES521|SHA256/384/512|EC</p>

<h3>JWE</h3>

<p>|Key Encryption|Payload authentication + crypt|
|---|---|
|<code>RSAES-PKCS1-v1.5</code> 2048b &amp; 4096b|<code>AES_128_CBC_HMAC_SHA_256</code>|
|<code>RSAES-PKCS1-v1.5</code> 2048b|<code>AES_192_CBC_HMAC_SHA_384</code>|
|<code>RSAES-PKCS1-v1.5</code> 2048b|<code>AES_256_CBC_HMAC_SHA_512</code>|
|<code>RSAES-OAEP</code>|<code>AES_256_GCM</code>|
|<code>AES128KW</code>, <code>AES192KW</code>, <code>AES256KW</code>|<code>AES_128_CBC_HMAC_SHA_256</code>|
|<code>AES128KW</code>, <code>AES192KW</code>, <code>AES256KW</code>|<code>AES_192_CBC_HMAC_SHA_384</code>|
|<code>AES128KW</code>, <code>AES192KW</code>, <code>AES256KW</code>|<code>AES_256_CBC_HMAC_SHA_512</code>|
|<code>ECDH-ES</code> (P-256/384/521 key)|<code>AES_128/192/256_GCM</code>|
|<code>ECDH-ES+A128/192/256KW</code> (P-256/384/521 key)|<code>AES_128/192/256_GCM</code>|</p>

<h3>Keys in the JOSE layer</h3>

<p>Keys in the JOSE layer use a <code>struct lws_jwk</code>, this contains two arrays of
<code>struct lws_jwk_elements</code> sized for the worst case (currently RSA).  One
array contains the key elements as described for the generic case, and the
other contains various nonencrypted key metadata taken from JWK JSON.</p>

<p>|metadata index|function|
|---|---|
|<code>JWK_META_KTY</code>|Key type, eg, "EC"|
|<code>JWK_META_KID</code>|Arbitrary ID string|
|<code>JWK_META_USE</code>|What the public key may be used to validate, "enc" or "sig"|
|<code>JWK_META_KEY_OPS</code>|Which operations the key is authorized for, eg, "encrypt"|
|<code>JWK_META_X5C</code>|Optional X.509 cert version of the key|
|<code>JWK_META_ALG</code>|Optional overall crypto algorithm the key is intended for use with|</p>

<p><code>lws_jwk_destroy()</code> should be called when the jwk is going out of scope... this
takes care to zero down any key element data in the jwk.</p>

<h1>ESP32 Support</h1>

<p>See \ref esp32 for details on how to build lws as a component in an ESP-IDF project.</p>

<p>Lws provides a "factory" application</p>

<p>https://github.com/warmcat/lws-esp32-factory</p>

<p>and a test application which implements the generic lws server test apps</p>

<p>https://github.com/warmcat/lws-esp32-test-server-demos</p>

<p>The behaviours of the generic factory are are quite rich, and cover uploading SSL certs through factory and user configuration, AP selection and passphrase entry, and managing a switch to allow the user to force entry to user setup mode at boot subsequently.</p>

<p>The factory app comes with partitioning for a 1MB factory partition containing that app and data, and a single 2.9MB OTA partition containing the main app.</p>

<p>The factory app is able to do OTA updates for both the factory and OTA partition slots; updating the factory slot first writes the new image to the OTA slot and copies it into place at the next boot, after which the user can reload the OTA slot.</p>

<p>State|Image|AP SSID|Port|URL|Mode
---|---|---|---|---|---
Factory Reset or Uninitialized|Factory|AP: ESP_012345|80|http://192.168.4.1|factory.html - to set certificates and serial
User configuration|Factory|AP: config-model-serial|443|https://192.168.4.1|index.html - user set up his AP information
Operation|OTA|Station only|443|https://model-serial.local|OTA application</p>

<h2>Basic Auth</h2>

<p>The lws-esp32-test-server-demos app also demos basic auth.</p>

<p>On a normal platform this is done by binding a mount to a text file somewhere in the filesystem, which
contains user:password information one per line.</p>

<p>On ESP32 there is not necessarily any generic VFS in use.  So instead, the basic auth lookup is bound to
a given nvs domain, where the username is the key and the password the value.  main/main.c in the test
demos app shows how to both make the mount use basic auth, and how to set a user:password combination
using nvs.</p>

<h1>Notes about generic-sessions Plugin</h1>

<p>@section gseb Enabling lwsgs for build</p>

<p>Enable at CMake with -DLWS<em>WITH</em>GENERIC_SESSIONS=1</p>

<p>This also needs sqlite3 (libsqlite3-dev or similar package)</p>

<p>@section gsi lwsgs Introduction</p>

<p>The generic-sessions protocol plugin provides cookie-based login
authentication for lws web and ws connections.</p>

<p>The plugin handles everything about generic account registration,
email verification, lost password, account deletion, and other generic account
management.</p>

<p>Other code, in another eg, ws protocol handler, only needs very high-level
state information from generic-sessions, ie, which user the client is
authenticated as.  Everything underneath is managed in generic-sessions.</p>

<ul>
<li><p>random 20-byte session id managed in a cookie</p></li>
<li><p>all information related to the session held at the server, nothing managed clientside</p></li>
<li><p>sqlite3 used at the server to manage active sessions and users</p></li>
<li><p>defaults to creating anonymous sessions with no user associated</p></li>
<li><p>admin account (with user-selectable username) is defined in config with a SHA-1 of the password; rest of the accounts are in sqlite3</p></li>
<li><p>user account passwords stored as salted SHA-1 with additional confounder
only stored in the JSON config, not the database </p></li>
<li><p>login, logout, register account + email verification built-in with examples</p></li>
<li><p>in a mount, some file suffixes (ie, .js) can be associated with a protocol for the purposes of rewriting symbolnames.  These are read-only copies of logged-in server state.</p></li>
<li><p>When your page fetches .js or other rewritten files from that mount, "$lwsgs_user" and so on are rewritten on the fly using chunked transfer encoding</p></li>
<li><p>Eliminates server-side scripting with a few rewritten symbols and
javascript on client side</p></li>
<li><p>32-bit bitfield for authentication sectoring, mounts can provide a mask on the loggin-in session's associated server-side bitfield that must be set for access.</p></li>
<li><p>No code (just config) required for, eg, private URL namespace that requires login to access. </p></li>
</ul>

<p>@section gsin Lwsgs Integration to HTML</p>

<p>Only three steps are needed to integrate lwsgs in your HTML.</p>

<p>1) lwsgs HTML UI is bundled with the javascript it uses in <code>lwsgs.js</code>, so
import that script file in your head section</p>

<p>2) define an empty div of id "lwsgs" somewhere</p>

<p>3) Call lwsgs_initial() in your page</p>

<p>That's it.  An example is below</p>

<p>```
    <html>
     <head>
      <script src="lwsgs.js"></script>
      <style>
         .body { font-size: 12 }
         .gstitle { font-size: 18 }
      </style>
      </head>
      <body style="background-image:url(seats.jpg)">
        <table style="width:100%;transition: max-height 2s;">
         <tr>
          <td style="vertical-align:top;text-align:left;width=200px">
           <img src="lwsgs-logo.png">
          </td>
          <td style="vertical-align:top;float:right">
        <div id=lwsgs style="text-align:right;background-color: rgba(255, 255, 255, 0.8);"></div>
          </td>
         </tr>
        </table>
       </form></p>

<pre><code>   &lt;script&gt;lwsgs_initial();&lt;/script&gt;

 &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>```</p>

<p>@section gsof Lwsgs Overall Flow@</p>

<p>When the protocol is initialized, it gets per-vhost information from the config, such
as where the sqlite3 databases are to be stored.  The admin username and sha-1 of the
admin password are also taken from here.</p>

<p>In the mounts using protocol-generic-sessions, a cookie is maintained against any requests; if no cookie was active on the initial request a new session is
created with no attached user.</p>

<p>So there should always be an active session after any transactions with the server.</p>

<p>In the example html going to the mount /lwsgs loads a login / register page as the default.</p>

<p>The <form> in the login page contains 'next url' hidden inputs that let the html 'program' where the form handler will go after a successful admin login, a successful user login and a failed login.</p>

<p>After a successful login, the sqlite record at the server for the current session is updated to have the logged-in username associated with it. </p>

<p>@section gsconf Lwsgs Configuration</p>

<p>"auth-mask" defines the authorization sector bits that must be enabled on the session to gain access.</p>

<p>"auth-mask" 0 is the default.</p>

<ul>
<li>b0 is set if you are logged in as a user at all.</li>
<li>b1 is set if you are logged in with the user configured to be admin</li>
<li>b2 is set if the account has been verified (the account configured for admin is always verified)</li>
<li>b3 is set if your session just did the forgot password flow successfully</li>
</ul>

<p><code>
          {
            # things in here can always be served
            "mountpoint": "/lwsgs",
            "origin": "file:///usr/share/libwebsockets-test-server/generic-sessions",
            "origin": "callback://protocol-lws-messageboard",
            "default": "generic-sessions-login-example.html",
            "auth-mask": "0",
            "interpret": {
                    ".js": "protocol-lws-messageboard"
            }
           }, {
            # things in here can only be served if logged in as a user
            "mountpoint": "/lwsgs/needauth",
            "origin": "file:///usr/share/libwebsockets-test-server/generic-sessions/needauth",
            "origin": "callback://protocol-lws-messageboard",
            "default": "generic-sessions-login-example.html",
            "auth-mask": "5", # logged in as a verified user
            "interpret": {
                    ".js": "protocol-lws-messageboard"
            }
           }, {
            # things in here can only be served if logged in as admin
            "mountpoint": "/lwsgs/needadmin",
            "origin": "file:///usr/share/libwebsockets-test-server/generic-sessions/needadmin",
            "origin": "callback://protocol-lws-messageboard",
            "default": "generic-sessions-login-example.html",
            "auth-mask": "7", # b2 = verified (by email / or admin), b1 = admin, b0 = logged in with any user name
            "interpret": {
                    ".js": "protocol-lws-messageboard"
            }
           }
</code>
Note that the name of the real application protocol that uses generic-sessions
is used, not generic-sessions itself. </p>

<p>The vhost configures the storage dir, admin credentials and session cookie lifetimes:</p>

<p>```
         "ws-protocols": [{
           "protocol-generic-sessions": {
             "status": "ok",
             "admin-user": "admin",</p>

<pre><code># create the pw hash like this (for the example pw, "jipdocesExunt" )
# $ echo -n "jipdocesExunt" | sha1sum
# 046ce9a9cca769e85798133be06ef30c9c0122c9 -
#
# Obviously ** change this password hash to a secret one before deploying **
#
         "admin-password-sha1": "046ce9a9cca769e85798133be06ef30c9c0122c9",
         "session-db": "/var/www/sessions/lws.sqlite3",
         "timeout-idle-secs": "600",
     "timeout-anon-idle-secs": "1200",
         "timeout-absolute-secs": "6000",
# the confounder is part of the salted password hashes.  If this config
# file is in a 0700 root:root dir, an attacker with apache credentials
# will have to get the confounder out of the process image to even try
# to guess the password hashes.
         "confounder": "Change to &lt;=31 chars of junk",

         "email-from": "noreply@example.com",
         "email-smtp-ip": "127.0.0.1",
         "email-expire": "3600",
         "email-helo": "myhost.com",
         "email-contact-person": "Set Me &lt;real-person@email.com&gt;",
         "email-confirm-url-base": "http://localhost:7681/lwsgs"
       }
</code></pre>

<p>```</p>

<p>The email- related settings control generation of automatic emails for
registration and forgotten password.</p>

<ul>
<li><p><code>email-from</code>: The email address automatic emails are sent from</p></li>
<li><p><code>email-smtp-ip</code>: Normally 127.0.0.1, if you have a suitable server on port
25 on your lan you can use this instead here.</p></li>
<li><p><code>email-expire</code>: Seconds that links sent in email will work before being
deleted</p></li>
<li><p><code>email-helo</code>: HELO to use when communicating with your SMTP server</p></li>
<li><p><code>email-contact-person</code>: mentioned in the automatic emails as a human who can
answer questions</p></li>
<li><p><code>email-confirm-url-base</code>: the URL to start links with in the emails, so the
recipient can get back to the web server</p></li>
</ul>

<p>The real protocol that makes use of generic-sessions must also be listed and
any configuration it needs given</p>

<p><code>
           "protocol-lws-messageboard": {
             "status": "ok",
             "message-db": "/var/www/sessions/messageboard.sqlite3"
           },
</code></p>

<p>Notice the real application uses his own sqlite db, no details about how
generic-sessions works or how it stores data are available to it.</p>

<p>@section gspwc Lwsgs Password Confounder</p>

<p>You can also define a per-vhost confounder shown in the example above, used
when aggregating the password with the salt when it is hashed.  Any attacker
will also need to get the confounder along with the database, which you can
make harder by making the config dir only eneterable / readable by root.</p>

<p>@section gsprep Lwsgs Preparing the db directory</p>

<p>You will have to prepare the db directory so it's suitable for the lwsws user to use,
that usually means apache, eg</p>

<p><code>
    # mkdir -p /var/www/sessions
    # chown root:apache /var/www/sessions
    # chmod 770 /var/www/sessions
</code></p>

<p>@section gsrmail Lwsgs Email configuration</p>

<p>lwsgs will can send emails by talking to an SMTP server on localhost:25.  That
will usually be sendmail or postfix, you should confirm that works first by
itself using the <code>mail</code> application to send on it.</p>

<p>lwsgs has been tested on stock Fedora sendmail and postfix.</p>

<p>@section gsap Lwsgs Integration with another protocol</p>

<p>lwsgs is designed to provide sessions and accounts in a standalone and generic way.</p>

<p>But it's not useful by itself, there will always be the actual application who wants
to make use of generic-sessions features.</p>

<p>We provide the "messageboard" plugin as an example of how to integrate with
your actual application protocol.</p>

<p>The basic approach is the 'real' protocol handler (usually a plugin itself)
subclasses the generic-sessions plugin and calls through to it by default.</p>

<p>The "real" protocol handler entirely deals with ws-related stuff itself, since
generic-sessions does not use ws.  But for</p>

<ul>
<li>LWS<em>CALLBACK</em>HTTP</li>
<li>LWS<em>CALLBACK</em>HTTP_BODY</li>
<li>LWS<em>CALLBACK</em>HTTP<em>BODY</em>COMPLETION</li>
<li>LWS<em>CALLBACK</em>HTTP<em>DROP</em>PROTOCOL</li>
</ul>

<p>the "real" protocol handler checks if it recognizes the activity (eg, his own
POST form URL) and if not, passes stuff through to the generic-sessions protocol callback to handle it.  To simplify matters the real protocol can just pass
through any unhandled messages to generic-sessions.</p>

<p>The "real" protocol can get a pointer to generic-sessions protocol on the
same vhost using</p>

<p><code>
    vhd-&gt;gsp = lws_vhost_name_to_protocol(vhd-&gt;vh, "protocol-generic-sessions");
</code></p>

<p>The "real" protocol must also arrange generic-sessions per<em>session</em>data in his
own per-session allocation.  To allow keeping generic-sessions opaque, the
real protocol must allocate that space at runtime, using the pss size
the generic-sessions protocol struct exposes</p>

<p>```
    struct per<em>session</em>data<em>_myapp {
        void *pss</em>gs;
    ...</p>

<pre><code>    pss-&gt;pss_gs = malloc(vhd-&gt;gsp-&gt;per_session_data_size);
</code></pre>

<p>```</p>

<p>The allocation reserved for generic-sessions is then used as user_space when
the real protocol calls through to the generic-sessions callback</p>

<p><code>
    vhd-&gt;gsp-&gt;callback(wsi, reason, &amp;pss-&gt;pss_gs, in, len);
</code></p>

<p>In that way the "real" protocol can subclass generic-sessions functionality.</p>

<p>To ease management of these secondary allocations, there are callbacks that
occur when a wsi binds to a protocol and when the binding is dropped.  These
should be used to malloc and free and kind of per-connection
secondary allocations.</p>

<p>```
    case LWS<em>CALLBACK</em>HTTP<em>BIND</em>PROTOCOL:
        if (!pss || pss->pss_gs)
            break;</p>

<pre><code>    pss-&gt;pss_gs = malloc(vhd-&gt;gsp-&gt;per_session_data_size);
    if (!pss-&gt;pss_gs)
        return -1;

    memset(pss-&gt;pss_gs, 0, vhd-&gt;gsp-&gt;per_session_data_size);
    break;

case LWS_CALLBACK_HTTP_DROP_PROTOCOL:
    if (vhd-&gt;gsp-&gt;callback(wsi, reason, pss ? pss-&gt;pss_gs : NULL, in, len))
        return -1;

    if (pss-&gt;pss_gs) {
        free(pss-&gt;pss_gs);
        pss-&gt;pss_gs = NULL;
    }
    break;
</code></pre>

<p>```</p>

<h1>section gsapsib Getting session-specific information from another protocol</h1>

<p>At least at the time when someone tries to upgrade an http(s) connection to
ws(s) with your real protocol, it is necessary to confirm the cookie the http(s)
connection has with generic-sessions and find out his username and other info.</p>

<p>Generic sessions lets another protocol check it again by calling his callback,
and lws itself provides a generic session info struct to pass the related data</p>

<p>```
    struct lws<em>session</em>info {
        char username[32];
        char email[100];
        char ip[72];
        unsigned int mask;
        char session[42];
    };</p>

<pre><code>struct lws_session_info sinfo;
...
vhd-&gt;gsp-&gt;callback(wsi, LWS_CALLBACK_SESSION_INFO,
               &amp;pss-&gt;pss_gs, &amp;sinfo, 0);
</code></pre>

<p>```</p>

<p>After the call to generic-sessions, the results can be</p>

<ul>
<li><p>all the strings will be zero-length and .mask zero, there is no usable cookie</p>

<ul>
<li><p>only .ip and .session are set: the cookie is OK but no user logged in</p></li>
<li><p>all the strings contain information about the logged-in user</p></li>
</ul></li>
</ul>

<p>the real protocol can use this to reject attempts to open ws connections from
http connections that are not authenticated; afterwards there's no need to
check the ws connection auth status again.</p>

<h1>Notes about generic-table</h1>

<p>@section gtint What is generic-table?</p>

<p>Generic-table is a JSON schema and client-side JS file that makes it easy to
display live, table structured HTML over a ws link.</p>

<p>An example plugin and index.html using it are provided, but lwsgt itself doesn't
have its own plugin, it's just a JSON schema and client-side JS that other
plugins can use to simplify displaying live, table-based data without having
to reinvent the wheel each time.</p>

<p>The ws protocol sends JSON describing the table, and then JSON updating the table
contents when it chooses, the brower table is updated automatically, live.</p>

<p>\image html lwsgt-overview.png</p>

<ul>
<li><p>Example protocol plugin (displays directory contents): https://github.com/warmcat/libwebsockets/tree/master/plugins/generic-table/protocol<em>table</em>dirlisting.c</p></li>
<li><p>Example HTML: https://github.com/warmcat/libwebsockets/tree/master/plugins/generic-table/assets/index.html</p></li>
<li><p>lwsgt.js (client-side table rendering / ws link management): https://github.com/warmcat/libwebsockets/tree/master/plugins/generic-table/assets/lwsgt.js</p></li>
</ul>

<p>@section gteb Enabling for build</p>

<p>Enable the demo plugin at CMake with -DLWS<em>WITH</em>PLUGINS=1</p>

<p>@section gtinth Integrating with your html</p>

<ul>
<li>In your HEAD section, include lwsgt.js</li>
</ul>

<p><code>
    &lt;script src="lwsgt.js"&gt;&lt;/script&gt;
</code></p>

<ul>
<li>Also in your HEAD section, style the lwsgt CSS, eg</li>
</ul>

<p><code>
    &lt;style&gt;
    .lwsgt_title { font-size: 24; text-align:center }
    .lwsgt_breadcrumbs { font-size: 18; text-align:left }
    .lwsgt_table { font-size: 14; padding:12px; margin: 12px; align:center }
    .lwsgt_hdr { font-size: 18; text-align:center;
             background-color: rgba(40, 40, 40, 0.8); color: white }
    .lwsgt_tr { padding: 10px  }
    .lwsgt_td { padding: 3px  }
    &lt;/style&gt;
</code></p>

<p>You can skip this but the result will be less beautiful until some CSS is
provided.</p>

<ul>
<li>In your body section, declare a div with an id (can be whatever you want)</li>
</ul>

<p><code>
    &lt;tr&gt;&lt;td&gt;&lt;div id="lwsgt1" class="group1"&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;
</code></p>

<p>lwsgt JS will put its content there.</p>

<ul>
<li>Finally in a <script> at the end of your page, instantiate lwsgt and
provide a custom callback for clickable links</li>
</ul>

<p>```
    <script>
    var v1 = new lwsgt<em>initial("Dir listing demo",
                   "protocol-lws-table-dirlisting",
                   "lwsgt1", "lwsgt</em>dir_click", "v1");</p>

<pre><code>function lwsgt_dir_click(gt, u, col, row)
{
    if (u[0] == '=') { /* change directory */
        window[gt].lwsgt_ws.send(u.substring(1, u.length));
        return;
    }
    var win = window.open(u, '_blank');
    win.focus();
}

&lt;/script&gt;
</code></pre>

<p>```</p>

<p>In the callback, you can recover the ws object by <code>window[gt].lwsgt_ws</code>.</p>

<p>@section gtc Lwsgt constructor</p>

<p>To instantiate the ws link and lwsgt instance, your HTML must call a lwsgt
constructor for each region on the page managed by lwsgt.</p>

<p><code>var myvar = new lwsgt_initial(title, ws_protocol, div_id, click_cb, myvar);</code></p>

<p>All of the arguments are strings.</p>

<p>| Parameter       | Description                                             |
|-----------------|---------------------------------------------------------|
| title           | Title string to go above the table                      |
| ws<em>protocol     | Protocol name string to use when making ws connection   |
| div</em>id          | HTML id of div to fill with content                     |
| click_cb        | Callback function name string to handle clickable links |
| myvar           | Name of var used to hold this instantiation globally    |</p>

<p>Note "myvar" is needed so it can be passed to the click handling callback.</p>

<p>@section gtclick Lwsgt click handling function</p>

<p>When a clickable link produced by lwsgt is clicked, the function named in the
click<em>cb parameter to lwsgt</em>initial is called.</p>

<p>That function is expected to take four parameters, eg</p>

<p><code>function lwsgt_dir_click(gt, u, col, row)</code></p>

<p>| Parameter | Description                                               |
|------- ---|-----------------------------------------------------------|
| gt        | Name of global var holding this lwsgt context (ie, myvar) |
| u         | Link "url" string                                         |
| col       | Table column number link is from                          |
| row       | Table row number link is from                             |</p>

<p>@section gtgj Generic-table JSON</p>

<h3>Column layout</h3>

<p>When the ws connection is established, the protocol should send a JSON message
describing the table columns.  For example</p>

<p><code>
      "cols": [
        { "name": "Date" },
        { "name": "Size", "align": "right" },
        { "name": "Icon" },
        { "name": "Name", "href": "uri"},
        { "name": "uri", "hide": "1" }
        ]
      }
</code></p>

<ul>
<li><p>This describes 5 columns</p></li>
<li><p>Only four columns (not "uri") should be visible</p></li>
<li><p>"Name" should be presented as a clickable link using "uri" as the
destination, when a "uri" field is presented.</p></li>
<li><p>"Size" field should be presented aligned to the right</p>

<h3>Breadcrumbs</h3>

<p>When a view is hierarchical, it's useful to provide a "path" with links back
in the "path", known as "breadcrumbs".</p>

<p>Elements before the last one should provide a "url" member as well as the
displayable name, which is used to create the link destination.</p>

<p>The last element, being the current displayed page should not have a url
member and be displayed without link style.</p>

<p><code>
"breadcrumbs":[{"name":"top", "url": "/" }, {"name":"mydir"}]
</code></p>

<h3>Table data</h3>

<p>The actual file data consists of an array of rows, containing the columns
mentioned in the original "cols" section.</p>

<p>```
"data":[
    {
     "Icon":" ",
     "Date":"2015-Feb-06 03:08:35 +0000",
     "Size":"1406",
     "uri":"./serve//favicon.ico",
     "Name":"favicon.ico"
    }
]</p>

<p>```</p>

<p>@section gtdirl Setting up protocol-lws-table-dirlisting</p>

<p>The example protocol needs two mounts, one to provide the index.html, js and
the protocol itself</p>

<p><code>
{
 "mountpoint": "/dirtest",
     "origin": "file:///usr/share/libwebsockets-test-server/generic-table",
 "origin": "callback://protocol-lws-table-dirlisting",
 "default": "index.html",
 "pmo": [{
    "dir": "/usr/share/libwebsockets-test-server"
 }]
},
</code></p></li>
</ul>

<p>The protocol wants a per-mount option (PMO) to tell it the base directory it
is serving from, named "dir".</p>

<p>The other mount is there to simply serve items that get clicked on from the
table in a secure way</p>

<p><code>
    {
     "mountpoint": "/dirtest/serve",
         "origin": "file:///usr/share/libwebsockets-test-server",
     "default": "index.html"
    },
</code></p>

<p>This last bit is not related to using lwsgt itself.</p>

<h1>Http fallback and raw proxying</h1>

<p>Lws has several interesting options and features that can be applied to get
some special behaviours... this article discusses them and how they work.</p>

<h2>Overview of normal vhost selection</h2>

<p>Lws supports multiple http or https vhosts sharing a listening socket on the
same port.</p>

<p>For unencrypted http, the Host: header is used to select which vhost the
connection should bind to, by comparing what is given there against the
names the server was configured with for the various vhosts.  If no match, it
selects the first configured vhost.</p>

<p>For TLS, it has an extension called SNI (Server Name Indication) which tells
the server early in the TLS handshake the host name the connection is aimed at.
That allows lws to select the vhost early, and use vhost-specific TLS certs
so everything is happy.  Again, if there is no match the connection proceeds
using the first configured vhost and its certs.</p>

<h2>Http(s) fallback options</h2>

<p>What happens if you try to connect, eg, an ssh client to the http server port
(this is not an idle question...)?  Obviously the http server part or the tls
part of lws will fail the connection and close it.  (We will look at that flow
in a moment in detail for both unencrypted and tls listeners.)</p>

<p>However if the first configured vhost for the port was created with the
vhost creation info struct <code>.options</code> flag <code>LWS_SERVER_OPTION_FALLBACK_TO_APPLY_LISTEN_ACCEPT_CONFIG</code>,
then instead of the error, the connection transitions to whatever role was
given in the vhost creation info struct <code>.listen_accept_role</code> and <code>.listen_accept_protocol</code>.</p>

<p>With lejp-conf / lwsws, the options can be applied to the first vhost using:</p>

<p><code>
   "listen-accept-role": "the-role-name",
   "listen-accept-protocol": "the-protocol-name",
   "fallback-listen-accept": "1"
</code></p>

<p>See <code>./minimal-examples/raw/minimal-raw-fallback-http-server</code> for examples of
all the options in use via commandline flags.</p>

<p>So long as the first packet for the protocol doesn't look like GET, POST, or
a valid tls packet if connection to an https vhost, this allows the one listen
socket to handle both http(s) and a second protocol, as we will see, like ssh.</p>

<p>Notice there is a restriction that no vhost selection processing is possible,
neither for tls listeners nor plain http ones... the packet belonging to a
different protocol will not send any Host: header nor tls SNI.</p>

<p>Therefore although the flags and settings are applied to the first configured
vhost, actually their effect is global for a given listen port.  If enabled,
all vhosts on the same listen port will do the fallback action.</p>

<h3>Plain http flow</h3>

<p><img src="/doc-assets/accept-flow-1.svg" alt="plain http flow" title="" /></p>

<p>Normally, if the first received packet does not contain a valid HTTP method,
then the connection is dropped.  Which is what you want from an http server.</p>

<p>However if enabled, the connection can transition to the defined secondary
role / protocol.</p>

<p>|Flag|lejp-conf / lwsws|Function|
|---|---|---|
|<code>LWS_SERVER_OPTION_FALLBACK_TO_APPLY_LISTEN_ACCEPT_CONFIG</code>|<code>"fallback-listen-accept": "1"</code>|Enable fallback processing|</p>

<h3>TLS https flow</h3>

<p><img src="/doc-assets/accept-flow-2.svg" alt="tls https flow" title="" /></p>

<p>If the port is listening with tls, the point that a packet from a different
protocol will fail is earlier, when the tls tunnel is being set up.</p>

<p>|Flag|lejp-conf / lwsws|Function|
|---|---|---|
|<code>LWS_SERVER_OPTION_FALLBACK_TO_APPLY_LISTEN_ACCEPT_CONFIG</code>|<code>"fallback-listen-accept": "1"</code>|Enable fallback processing|
|<code>LWS_SERVER_OPTION_REDIRECT_HTTP_TO_HTTPS</code>|<code>"redirect-http": "1"</code>|Treat invalid tls packet as http, issue http redirect to https://|
|<code>LWS_SERVER_OPTION_ALLOW_HTTP_ON_HTTPS_LISTENER</code>|<code>"allow-http-on-https": "1"</code>|Accept unencrypted http connections on this tls port (dangerous)|</p>

<p>The latter two options are higher priority than, and defeat, the first one.</p>

<h3>Non-http listener</h3>

<p><img src="/doc-assets/accept-flow-3.svg" alt="non-http flow" title="" /></p>

<p>It's also possible to skip the fallback processing and just force the first
vhost on the port to use the specified role and protocol in the first place.</p>

<p>|Flag|lejp-conf / lwsws|Function|
|---|---|---|
|LWS<em>SERVER</em>OPTION<em>ADOPT</em>APPLY<em>LISTEN</em>ACCEPT_CONFIG|<code>"apply-listen-accept": "1"</code>|Force vhost to use listen-accept-role / listen-accept-protocol|</p>

<h2>Using http(s) fallback with raw-proxy</h2>

<p>If enabled for build with <code>cmake .. -DLWS_ROLE_RAW_PROXY=1 -DLWS_WITH_PLUGINS=1</code>
then lws includes ready-to-use support for raw tcp proxying.</p>

<p>This can be used standalone on the first vhost on a port, but most intriguingly
it can be specified as the fallback for http(s)...</p>

<p>See <code>./minimal-examples/raw/minimal-raw-proxy-fallback.c</code> for a working example.</p>

<h3>fallback with raw-proxy in code</h3>

<p>On the first vhost for the port, specify the required "onward" pvo to configure
the raw-proxy protocol...you can adjust the "ipv4:127.0.0.1:22" to whatever you
want...</p>

<p>```
    static struct lws<em>protocol</em>vhost_options pvo1 = {
            NULL,
            NULL,
            "onward",       /* pvo name <em>/
            "ipv4:127.0.0.1:22" /</em> pvo value */
    };</p>

<pre><code>static const struct lws_protocol_vhost_options pvo = {
        NULL,               /* "next" pvo linked-list */
        &amp;pvo1,          /* "child" pvo linked-list */
        "raw-proxy",        /* protocol name we belong to on this vhost */
        ""                  /* ignored */
};
</code></pre>

<p>```</p>

<p>... and set up the fallback enable and bindings...</p>

<p><code>
    info.options |= LWS_SERVER_OPTION_FALLBACK_TO_APPLY_LISTEN_ACCEPT_CONFIG;
    info.listen_accept_role = "raw_proxy";
    info.listen_accept_proxy = "raw_proxy";
    info.pvo = &amp;pvo;
</code></p>

<h3>fallback with raw-proxy in JSON conf</h3>

<p>On the first vhost for the port, enable the raw-proxy protocol on the vhost and
set the pvo config</p>

<p><code>
                "ws-protocols": [{
                        "raw-proxy": {
                         "status": "ok",
                         "onward": "ipv4:127.0.0.1:22"
                        }
                 }],
</code></p>

<p>Enable the fallback behaviour on the vhost and the role / protocol binding</p>

<p><code>
    "listen-accept-role": "raw-proxy",
    "listen-accept-protocol": "raw-proxy",
    "fallback-listen-accept": "1"
</code></p>

<h3>Testing</h3>

<p>With this configured, the listen port will function normally for http or https
depending on how it was set up.</p>

<p>But if you try to connect to it with an ssh client, that will also work fine.</p>

<p>The libwebsockets.org server is set up in this way, you can confirm it by
visiting <code>https://libwebsockets.org</code> on port 443 as usual, but also trying
<code>ssh -p 443 invalid@libwebsockets.org</code>... you will get permission denied from
your ssh client.  With valid credentials in fact that works perfectly for
ssh, scp, git-over-ssh etc all on port 443...</p>

<h1>lws_dll Doubly-linked list</h1>

<h2>Introduction</h2>

<p>Lws supports two kinds of doubly-linked list, <code>lws_dll</code> and <code>lws_dll2</code>.</p>

<p>Unless memory is at a big premium, or it has to work on lws &lt; v3.2, it's
best to simply use <code>lws_dll2</code>.</p>

<p><img src="../doc-assets/lws_dll.svg" alt="lws_dll overview" title="" /></p>

<h2>How to use</h2>

<p>The basics are the same for lws<em>dll and lws</em>dll2.</p>

<p>The list objects point only to themselves, and you use the <code>lws_container_of</code>
macro to get a pointer to your struct that contains the list object.  Doing
it this way</p>

<ul>
<li><p>the list object does not have to be the first thing in your struct</p></li>
<li><p>your struct can contain multiple list objects and appear on lists belonging
to multiple owners simultaenously,</p></li>
</ul>

<h3>lws_dll Minimal example</h3>

<p>```
struct mystruct {
    ....
    lws_dll list;
    ...
};</p>

<p>lws_dll owner;
```</p>

<p>Adding a mystruct to the owner list (...add_tail() works the same way but adds
to the other end of the list)</p>

<p>```
    struct mystruct *p;</p>

<pre><code>...

lws_dll_add_head(&amp;p-&gt;list, &amp;owner);
</code></pre>

<p>```</p>

<p>Removing the list object from its owner</p>

<p><code>
    lws_dll2_remove(&amp;p-&gt;list, &amp;owner);
</code></p>

<p>If you have a <code>struct lws_dll *d</code> pointing to <code>list</code> in struct mystruct, you can
convert it to a <code>struct mystruct *p</code> ike this</p>

<p><code>
    struct mystruct *p = lws_container_of(d, struct lws_dll, list);
</code></p>

<h3>lws_dll2 Minimal example</h3>

<p>```
struct mystruct {
    ....
    lws_dll2 list;
    ...
};</p>

<p>lws<em>dll2</em>owner owner;
```</p>

<p>Adding a mystruct to the owner list (...add_tail() works the same way but adds
to the other end of the list)</p>

<p>```
    struct mystruct *p;</p>

<pre><code>...

lws_dll2_add_head(&amp;p-&gt;list, &amp;owner);
</code></pre>

<p>```</p>

<p>Removing the list object from its owner (notice compared to lws_dll, it doesn't
need to be told the owner)</p>

<p><code>
    lws_dll2_remove(&amp;p-&gt;list);
</code></p>

<p>If you have a <code>struct lws_dll2 *d</code> pointing to <code>list</code> in struct mystruct, you
can convert it to a <code>struct mystruct *p</code> ike this</p>

<p><code>
    struct mystruct *p = lws_container_of(d, struct lws_dll2, list);
</code></p>

<h2>Summary Comparing lws<em>dll and lws</em>dll2</h2>

<ul>
<li><p>both offer a doubly-linked list object, and (since v3.2) track both the
head and tail in an "list owner" object</p></li>
<li><p>both are initalized by memsetting to 0</p></li>
<li><p>for <code>lws_dll</code>, it reuses an <code>lws_dll</code> as the "owner", for <code>lws_dll2</code>, there's a
specific <code>lws_dll2_owner</code> structure for that</p></li>
<li><p><code>lws_dll2_owner</code> also keeps count of the number of list elements</p></li>
<li><p><code>lws_dll2</code> knows which owner's list it is participating on.  So it can remove
itself and update the owner without the caller needing to know its owner.
In the case there are several potential owners list objects may be on, this
is very convenient.</p></li>
<li><p><code>lws_dll</code> is simpler and has a smaller footprint (two pointers per entry vs
three).  But you have to know the exact list owner to perform operations on
it.</p></li>
</ul>

<h2>apis</h2>

<p>|function|lws<em>dll|lws</em>dll2|
|---|---|---|
|add entry at head|<code>void lws_dll_add_head(struct lws_dll *d, struct lws_dll *phead)</code>|<code>void lws_dll2_add_head(struct lws_dll2 *d, struct lws_dll2_owner *owner)</code>|
|add entry at tail|<code>void lws_dll_add_tail(struct lws_dll *d, struct lws_dll *phead);</code>|<code>void lws_dll2_add_tail(struct lws_dll2 *d, struct lws_dll2_owner *owner)</code>|
|remove entry from its owning list|<code>void lws_dll_remove_track_tail(struct lws_dll *d, struct lws_dll *phead)</code>|<code>void lws_dll2_add_tail(struct lws_dll2 *d, struct lws_dll2_owner *owner)</code>|
|get owner|(not supported)|<code>struct lws_dll2_owner * lws_dll2_owner(const struct lws_dll2 *d)</code>|
|check if item is detached from any list|<code>lws_dll_is_detached(struct lws_dll *d, struct lws_dll *phead)|int lws_dll2_is_detached(const struct lws_dll2 *d)</code>|
|iterate through items on list|<code>int lws_dll_foreach_safe(struct lws_dll *phead, void *user, int (*cb)(struct lws_dll *d, void *user))|int lws_dll2_foreach_safe(struct lws_dll2_owner *owner, void *user, int (*cb)(struct lws_dll2 *d, void *user))</code>|</p>

<h1><code>lws_sequencer_t</code> introduction</h1>

<p>Often a single network action like a client GET is just part of a
larger series of actions, perhaps involving different connections.</p>

<p>Since lws operates inside an event loop, if the outer sequencing
doesn't, it can be awkward to synchronize these steps with what's
happening on the network with a particular connection on the event
loop thread.</p>

<p><img src="/doc-assets/lws_sequencer.svg" alt="lws_sequencer" title="" /></p>

<p><code>lws_sequencer_t</code> provides a generic way to stage multi-step
operations from inside the event loop.  Because it participates
in the event loop similar to a wsi, it always operates from the
service thread context and can access structures that share the
service thread without locking.  It can also provide its own
higher-level timeout handling.</p>

<p>Naturally you can have many of them running in the same event
loop operating independently.</p>

<p>Sequencers themselves bind to a pt (per-thread) service thread,
by default there's only one of these and it's the same as saying
they bind to an <code>lws_context</code>.  The sequencer callback may create
wsi which in turn are bound to a vhost, but the sequencer itself
is above all that.</p>

<h2>Sequencer timeouts</h2>

<p>The sequencer additionally maintains its own second-resolution timeout
checked by lws for the step being sequenced... this is independent of
any lws wsi timeouts which tend to be set and reset for very short-term
timeout protection inside one transaction.</p>

<p>The sequencer timeout operates separately and above any wsi timeout, and
is typically only reset by the sequencer callback when it receives an
event indicating a step completed or failed, or it sets up the next sequence
step.</p>

<p>If the sequencer timeout expires, then the sequencer receives a queued
<code>LWSSEQ_TIMED_OUT</code> message informing it, and it can take corrective action
or schedule a retry of the step.  This message is queued and sent normally
under the service thread context and in order of receipt.</p>

<p>Unlike lws timeouts which force the wsi to close, the sequencer timeout
only sends the message.  This allows the timeout to be used to, eg, wait
out a retry cooloff period and then start the retry when the
<code>LWSSEQ_TIMED_OUT</code> is received, according to the state of the sequencer.</p>

<h2>Creating an <code>lws_sequencer_t</code></h2>

<p><code>
typedef struct lws_seq_info {
    struct lws_context      *context;   /* lws_context for seq */
    int             tsi;        /* thread service idx */
    size_t              user_size;  /* size of user alloc */
    void                **puser;    /* place ptr to user */
    lws_seq_event_cb        cb;     /* seq callback */
    const char          *name;      /* seq name */
    const lws_retry_bo_t        *retry;     /* retry policy */
} lws_seq_info_t;
</code></p>

<p><code>
lws_sequencer_t *
lws_sequencer_create(lws_seq_info_t *info);
</code></p>

<p>When created, in lws the sequencer objects are bound to a 'per-thread',
which is by default the same as to say bound to the <code>lws_context</code>.  You
can tag them with an opaque user data pointer, and they are also bound to
a user-specified callback which handles sequencer events</p>

<p><code>
typedef int (*lws_seq_event_cb)(struct lws_sequencer *seq, void *user_data,
                lws_seq_events_t event, void *data);
</code></p>

<p><code>lws_sequencer_t</code> objects are private to lws and opaque to the user.  A small
set of apis lets you perform operations on the pointer returned by the
create api.</p>

<h2>Queueing events on a sequencer</h2>

<p>Each sequencer object can be passed "events", which are held on a per-sequencer
queue and handled strictly in the order they arrived on subsequent event loops.
<code>LWSSEQ_CREATED</code> and <code>LWSSEQ_DESTROYED</code> events are produced by lws reflecting
the sequencer's lifecycle, but otherwise the event indexes have a user-defined
meaning and are queued on the sequencer by user code for eventual consumption
by user code in the sequencer callback.</p>

<p>Pending events are removed from the sequencer queues and sent to the sequencer
callback from inside the event loop at a rate of one per event loop wait.</p>

<h2>Destroying sequencers</h2>

<p><code>lws_sequencer_t</code> objects are cleaned up during context destruction if they are
still around.</p>

<p>Normally the sequencer callback receives a queued message that
informs it that it's either failed at the current step, or succeeded and that
was the last step, and requests that it should be destroyed by returning
<code>LWSSEQ_RET_DESTROY</code> from the sequencer callback.</p>

<h2>Lifecycle considerations</h2>

<p>Sequencers may spawn additional assets like client wsi as part of the sequenced
actions... the lifecycle of the sequencer and the assets overlap but do not
necessarily depend on each other... that is a wsi created by the sequencer may
outlive the sequencer.</p>

<p>It's important therefore to detach assets from the sequencer and the sequencer
from the assets when each step is over and the asset is "out of scope" for the
sequencer.  It doesn't necessarily mean closing the assets, just making sure
pointers are invalidated.  For example, if a client wsi held a pointer to the
sequencer as its <code>.user_data</code>, when the wsi is out of scope for the sequencer
it can set it to NULL, eg, <code>lws_set_wsi_user(wsi, NULL);</code>.</p>

<p>Under some conditions wsi may want to hang around a bit to see if there is a
subsequent client wsi transaction they can be reused on.  They will clean
themselves up when they time out.</p>

<h2>Watching wsi lifecycle from a sequencer</h2>

<p>When a sequencer is creating a wsi as part of its sequence, it will be very
interested in lifecycle events.  At client wsi creation time, the sequencer
callback can set info->seq to itself in order to receive lifecycle messages
about its wsi.</p>

<p>|message|meaning|
|---|---|
|<code>LWSSEQ_WSI_CONNECTED</code>|The wsi has become connected|
|<code>LWSSEQ_WSI_CONN_FAIL</code>|The wsi has failed to connect|
|<code>LWSSEQ_WSI_CONN_CLOSE</code>|The wsi had been connected, but has now closed|</p>

<p>By receiving these, the sequencer can understand when it should attempt
reconnections or that it cannot progress the sequence.</p>

<p>When dealing with wsi that were created by the sequencer, they may close at
any time, eg, be closed by the remote peer or an intermediary.  The
<code>LWSSEQ_WSI_CONN_CLOSE</code> message may have been queued but since they are
strictly handled in the order they arrived, before it was
handled an earlier message may want to cause some api to be called on
the now-free()-d wsi.  To detect this situation safely, there is a
sequencer api <code>lws_sequencer_check_wsi()</code> which peeks the message
buffer and returns nonzero if it later contains an <code>LWSSEQ_WSI_CONN_CLOSE</code>
already.</p>

<h1>lws_struct</h1>

<h2>Overview</h2>

<p>lws_struct provides a lightweight method for serializing and deserializing C
structs to and from JSON, and to and from sqlite3.</p>

<p><img src="../doc-assets/lws_struct-overview.svg" alt="lws_struct overview" title="" /></p>

<ul>
<li><p>you provide a metadata array describing struct members one-time, then call
generic apis to serialize and deserialize </p></li>
<li><p>supports flat structs, single child struct pointers, and unbounded arrays /
linked-lists of child objects automatically using <a href="./README.lws_dll.md">lws_dll2 linked-lists</a></p></li>
<li><p>supports boolean and C types char, int, long, long long in explicitly signed
and unsigned forms</p></li>
<li><p>supports both char * type string members where the unbounded content is
separate and pointed to, and fixed length char array[] type members where
the content is part of the struct</p></li>
<li><p>huge linear strings are supported by storing to a temp lwsac of chained chunks,
which is written into a single linear chunk in the main lwsac once the
total string length is known</p></li>
<li><p>deserialization allocates into an <a href="../lib/misc/lwsac/README.md">lwsac</a>, so everything is inside as few
heap allocations as possible while still able to expand to handle arbitrary
array or strins sizes</p></li>
<li><p>when deserialized structs are finished with, a single call to free the
lwsac frees the whole thing without having to walk it</p></li>
<li><p>stateful serializaton and deserialization allows as-you-get packets incremental
parsing and production of chunks of as-you-can-send incremental serialization
output cleanly</p></li>
</ul>

<h2>Examples</h2>

<h1>Notes about lwsws</h1>

<p>@section lwsws Libwebsockets Web Server</p>

<p>lwsws is an implementation of a very lightweight, ws-capable generic web
server, which uses libwebsockets to implement everything underneath.</p>

<p>If you are basically implementing a standalone server with lws, you can avoid
reinventing the wheel and use a debugged server including lws.</p>

<p>@section lwswsb Build</p>

<p>Just enable -DLWS<em>WITH</em>LWSWS=1 at cmake-time.</p>

<p>It enables libuv and plugin support automatically.</p>

<p>NOTICE on Ubuntu, the default libuv package is called "libuv-0.10".  This is ancient.</p>

<p>You should replace this with libuv1 and libuv1-dev before proceeding.</p>

<p>@section lwswsc Lwsws Configuration</p>

<p>lwsws uses JSON config files, they're pure JSON except:</p>

<ul>
<li><p>'#' may be used to turn the rest of the line into a comment.</p></li>
<li><p>There's also a single substitution, if a string contains "<em>lws</em>ddir_", then that is
replaced with the LWS install data directory path, eg, "/usr/share" or whatever was
set when LWS was built + installed.  That lets you refer to installed paths without
having to change the config if your install path was different.</p></li>
</ul>

<p>There is a single file intended for global settings</p>

<p>/etc/lwsws/conf
```
    # these are the server global settings
    # stuff related to vhosts should go in one
    # file per vhost in ../conf.d/</p>

<pre><code>{
  "global": {
   "username": "apache",
   "groupname": "apache",
   "count-threads": "1",
   "server-string": "myserver v1", # returned in http headers
   "ws-pingpong-secs": "200", # confirm idle established ws connections this often
   "init-ssl": "yes"
 }
}
</code></pre>

<p>```
and a config directory intended to take one file per vhost</p>

<p>/etc/lwsws/conf.d/warmcat.com
<code>
    {
        "vhosts": [{
            "name": "warmcat.com",
            "port": "443",
            "interface": "eth0",  # optional
            "host-ssl-key": "/etc/pki/tls/private/warmcat.com.key",  # if given enable ssl
            "host-ssl-cert": "/etc/pki/tls/certs/warmcat.com.crt",
            "host-ssl-ca": "/etc/pki/tls/certs/warmcat.com.cer",
            "mounts": [{  # autoserve
                "mountpoint": "/",
                "origin": "file:///var/www/warmcat.com",
                "default": "index.html"
            }]
        }]
    }
</code>
To get started quickly, an example config reproducing the old test server
on port 7681, non-SSL is provided.  To set it up
<code>
    # mkdir -p /etc/lwsws/conf.d /var/log/lwsws
    # cp ./lwsws/etc-lwsws-conf-EXAMPLE /etc/lwsws/conf
    # cp ./lwsws/etc-lwsws-conf.d-localhost-EXAMPLE /etc/lwsws/conf.d/test-server
    # sudo lwsws
</code></p>

<p>@section lwswsacme Using Letsencrypt or other ACME providers</p>

<p>Lws supports automatic provisioning and renewal of TLS certificates.</p>

<p>See ./READMEs/README.plugin-acme.md for examples of how to set it up on an lwsws vhost.</p>

<p>@section lwsogo Other Global Options</p>

<ul>
<li><code>reject-service-keywords</code> allows you to return an HTTP error code and message of your choice
if a keyword is found in the user agent</li>
</ul>

<p><code>
   "reject-service-keywords": [{
        "scumbot": "404 Not Found"
   }]
</code></p>

<ul>
<li><code>timeout-secs</code> lets you set the global timeout for various network-related
operations in lws, in seconds.  It defaults to 5.</li>
</ul>

<p>@section lwswsv Lwsws Vhosts</p>

<p>One server can run many vhosts, where SSL is in use SNI is used to match
the connection to a vhost and its vhost-specific SSL keys during SSL
negotiation.</p>

<p>Listing multiple vhosts looks something like this
```
    {
     "vhosts": [ {
         "name": "localhost",
         "port": "443",
         "host-ssl-key":  "/etc/pki/tls/private/libwebsockets.org.key",
         "host-ssl-cert": "/etc/pki/tls/certs/libwebsockets.org.crt",
         "host-ssl-ca":   "/etc/pki/tls/certs/libwebsockets.org.cer",
         "mounts": [{
           "mountpoint": "/",
           "origin": "file:///var/www/libwebsockets.org",
           "default": "index.html"
           }, {
            "mountpoint": "/testserver",
            "origin": "file:///usr/local/share/libwebsockets-test-server",
            "default": "test.html"
           }],
         # which protocols are enabled for this vhost, and optional
         # vhost-specific config options for the protocol
         #
         "ws-protocols": [{
           "warmcat,timezoom": {
             "status": "ok"
           }
         }]
        },
        {
        "name": "localhost",
        "port": "7681",
         "host-ssl-key":  "/etc/pki/tls/private/libwebsockets.org.key",
         "host-ssl-cert": "/etc/pki/tls/certs/libwebsockets.org.crt",
         "host-ssl-ca":   "/etc/pki/tls/certs/libwebsockets.org.cer",
         "mounts": [{
           "mountpoint": "/",
           "origin": ">https://localhost"
         }]
       },
        {
        "name": "localhost",
        "port": "80",
         "mounts": [{
           "mountpoint": "/",
           "origin": ">https://localhost"
         }]
       }</p>

<pre><code>  ]
}
</code></pre>

<p>```</p>

<p>That sets up three vhosts all called "localhost" on ports 443 and 7681 with SSL, and port 80 without SSL but with a forced redirect to https://localhost</p>

<p>@section lwswsvn Lwsws Vhost name and port sharing</p>

<p>The vhost name field is used to match on incoming SNI or Host: header, so it
must always be the host name used to reach the vhost externally.</p>

<ul>
<li><p>Vhosts may have the same name and different ports, these will each create a
listening socket on the appropriate port.</p></li>
<li><p>Vhosts may also have the same port and different name: these will be treated as
true vhosts on one listening socket and the active vhost decided at SSL
negotiation time (via SNI) or if no SSL, then after the Host: header from
the client has been parsed.</p></li>
</ul>

<p>@section lwswspr Lwsws Protocols</p>

<p>Vhosts by default have available the union of any initial protocols from context creation time, and
any protocols exposed by plugins.</p>

<p>Vhosts can select which plugins they want to offer and give them per-vhost settings using this syntax
<code>
         "ws-protocols": [{
           "warmcat-timezoom": {
             "status": "ok"
           }
         }]
</code></p>

<p>The "x":"y" parameters like "status":"ok" are made available to the protocol during its per-vhost
LWS<em>CALLBACK</em>PROTOCOL<em>INIT (in is a pointer to a linked list of struct lws</em>protocol<em>vhost</em>options
containing the name and value pointers).</p>

<p>To indicate that a protocol should be used when no Protocol: header is sent
by the client, you can use "default": "1"
<code>
         "ws-protocols": [{
           "warmcat-timezoom": {
             "status": "ok",
             "default": "1"
           }
         }]
</code></p>

<p>Similarly, if your vhost is serving a raw protocol, you can mark the protocol
to be selected using "raw": "1"
<code>
         "ws-protocols": [{
           "warmcat-timezoom": {
             "status": "ok",
             "raw": "1"
           }
         }]
</code></p>

<p>See also "apply-listen-accept" below.</p>

<p>@section lwswsovo Lwsws Other vhost options</p>

<ul>
<li><p>If the three options <code>host-ssl-cert</code>, <code>host-ssl-ca</code> and <code>host-ssl-key</code> are given, then the vhost supports SSL.</p>

<p>Each vhost may have its own certs, SNI is used during the initial connection negotiation to figure out which certs to use by the server name it's asking for from the request DNS name.</p></li>
<li><p><code>keeplive-timeout</code> (in secs) defaults to 60 for lwsws, it may be set as a vhost option</p></li>
<li><p><code>interface</code> lets you specify which network interface to listen on, if not given listens on all.  If the network interface is not usable (eg, ethernet cable out) it will be logged at startup with such vhost not listening, and lws will poll for it and bind a listen socket to the interface if and when it becomes available.</p></li>
<li><p>"<code>unix-socket</code>": "1" causes the unix socket specified in the interface option to be used instead of an INET socket</p></li>
<li><p>"<code>unix-socket-perms</code>": "user:group" allows you to control the unix permissons on the listening unix socket.  It's always get to <code>0600</code> mode, but you can control the user and group for the socket fd at creation time.  This allows you to use unix user and groups to control who may open the other end of the unix socket on the local system.</p></li>
<li><p>"<code>sts</code>": "1" causes lwsws to send a Strict Transport Security header with responses that informs the client he should never accept to connect to this address using http.  This is needed to get the A+ security rating from SSL Labs for your server.</p></li>
<li><p>"<code>access-log</code>": "filepath"   sets where apache-compatible access logs will be written</p></li>
<li><p><code>"enable-client-ssl"</code>: <code>"1"</code> enables the vhost's client SSL context, you will need this if you plan to create client conections on the vhost that will use SSL.  You don't need it if you only want http / ws client connections.</p></li>
<li><p>"<code>ciphers</code>": "<cipher list>"  OPENSSL only: sets the allowed list of TLS &lt;= 1.2 ciphers and key exchange protocols for the serving SSL_CTX on the vhost.  The default list is restricted to only those providing PFS (Perfect Forward Secrecy) on the author's Fedora system.</p>

<p>If you need to allow weaker ciphers, you can provide an alternative list here per-vhost.</p></li>
<li><p>"<code>client-ssl-ciphers</code>": "<cipher list>"  OPENSSL only: sets the allowed list of &lt;= TLS1.2 ciphers and key exchange protocols for the client SSL_CTX on the vhost</p></li>
<li><p>"<code>tls13-ciphers</code>": "<cipher list>"  OPENSSL 1.1.1+ only: sets allowed list of TLS1.3+ ciphers and key exchange protocols for the client SSL_CTX on the vhost.  The default is to allow all.</p></li>
<li><p>"<code>client-tls13-ciphers</code>": "<cipher list>"  OPENSSL 1.1.1+ only: sets the allowed list of TLS1.3+ ciphers and key exchange protocols for the client SSL_CTX on the vhost.  The default is to allow all.</p></li>
<li><p>"<code>ecdh-curve</code>": "<curve name>"   The default ecdh curve is "prime256v1", but you can override it here, per-vhost</p></li>
<li><p>"<code>noipv6</code>": "on"  Disable ipv6 completely for this vhost</p></li>
<li><p>"<code>ipv6only</code>": "on"  Only allow ipv6 on this vhost / "off" only allow ipv4 on this vhost</p></li>
<li><p>"<code>ssl-option-set</code>": "<decimal>"  Sets the SSL option flag value for the vhost.
It may be used multiple times and OR's the flags together.</p>

<p>The values are derived from /usr/include/openssl/ssl.h
<code>
 # define SSL_OP_NO_TLSv1_1                               0x10000000L
</code></p>

<p>would equate to</p></li>
</ul>

<p><code>
     "`ssl-option-set`": "268435456"
</code>
 - "`ssl-option-clear'": "<decimal>"   Clears the SSL option flag value for the vhost.
 It may be used multiple times and OR's the flags together.</p>

<ul>
<li><p>"<code>ssl-client-option-set</code>" and "<code>ssl-client-option-clear</code>" work the same way for the vhost Client SSL context</p></li>
<li><p>"`headers':: [{ "header1": "h1value", "header2": "h2value" }] </p></li>
</ul>

<p>allows you to set arbitrary headers on every file served by the vhost</p>

<p>recommended vhost headers for good client security are</p>

<p>```
                   "headers": [{
                        "Content-Security-Policy": "script-src 'self'",
                        "X-Content-Type-Options": "nosniff",
                        "X-XSS-Protection": "1; mode=block",
                        "X-Frame-Options": "SAMEORIGIN"
                 }]</p>

<p>```</p>

<ul>
<li>"<code>apply-listen-accept</code>": "on"  This vhost only serves a non-http protocol, specified in "listen-accept-role" and "listen-accept-protocol"</li>
</ul>

<p>@section lwswsm Lwsws Mounts</p>

<p>Where mounts are given in the vhost definition, then directory contents may
be auto-served if it matches the mountpoint.</p>

<p>Mount protocols are used to control what kind of translation happens</p>

<ul>
<li><p>file://  serve the uri using the remainder of the url past the mountpoint based on the origin directory.</p>

<p>Eg, with this mountpoint
<code>
       {
        "mountpoint": "/",
        "origin": "file:///var/www/mysite.com",
        "default": "/"
       }
</code>
The uri /file.jpg would serve /var/www/mysite.com/file.jpg, since / matched.</p></li>
<li><p>^http:// or ^https://  these cause any url matching the mountpoint to issue a redirect to the origin url</p></li>
<li><p>cgi://   this causes any matching url to be given to the named cgi, eg
<code>
       {
        "mountpoint": "/git",
        "origin": "cgi:///var/www/cgi-bin/cgit",
        "default": "/"
       }, {
        "mountpoint": "/cgit-data",
        "origin": "file:///usr/share/cgit",
        "default": "/"
       },
</code>
would cause the url /git/myrepo to pass "myrepo" to the cgi /var/www/cgi-bin/cgit and send the results to the client.</p></li>
<li><p>http:// or https://  these perform reverse proxying, serving the remote origin content from the mountpoint.  Eg</p></li>
</ul>

<p><code>
        {
         "mountpoint": "/proxytest",
         "origin": "https://libwebsockets.org"
        }
</code></p>

<p>This will cause your local url <code>/proxytest</code> to serve content fetched from libwebsockets.org over ssl; whether it's served from your server using ssl is unrelated and depends how you configured your local server.  Notice if you will use the proxying feature, <code>LWS_WITH_HTTP_PROXY</code> is required to be enabled at cmake, and for <code>https</code> proxy origins, your lwsws configuration must include <code>"init-ssl": "1"</code> and the vhost with the proxy mount must have <code>"enable-client-ssl": "1"</code>, even if you are not using ssl to serve.</p>

<p><code>/proxytest/abc</code>, or <code>/proxytest/abc?def=ghi</code> etc map to the origin + the part past <code>/proxytest</code>, so links and img src urls etc work as do all urls under the origin path.</p>

<p>In addition link and src urls in the document are rewritten so / or the origin url part are rewritten to the mountpoint part.</p>

<p>@section lwswsomo Lwsws Other mount options</p>

<p>1) Some protocols may want "per-mount options" in name:value format.  You can
provide them using "pmo"</p>

<pre><code>       {
        "mountpoint": "/stuff",
        "origin": "callback://myprotocol",
        "pmo": [{
                "myname": "myvalue"
        }]
       }
</code></pre>

<p>2) When using a cgi:// protocol origin at a mountpoint, you may also give cgi environment variables specific to the mountpoint like this
<code>
           {
            "mountpoint": "/git",
            "origin": "cgi:///var/www/cgi-bin/cgit",
            "default": "/",
            "cgi-env": [{
                    "CGIT_CONFIG": "/etc/cgitrc/libwebsockets.org"
            }]
           }
</code>
 This allows you to customize one cgi depending on the mountpoint (and / or vhost).</p>

<p>3) It's also possible to set the cgi timeout (in secs) per cgi:// mount, like this
<code>
    "cgi-timeout": "30"
</code>
4) <code>callback://</code> protocol may be used when defining a mount to associate a
named protocol callback with the URL namespace area.  For example
<code>
           {
            "mountpoint": "/formtest",
            "origin": "callback://protocol-post-demo"
           }
</code>
All handling of client access to /formtest[anything] will be passed to the
callback registered to the protocol "protocol-post-demo".</p>

<p>This is useful for handling POST http body content or general non-cgi http
payload generation inside a plugin.</p>

<p>See the related notes in README.coding.md</p>

<p>5) Cache policy of the files in the mount can also be set.  If no
options are given, the content is marked uncacheable.
<code>
           {
            "mountpoint": "/",
            "origin": "file:///var/www/mysite.com",
            "cache-max-age": "60",      # seconds
            "cache-reuse": "1",         # allow reuse at client at all
            "cache-revalidate": "1",    # check it with server each time
            "cache-intermediaries": "1" # allow intermediary caches to hold
           }
</code></p>

<p>6) You can also define a list of additional mimetypes per-mount
<code>
            "extra-mimetypes": {
                     ".zip": "application/zip",
                     ".doc": "text/evil"
             }
</code></p>

<p>Normally a file suffix MUST match one of the canned mimetypes or one of the extra
mimetypes, or the file is not served.  This adds a little bit of security because
even if there is a bug somewhere and the mount dirs are circumvented, lws will not
serve, eg, /etc/passwd.</p>

<p>If you provide an extra mimetype entry</p>

<pre><code>        "*": ""
</code></pre>

<p>Then any file is served, if the mimetype was not known then it is served without a
Content-Type: header.</p>

<p>7) A mount can be protected by HTTP Basic Auth.  This only makes sense when using
https, since otherwise the password can be sniffed.</p>

<p>You can add a <code>basic-auth</code> entry on an http mount like this</p>

<p><code>
{
        "mountpoint": "/basic-auth",
        "origin": "file://_lws_ddir_/libwebsockets-test-server/private",
        "basic-auth": "/var/www/balogins-private"
}
</code></p>

<p>Before serving anything, lws will signal to the browser that a username / password
combination is required, and it will pop up a dialog.  When the user has filled it
in, lwsws checks the user:password string against the text file named in the <code>basic-auth</code>
entry.</p>

<p>The file should contain user:pass one per line</p>

<p><code>
testuser:testpass
myuser:hispass
</code></p>

<p>The file should be readable by lwsws, and for a little bit of extra security not
have a file suffix, so lws would reject to serve it even if it could find it on
a mount.</p>

<p>After successful authentication, <code>WSI_TOKEN_HTTP_AUTHORIZATION</code> contains the
authenticated username.</p>

<p>In the case you want to also protect being able to connect to a ws protocol on
a particular vhost by requiring the http part can authenticate using Basic
Auth before the ws upgrade, this is also possible.  In this case, the
"basic-auth": and filepath to the credentials file is passed as a pvo in the
"ws-protocols" section of the vhost definition.</p>

<p>@section lwswscc Requiring a Client Cert on a vhost</p>

<p>You can make a vhost insist to get a client certificate from the peer before
allowing the connection with</p>

<p><code>
    "client-cert-required": "1"
</code></p>

<p>the connection will only proceed if the client certificate was signed by the
same CA as the server has been told to trust.</p>

<p>@section rawconf Configuring Fallback and Raw vhosts</p>

<p>Lws supports some unusual modes for vhost listen sockets, which may be
configured entirely using the JSON per-vhost config language in the related
vhost configuration section.</p>

<p>There are three main uses for them</p>

<p>1) A vhost bound to a specific role and protocol, not http.  This binds all
incoming connections on the vhost listen socket to the "raw-proxy" role and
protocol "myprotocol".</p>

<p><code>
    "listen-accept-role":       "raw-proxy",
    "listen-accept-protocol":   "myprotocol",
    "apply-listen-accept":      "1"
</code></p>

<p>2) A vhost that wants to treat noncompliant connections for http or https as
   belonging to a secondary fallback role and protocol.  This causes non-https
   connections to an https listener to stop being treated as https, to lose the
   tls wrapper, and bind to role "raw-proxy" and protocol "myprotocol".  For
   example, connect a browser on your external IP :443 as usual and it serves
   as normal, but if you have configured the raw-proxy to portforward
   127.0.0.1:22, then connecting your ssh client to your external port 443 will
   instead proxy your sshd over :443 with no http or tls getting in the way.</p>

<p><code>
    "listen-accept-role":       "raw-proxy",
    "listen-accept-protocol":   "myprotocol",
    "fallback-listen-accept":   "1",
    "allow-non-tls":        "1"
</code></p>

<p>3) A vhost wants to either redirect stray http traffic back to https, or to
   actually serve http on an https listen socket (this is not recommended
   since it allows anyone to drop the security assurances of https by
   accident or design).</p>

<p><code>
    "allow-non-tls":        "1",
    "redirect-http":        "1",
</code></p>

<p>...or,</p>

<p><code>
    "allow-non-tls":        "1",
    "allow-http-on-https":      "1",
</code></p>

<p>@section lwswspl Lwsws Plugins</p>

<p>Protcols and extensions may also be provided from "plugins", these are
lightweight dynamic libraries.  They are scanned for at init time, and
any protocols and extensions found are added to the list given at context
creation time.</p>

<p>Protocols receive init (LWS<em>CALLBACK</em>PROTOCOL<em>INIT) and destruction
(LWS</em>CALLBACK<em>PROTOCOL</em>DESTROY) callbacks per-vhost, and there are arrangements
they can make per-vhost allocations and get hold of the correct pointer from
the wsi at the callback.</p>

<p>This allows a protocol to choose to strictly segregate data on a per-vhost
basis, and also allows the plugin to handle its own initialization and
context storage.</p>

<p>To help that happen conveniently, there are some new apis</p>

<ul>
<li>lws<em>vhost</em>get(wsi)</li>
<li>lws<em>protocol</em>get(wsi)</li>
<li>lws<em>callback</em>on<em>writable</em>all<em>protocol</em>vhost(vhost, protocol)</li>
<li>lws<em>protocol</em>vh<em>priv</em>zalloc(vhost, protocol, size)</li>
<li>lws<em>protocol</em>vh<em>priv</em>get(vhost, protocol)</li>
</ul>

<p>dumb increment, mirror and status protocol plugins are provided as examples.</p>

<p>@section lwswsplaplp Additional plugin search paths</p>

<p>Packages that have their own lws plugins can install them in their own
preferred dir and ask lwsws to scan there by using a config fragment
like this, in its own conf.d/ file managed by the other package
<code>
    {
      "global": {
       "plugin-dir": "/usr/local/share/coherent-timeline/plugins"
      }
    }
</code></p>

<p>@section lwswsssp lws-server-status plugin</p>

<p>One provided protocol can be used to monitor the server status.</p>

<p>Enable the protocol like this on a vhost's ws-protocols section
<code>
           "lws-server-status": {
             "status": "ok",
             "update-ms": "5000"
           }
</code>
<code>"update-ms"</code> is used to control how often updated JSON is sent on a ws link.</p>

<p>And map the provided HTML into the vhost in the mounts section
<code>
           {
            "mountpoint": "/server-status",
            "origin": "file:///usr/local/share/libwebsockets-test-server/server-status",
            "default": "server-status.html"
           }
</code>
You might choose to put it on its own vhost which has "interface": "lo", so it's not
externally visible, or use the Basic Auth support to require authentication to
access it.</p>

<p><code>"hide-vhosts": "{0 | 1}"</code> lets you control if information about your vhosts is included.
Since this includes mounts, you might not want to leak that information, mount names,
etc.</p>

<p><code>"filespath":"{path}"</code> lets you give a server filepath which is read and sent to the browser
on each refresh.  For example, you can provide server temperature information on most
Linux systems by giving an appropriate path down /sys.</p>

<p>This may be given multiple times.</p>

<p>@section lwswsreload Lwsws Configuration Reload</p>

<p>You may send lwsws a <code>HUP</code> signal, by, eg</p>

<p><code>
$ sudo killall -HUP lwsws
</code></p>

<p>This causes lwsws to "deprecate" the existing lwsws process, and remove and close all of
its listen sockets, but otherwise allowing it to continue to run, until all
of its open connections close.</p>

<p>When a deprecated lwsws process has no open connections left, it is destroyed
automatically.</p>

<p>After sending the SIGHUP to the main lwsws process, a new lwsws process, which can
pick up the newly-available listen sockets, and use the current configuration
files, is automatically started.</p>

<p>The new configuration may differ from the original one in arbitrary ways, the new
context is created from scratch each time without reference to the original one.</p>

<p>Notes</p>

<p>1) Protocols that provide a "shared world" like mirror will have as many "worlds"
as there are lwsws processes still active.  People connected to a deprecated lwsws
process remain connected to the existing peers.</p>

<p>But any new connections will apply to the new lwsws process, which does not share
per-vhost "shared world" data with the deprecated process.  That means no new
connections on the deprecated context, ie a "shrinking world" for those guys, and a
"growing world" for people who connect after the SIGHUP.</p>

<p>2) The new lwsws process owes nothing to the previous one.  It starts with fresh
plugins, fresh configuration, fresh root privileges if that how you start it.</p>

<p>The plugins may have been updated in arbitrary ways including struct size changes
etc, and lwsws or lws may also have been updated arbitrarily.</p>

<p>3) A root parent process is left up that is not able to do anything except
respond to SIGHUP or SIGTERM.  Actual serving and network listening etc happens
in child processes which use the privileges set in the lwsws config files.</p>

<p>@section lwswssysd Lwsws Integration with Systemd</p>

<p>lwsws needs a service file like this as <code>/usr/lib/systemd/system/lwsws.service</code>
```
[Unit]
Description=Libwebsockets Web Server
After=syslog.target</p>

<p>[Service]
ExecStart=/usr/local/bin/lwsws 
ExecReload=/usr/bin/killall -s SIGHUP lwsws ; sleep 1 ; /usr/local/bin/lwsws
StandardError=null</p>

<p>[Install]
WantedBy=multi-user.target
```</p>

<p>You can find this prepared in <code>./lwsws/usr-lib-systemd-system-lwsws.service</code></p>

<p>@section lwswslr Lwsws Integration with logrotate</p>

<p>For correct operation with logrotate, <code>/etc/logrotate.d/lwsws</code> (if that's
where we're putting the logs) should contain
<code>
    /var/log/lwsws/*log {
        copytruncate
        missingok
        notifempty
        delaycompress
    }
</code>
You can find this prepared in <code>/lwsws/etc-logrotate.d-lwsws</code></p>

<p>Prepare the log directory like this</p>

<p><code>
    sudo mkdir /var/log/lwsws
    sudo chmod 700 /var/log/lwsws
</code></p>

<p>@section lwswsgdb Debugging lwsws with gdb</p>

<p>Hopefully you won't need to debug lwsws itself, but you may want to debug your plugins.  start lwsws like this to have everything running under gdb</p>

<p>```
sudo gdb -ex "set follow-fork-mode child" -ex "run" --args /usr/local/bin/lwsws</p>

<p>```</p>

<p>this will give nice backtraces in lwsws itself and in plugins, if they were built with symbols.</p>

<p>@section lwswsvgd Running lwsws under valgrind</p>

<p>You can just run lwsws under valgrind as usual and get valid results.  However the results / analysis part of valgrind runs
after the plugins have removed themselves, this means valgrind backtraces into plugin code is opaque, without
source-level info because the dynamic library is gone.</p>

<p>There's a simple workaround, use LD_PRELOAD=<plugin.so> before running lwsws, this has the loader bring the plugin
in before executing lwsws as if it was a direct dependency.  That means it's still mapped until the whole process
exits after valgtind has done its thing.</p>

<h1>lws-acme-client Plugin</h1>

<h2>Introduction</h2>

<p>lws-acme-client is a protcol plugin for libwebsockets that implements an
ACME client able to communicate with let's encrypt and other certificate
providers.</p>

<p>It implements <code>tls-sni-01</code> challenge, and is able to provision tls certificates
"from thin air" that are accepted by all the major browsers.  It also manages
re-requesting the certificate when it only has two weeks left to run.</p>

<p>It works with both the OpenSSL and mbedTLS backends.</p>

<h2>Overview for use</h2>

<p>You need to:</p>

<ul>
<li><p>Provide name resolution to the IP with your server, ie, myserver.com needs to
resolve to the IP that hosts your server</p></li>
<li><p>Enable port forwarding / external firewall access to your port, usually 443</p></li>
<li><p>Enable the "lws-acme-client" plugin on the vhosts you want it to manage
certs for</p></li>
<li><p>Add per-vhost options describing what should be in the certificate</p></li>
</ul>

<p>After that the plugin will sort everything else out.</p>

<h2>Example lwsws setup</h2>

<p><code>
 "vhosts": [ {
    "name":            "home.warmcat.com",
    "port":            "443",
        "host-ssl-cert":           "/etc/lwsws/acme/home.warmcat.com.crt.pem",
        "host-ssl-key":            "/etc/lwsws/acme/home.warmcat.com.key.pem",
        "ignore-missing-cert":     "1",
    "access-log":          "/var/log/lwsws/test-access-log",
        "ws-protocols": [{
      "lws-acme-client": {
        "auth-path":       "/etc/lwsws/acme/auth.jwk",
        "cert-path":           "/etc/lwsws/acme/home.warmcat.com.crt.pem",
        "key-path":            "/etc/lwsws/acme/home.warmcat.com.key.pem",
        "directory-url":       "https://acme-staging.api.letsencrypt.org/directory",
        "country":             "TW",
        "state":               "Taipei",
        "locality":            "Xiaobitan",
        "organization":        "Crash Barrier Ltd",
        "common-name":         "home.warmcat.com",
        "email":               "andy@warmcat.com"
      },
      ...
</code></p>

<h2>Required PVOs</h2>

<p>Notice that the <code>"host-ssl-cert"</code> and <code>"host-ssl-key"</code> entries have the same
meaning as usual, they point to your certificate and private key.  However
because the ACME plugin can provision these, you should also mark the vhost with
<code>"ignore-missing-cert" : "1"</code>, so lwsws will ignore what will initially be
missing certificate / keys on that vhost, and will set about creating the
necessary certs and keys instead of erroring out.</p>

<p>You must make sure the directories mentioned here exist, lws doesn't create them
for you.  They should be 0700 root:root, even if you drop lws privileges.</p>

<p>If you are implementing support in code, this corresponds to making sure the
vhost creating <code>info.options</code> has the <code>LWS_SERVER_OPTION_IGNORE_MISSING_CERT</code>
bit set.</p>

<p>Similarly, in code, the each of the per-vhost options shown above can be
provided in a linked-list of structs at vhost creation time.  See
<code>./test-apps/test-server-v2.0.c</code> for example code for providing pvos.</p>

<h3>auth-path</h3>

<p>This is where the plugin will store the auth keys it generated.</p>

<h3>cert-path</h3>

<p>Where the plugin will store the certificate file.  Should match <code>host-ssl-cert</code>
that the vhost wants to use.</p>

<p>The path should include at least one 0700 root:root directory.</p>

<h3>key-path</h3>

<p>Where the plugin will store the certificate keys.  Again it should match
<code>host-ssl-key</code> the vhost is trying to use.</p>

<p>The path should include at least one 0700 root:root directory.</p>

<h3>directory-url</h3>

<p>This defines the URL of the certification server you will get your
certificates from.  For let's encrypt, they have a "practice" one</p>

<ul>
<li><code>https://acme-staging.api.letsencrypt.org/directory</code></li>
</ul>

<p>and they have a "real" one</p>

<ul>
<li><code>https://acme-v01.api.letsencrypt.org/directory</code></li>
</ul>

<p>the main difference is the CA certificate for the real one is in most browsers
already, but the staging one's CA certificate isn't.  The staging server will
also let you abuse it more in terms of repeated testing etc.</p>

<p>It's recommended you confirm expected operation with the staging directory-url,
and then switch to the "real" URL.</p>

<h3>common-name</h3>

<p>Your server DNS name, like "libwebsockets.org".  The remote ACME server will
use this to find your server to perform the SNI challenges.</p>

<h3>email</h3>

<p>The contact email address for the certificate.</p>

<h2>Optional PVOs</h2>

<p>These are not included in the cert by letsencrypt</p>

<h3>country</h3>

<p>Two-letter country code for the certificate</p>

<h3>state</h3>

<p>State "or province" for the certificate</p>

<h3>locality</h3>

<p>Locality for the certificate</p>

<h3>organization</h3>

<p>Your company name</p>

<h2>Security / Key storage considerations</h2>

<p>The <code>lws-acme-client</code> plugin is able to provision and update your certificate
and keys in an entirely root-only storage environment, even though lws runs
as a different uid / gid with no privileges to access the storage dir.</p>

<p>It does this by opening and holding two WRONLY fds on "update paths" inside the
root directory structure for each cert and key it manages; these are the normal
cert and key paths with <code>.upd</code> appended.  If during the time the server is up
the certs become within two weeks of expiry, the <code>lws-acme-client</code> plugin will
negotiate new certs and write them to the file descriptors.</p>

<p>Next time the server starts, if it sees <code>.upd</code> cert and keys, it will back up
the old ones and copy them into place as the new ones, before dropping privs.</p>

<p>To also handle the long-uptime server case, lws will update the vhost with the
new certs using in-memory temporary copies of the cert and key after updating
the cert.</p>

<p>In this way the cert and key live in root-only storage but the vhost is kept up
to date dynamically with any cert changes as well.</p>

<h2>Multiple vhosts using same cert</h2>

<p>In the case you have multiple vhosts using of the same cert, just attach
the <code>lws-acme-client</code> plugin to one instance.  When the cert updates, all the
vhosts are informed and vhosts using the same filepath to access the cert will
be able to update their cert.</p>

<h2>Implementation point</h2>

<p>You will need to remove the auth keys when switching from OpenSSL to
mbedTLS.  They will be regenerated automatically.  It's the file at this
path:</p>

<p><code>
"auth-path":       "/etc/lwsws/acme/auth.jwk",
</code></p>

<h1>ssh-base Plugin</h1>

<h2>Introduction</h2>

<p>lws-ssh-base is a protcol plugin for libwebsockets that implements a
generic, abstract, ssh server.</p>

<ul>
<li><p>very small footprint in code and memory, takes up small part of ESP32</p></li>
<li><p>written with security in mind: valgrind and Coverity -clean</p></li>
<li><p>binds to one or more vhosts, that controls listen port(s)</p></li>
<li><p>all IO and settings abstracted through a single "ops" struct from user code</p></li>
<li><p>each instance on a vhost has its own "ops" struct, defining server keys,
auth method and functions to implement IO and other operations</p></li>
<li><p>The plugin has no built-in behaviours like check ~/.ssh/authorized_keys,
treat auth usernames as system usernames, or spawn the user's shell.
Everything potentially dangerous is left to the user ops code to decide
how to handle.  It's NOT like sshd where running it implies it will accept
existing keys for any system user, will spawn a shell, etc, unless you
implement those parts in the ops callbacks.</p></li>
<li><p>The plugin requires extra code around it in the form of the ops struct
handlers.  So it's role is something like an abstract base class for an ssh
server.  All the crypto, protocol sequencing and state machine are inside,
but all the IO except the network connection is outside.</p></li>
<li><p>Built as part of libwebsockets, like all plugins may be dynamically loaded
at runtime or built statically.  Test app <code>libwebsockets-test-sshd</code> provided</p></li>
<li><p>Uses hash and RSA functions from either mbedTLS or OpenSSL automatically,
according to which library libwebsockets was built for</p></li>
</ul>

<p>To maintain its small size, it implements a single "best of breed" crypto for
the following functions:</p>

<p>|Function|Crypto|
|---|---|
|KEX|curve25519-sha256@libssh.org|
|Server host key|ssh-rsa (4096b)|
|Encryption|chacha20-poly1305@openssh.com|
|Compression|None|</p>

<h2>License</h2>

<p>lws-ssh-base is Free Software, available under libwebsocket's LGPLv2 +
static linking exception license.</p>

<p>The crypto parts are available elsewhere under a BSD license.  But for
simplicity the whole plugin is under LGPLv2.</p>

<h2>Generating your own keys</h2>

<p><code>
 $ ssh-keygen -t rsa -b 4096 -f mykeys
</code></p>

<p>will ask for a passphrase and generate the private key in <code>mykeys</code> and the
public key in <code>mykeys.pub</code>.  If you already have a suitable RSA key you use
with ssh, you can just use that directly.</p>

<p>lws installs a test keypair in /usr[/local]/share/libwebsockets-test-server
that the test apps will accept.</p>

<h2>Example code</h2>

<p>1) There's a working example app <code>libwebsockets-test-sshd</code> included that
spawns a bash shell when an ssh client authenticates.  The username used on
the remote ssh has no meaning, it spawns the shell under the credentials of
"lws-test-sshd" was run under.  It accepts the lws ssh test key which is
installed into /usr[/local]/share/libwebsockets-test-server.</p>

<p>Start the server like this (it wants root only because the server key is stored
in /etc)</p>

<p><code>
 $ sudo libwebsockets-test-sshd
</code></p>

<p>Connect to it using the test private key like this</p>

<p><code>
 $ ssh -p 2200 -i /usr/local/share/libwebsockets-test-server/lws-ssh-test-keys anyuser@127.0.0.1
</code></p>

<p>2) There's also a working example plugin <code>lws-sshd-demo</code> that "subclasses" the
abstract <code>lws-ssh-base</code> plugin to make a protocol which can be used from,
eg, lwsws.  For an lwsws vhost that listens on port 2222 and responds with
the lws-sshd-demo ssh server, the related config is:</p>

<p><code>
        {
                "name": "sshd",
                "port": "2222",
                "onlyraw": "1",
                "ws-protocols": [{
                        "lws-ssh-base": {
                                "status": "ok",
                                "ops-from": "lws-sshd-demo"
                        },
                        "lws-sshd-demo": {
                                "status": "ok",
                                "raw": "1"
                        }
                }]
        }
</code></p>

<h2>Integration to other apps</h2>

<h3>Step 0: Build and install libwebsockets</h3>

<p>For the <code>libwebsockets-test-sshd</code> example, you will need CMake options
<code>LWS_WITH_CGI</code>, since it uses lws helpers to spawn a shell.</p>

<p>lws-ssh-base itself doesn't require CGI support in libwebsockets.</p>

<h3>Step 1: make the code available in your app</h3>

<p>Include <code>lws-plugin-ssh-base</code> in your app, either as a runtime plugin or by using
the lws static include scheme.</p>

<p>To bring in the whole of the ssh-base plugin
into your app in one step, statically, just include
<code>plugins/ssh-base/include/lws-plugin-sshd-static-build-includes.h</code>, you can see
an example of this in <code>./test-apps/test-sshd.c</code>.</p>

<h3>Step 2: define your <code>struct lws_ssh_ops</code></h3>

<p><code>plugins/ssh-base/include/lws-plugin-ssh.h</code> defines
<code>struct lws_ssh_ops</code> which is used for all customization and integration
of the plugin per vhost.  Eg,</p>

<p><code>
static const struct lws_ssh_ops ssh_ops = {
    .channel_create         = ssh_ops_channel_create,
    .channel_destroy        = ssh_ops_channel_destroy,
    .tx_waiting         = ssh_ops_tx_waiting,
    .tx             = ssh_ops_tx,
    .rx             = ssh_ops_rx,
    .get_server_key         = ssh_ops_get_server_key,
    .set_server_key         = ssh_ops_set_server_key,
    .set_env            = ssh_ops_set_env,
    .pty_req            = ssh_ops_pty_req,
    .child_process_io       = ssh_ops_child_process_io,
    .child_process_terminated   = ssh_ops_child_process_terminated,
    .exec               = ssh_ops_exec,
    .shell              = ssh_ops_shell,
    .is_pubkey_authorized       = ssh_ops_is_pubkey_authorized,
    .banner             = ssh_ops_banner,
    .disconnect_reason      = ssh_ops_disconnect_reason,
    .server_string          = "SSH-2.0-Libwebsockets",
    .api_version            = 1,
};
</code>
The <code>ssh_ops_...()</code> functions are your implementations for the operations
needed by the plugin for your purposes.</p>

<h3>Step 3: enable <code>lws-ssh-base</code> protocol to a vhost and configure using pvo</h3>

<p>A pointer to your struct lws<em>ssh</em>ops is passed into the vhost instance of the
protocol using per-vhost options</p>

<p>```
static const struct lws<em>protocol</em>vhost<em>options pvo</em>ssh<em>ops = {
    NULL,
    NULL,
    "ops",
    (void *)&amp;ssh</em>ops
};</p>

<p>static const struct lws<em>protocol</em>vhost<em>options pvo</em>ssh = {
    NULL,
    &amp;pvo<em>ssh</em>ops,
    "lws-sshd-base",
    "" /* ignored, just matches the protocol name above */
};</p>

<p>...
    info.port = 22;
    info.options = LWS<em>SERVER</em>OPTION<em>ONLY</em>RAW;
    info.vhost<em>name = "sshd";
    info.protocols = protocols</em>sshd;
    info.pvo = &pvo_ssh;</p>

<pre><code>vh_sshd = lws_create_vhost(context, &amp;info);
</code></pre>

<p>```</p>

<p>There are two possible pvos supported, "ops", shown above, directly passes the
ops structure in using the value on the "ops" pvo.</p>

<p>To support other protocols that want to provide ops to lws-ssh-base themselves
for a particular vhost, you can also provide a pvo <code>"ops-from"</code> whose value is
the name of the protocol also enabled on this vhost, whose protocol ".user"
pointer points to the ops struct lws-ssh-base should use.</p>

<h2>Integration to other plugins</h2>

<p>A worked example of using the abstract <code>lws-ssh-base</code> plugin from another
plugin that provides the ops struct is in <code>./plugins/protocol_lws_sshd_demo</code>.</p>

<p>The key points to note</p>

<ul>
<li><p>the plugin sets the ops struct for the vhost instantiation of <code>lws-ssh-base</code>
by passing a pointer to the ops struct in its <code>lws_protocols</code> struct <code>user</code>
member.</p></li>
<li><p>the config for the vhost tells <code>lws-ssh-base</code> to pick up the ops struct
pointer using an "ops-from" pvo that indicates the protocol name.</p></li>
</ul>

<p><code>
            "lws-ssh-base": {
                                "status": "ok",
                                "ops-from": "lws-sshd-demo"
                        },
</code></p>

<ul>
<li>the config for the vhost tells lws this vhost only serves RAW (ie, no http)</li>
</ul>

<p><code>
         {
                "name": "sshd",
                "port": "2222",
                "onlyraw": "1",
                ...
</code></p>

<ul>
<li>the config for the vhost marks the protocol that uses <code>lws-ssh-base</code>, not
<code>lws-ssh-base</code> itself, as the protocol to be served for raw connections</li>
</ul>

<p><code>
                        "lws-sshd-demo": {
                                "status": "ok",
                                "raw": "1"
                         ...
</code></p>

<h2>Notes</h2>

<p>You can have the vhost it binds to listen on a nonstandard port.  The ssh
commandline app cane be told to connect to a non-22 port with
<code>ssh -p portnum user@hostname</code></p>

<h1>Guidance for porting to new platform</h1>

<p>Where differences existed between the initial POSIX platform for lws and other
supported platforms like Windows, <code>lws_plat_...()</code> apis were added to move
handling to platform-specific code in <code>./lib/plat/</code>.</p>

<p>Depending o which platform is built, different platform-specific implementations
of these <code>lws_plat...()</code> apis get built.</p>

<h2>1) Prepare the cmake cross-build file if necessary</h2>

<p>CMake isolates its settings for cross-build into a separate file, which can be
used to different cmake projects for the same platform as well.</p>

<p>Find a similar examples already in <code>./contrib/cross-*</code> and copy and adapt it
as needed,</p>

<p>All settings related to toolchain should go in there.  For cross-toolchain,
the convention is to pass the path to its installed directory in <code>CROSS_PATH</code>
environment variable.</p>

<h2>2) Copy the closest platform dir in ./lib/plat</h2>

<p>Wholesale copy the closest existing platform dir to <code>/lib/plat/myplatform</code> and
rename the files.</p>

<p>Remove stuff specific to the original platform.</p>

<h2>3) Add a flag in CMakeLists.txt</h2>

<p>Cut and paste a flag to select your platform, preferably <code>LWS_PLAT_MYPLATFORM</code> or so</p>

<h2>4) Add a section to force-select and deselect other cmake options based on platform flag</h2>

<p>Some options on by default may not make sense on your platform, and others off
by default may be mandatory.  After the options() section in CMakeLists.txt, you
can use this kind of structure</p>

<p><code>
    if (LWS_PLAT_MYPLATFORM)
        set(LWS_WITH_XXXX 0)
    endif()
</code></p>

<p>to enforce implicit requirements of your platform.  Optional stuff should be set by
running cmake commandline as usual.</p>

<h2>5) Add building your platform files into CMakeLists.txt</h2>

<p>Add entries in CMakeLists.txt for building stuff in <code>./lib/plat/myplatform</code> when
<code>LWS_PLAT_MYPLATFORM</code> is enabled.</p>

<h2>6) Adapt your copied ./lib/plat/myplatform/ files</h2>

<p>You can now do test builds using the cross-build file, your platform flag in
cmake, and your copied ./lib/plat content... this last part since it was
copied from another platform will initially be a plentiful source of errors.</p>

<p>You can iteratively build and adapt the platform files.</p>

<h1>Debugging problems</h1>

<h2>Check it's still a problem with latest lws</h2>

<p>Older versions of lws don't attract any new work after they are released
(see <a href="https://libwebsockets.org/git/libwebsockets/tree/READMEs/README.release-policy.md">the release policy</a> for details);
for a while they will get backported bugfixes but that's it.</p>

<p>All new work and bugfixes happen on master branch.</p>

<p>Old, old versions may be convenient for you to use for some reason.  But unless
you pay for support or have contributed work to lws so we feel we owe you some
consideration, nobody else has any reason to particularly care about solving
issues on ancient versions.  Whereas if the problem exists on master, and can be
reproduced by developers, it usually gets attention, often immediately.</p>

<p>If the problem doesn't exist on master, you can either use master or check also
the -stable branch of the last released version to see if it was already solved
there.</p>

<h2>Library is a component</h2>

<p>As a library, lws is always just a component in a bigger application.</p>

<p>When users have a problem involving lws, what is happening in the bigger
application is usually critical to understand what is going on (and where the
solution lies).  Sometimes access to the remote peer like server or client is also
necessary to provoke the symptom.  Sometimes, the problem is in lws, but
sometimes the problem is not in lws but in these other pieces.</p>

<p>Many users are able to share their sources, but others decide not to, for
presumed "commercial advantage" or whatever.  (In any event, it can be painful
looking through large chunks of someone else's sources for problems when that
is not the library author's responsibility.)</p>

<p>This makes answering questions like "what is wrong with my code I am not
going to show you?" or even "what is wrong with my code?" very difficult.</p>

<p>Even if it's clear there is a problem somewhere, it cannot be understood or
reproduced by anyone else if it needs user code that isn't provided.</p>

<p>The biggest question is, "is this an lws problem actually"?  To solve that
the best solution is to strip out all or as much user code as possible,
and see if the problem is still coming.</p>

<h2>Use the test apps / minimal examples as sanity checks</h2>

<p>The test server and client, and any more specifically relevant minimal example
 are extremely useful for sanity checks and debugging guidance.</p>

<ul>
<li><p><strong>test apps work on your platform</strong>, then either</p>

<ul>
<li>your user code is broken, align it to how the test apps work, or,</li>
<li>something from your code is required to show an lws problem, provide a
minimal patch on a test app so it can be reproduced</li>
</ul></li>
<li><p><strong>test apps break on your platform</strong>, but work on, eg, x86_64, either</p>

<ul>
<li>toolchain or platform-specific (eg, OS) issue, or</li>
<li>lws platform support issue</li>
</ul></li>
<li><p><strong>test apps break everywhere</strong></p>

<ul>
<li>sounds like lws problem, info to reproduce and / or a patch is appreciated
<h1>lws release policy</h1></li>
</ul></li>
</ul>

<h2>Master branch</h2>

<p>Master branch is the default and all new work happens there.  It's unstable and
subject to history rewrites, patches moving about and being squashed etc.  In
terms of it working, it is subject to passing CI tests including a battery of
runtime tests, so if it is passing CI as it usually is then it's probably in
usable shape.</p>

<p><img src="../doc-assets/lws-relpol-1.svg" alt="all work happens on master" title="" /></p>

<p>If you have patches (you are a hero) they should be targeted at master.</p>

<p>To follow such a branch, <code>git pull</code> is the wrong tool... the starting point
of what you currently have may no longer exist remotely due to rearranging the
patches there.  Instead use a flow like this:</p>

<p><code>
 $ git fetch https://libwebsockets.org/repo/libwebsockets +master:m &amp;&amp; git reset --hard m
</code></p>

<p>This fetches current remote master into local branch <code>m</code>, and then forces your
local checkout to exactly match <code>m</code>.  This replaces your checked-out tree
including any of your local changes, so stash those first, or use stgit or so
to pop them before updating your basis against lws master.</p>

<h2>Stable branches</h2>

<p>Master is very useful for coordinating development, and integrating WIP,
but for distros or integration into large user projects some stability is often
more desirable than the latest development work.</p>

<p>Periodically, when master seems in good shape and various new developments seem
to be working, it's copied out into a versioned stable branch, like <code>v3.0-stable</code>.</p>

<p><img src="../doc-assets/lws-relpol-2.svg" alt="stable branches are copied from master" title="" /></p>

<p>The initial copy is tagged with, eg, <code>v3.0.0</code>.</p>

<p>(At that time, master's logical version is set to "...99", eg, <code>v3.0.99</code> so
version comparisons show that version of master is "later" than any other
v3.0 version, which will never reach 99 point releases itself, but "earlier"
than, eg, v3.1.)</p>

<h2>Backport policy</h2>

<p>Work continues on master, and as part of that usually bugs are reported and / or
fixes found that may apply not just to current master, but the version of master
that was copied to form the last -stable branch.</p>

<p>In that case, the patch may be backported to the last stable branch to also fix
the bug there.  In the case of refactors or major internal improvements, these
typically do not get backported.</p>

<p>This applies only to fixes and public API-neutral internal changes to lws... if
new features were backported or API changes allowed, then there would be
multiple apis under the same version name and library soname, which is
madness.</p>

<p>When new stable releases are made, the soname is bumped reflecting the API is
different than that of previous versions.</p>

<p><img src="../doc-assets/lws-relpol-3.svg" alt="backports from master to stable" title="" /></p>

<p>If there is something you need in a later lws version that is not backported,
you need to either backport it yourself (remember that lws is LGPL and you must
provide your changes when you distribute the binary) or use a later lws version.
Using a more recent version of lws is almost always the correct way.</p>

<h2>Stable point releases</h2>

<p>Periodically fix patches pile up on the -stable branch and are tagged out as
"point releases".  So if the original stable release was "v3.0.0", the point
release may be "v3.0.1".</p>

<p><img src="../doc-assets/lws-relpol-4.svg" alt="point releases of stable" title="" /></p>

<h2>Critical fixes</h2>

<p>Sometimes a bug is found and fixed that had been hiding for a few versions.
If the bug has some security dimension or is otherwise important, we may
backport it to a few recent releases, not just the last one.  This is pretty
uncommon though.</p>

<p><img src="../doc-assets/lws-relpol-5.svg" alt="backport to multiple stable branches" title="" /></p>

<h1>Overview of lws test apps</h1>

<p>Are you building a client?  You just need to look at the test client
<a href="../test-apps/test-client.c">libwebsockets-test-client</a>.</p>

<p>If you are building a standalone server, there are three choices, in order of
preferability.</p>

<p>1) lwsws + protocol plugins</p>

<p>Lws provides a generic web server app that can be configured with JSON
config files.  https://libwebsockets.org itself uses this method.</p>

<p>With lwsws handling the serving part, you only need to write an lws protocol
plugin.  See <a href="../plugin-standalone">plugin-standalone</a> for an example of how
to do that outside lws itself, using lws public apis.</p>

<p>$ cmake .. -DLWS<em>WITH</em>LWSWS=1</p>

<p>See <a href="../READMEs/README.lwsws.md">README.lwsws.md</a> for information on how to configure
lwsws.</p>

<p>NOTE this method implies libuv is used by lws, to provide crossplatform
implementations of timers, dynamic lib loading etc for plugins and lwsws.</p>

<p>2) test-server-v2.0.c</p>

<p>This method lets you configure web serving in code, instead of using lwsws.</p>

<p>Plugins are still used, but you have a choice whether to dynamically load
them or statically include them.  In this example, they are dynamically
loaded.</p>

<p>$ cmake .. -DLWS<em>WITH</em>PLUGINS=1</p>

<p>See <a href="../test-apps/test-server-v2.0.c">test-server-v2.0.c</a></p>

<p>3) protocols in the server app</p>

<p>This is the original way lws implemented servers, plugins and libuv are not
required, but without plugins separating the protocol code directly, the
combined code is all squidged together and is much less maintainable.</p>

<p>This method is still supported in lws but all ongoing and future work is
being done in protocol plugins only.</p>

<p>You can simply include the plugin contents and have it buit statically into
your server, just define this before including the plugin source</p>

<p>```</p>

<h1>define LWS<em>PLUGIN</em>STATIC</h1>

<p>```</p>

<p>This gets you most of the advantages without needing dynamic loading +
libuv.</p>

<h1>Notes about lws test apps</h1>

<p>@section tsb Testing server with a browser</p>

<p>If you run <a href="../test-apps/test-server.c">libwebsockets-test-server</a> and point your browser
(eg, Chrome) to</p>

<pre><code>http://127.0.0.1:7681
</code></pre>

<p>It will fetch a script in the form of <code>test.html</code>, and then run the
script in there on the browser to open a websocket connection.
Incrementing numbers should appear in the browser display.</p>

<p>By default the test server logs to both stderr and syslog, you can control
what is logged using <code>-d &lt;log level&gt;</code>, see later.</p>

<p>@section tsd Running test server as a Daemon</p>

<p>You can use the -D option on the test server to have it fork into the
background and return immediately.  In this daemonized mode all stderr is
disabled and logging goes only to syslog, eg, <code>/var/log/messages</code> or similar.</p>

<p>The server maintains a lockfile at <code>/tmp/.lwsts-lock</code> that contains the pid
of the master process, and deletes this file when the master process
terminates.</p>

<p>To stop the daemon, do
<code>
       $ kill \`cat /tmp/.lwsts-lock\`
</code>
If it finds a stale lock (the pid mentioned in the file does not exist
any more) it will delete the lock and create a new one during startup.</p>

<p>If the lock is valid, the daemon will exit with a note on stderr that
it was already running.</p>

<p>@section clicert Testing Client Certs</p>

<p>Here is a very quick way to create a CA, and a client and server cert from it,
for testing.</p>

<p><code>
$ cp -rp ./scripts/client-ca /tmp
$ cd /tmp/client-ca
$ ./create-ca.sh
$ ./create-server-cert.sh server
$ ./create-client-cert.sh client
</code></p>

<p>The last step wants an export password, you will need this password again to
import the p12 format certificate into your browser.</p>

<p>This will get you the following</p>

<p>|name|function|
|----|--------|
|ca.pem|Your Certificate Authority cert|
|ca.key|Private key for the CA cert|
|client.pem|Client certificate, signed by your CA|
|client.key|Client private key|
|client.p12|combined client.pem + client.key in p12 format for browsers|
|server.pem|Server cert, signed by your CA|
|server.key|Server private key|</p>

<p>You can confirm yourself the client and server certs are signed by the CA.</p>

<p><code>
 $ openssl verify -verbose -trusted ca.pem server.pem
 $ openssl verify -verbose -trusted ca.pem client.pem
</code></p>

<p>Import the client.p12 file into your browser.  In FFOX57 it's</p>

<ul>
<li>preferences</li>
<li>Privacy &amp; Security</li>
<li>Certificates | View Certificates</li>
<li>Certificate Manager | Your Certificates | Import...</li>
<li>Enter the password you gave when creating client1.p12</li>
<li>Click OK.</li>
</ul>

<p>You can then run the test server like this:</p>

<p><code>
 $ libwebsockets-test-server -s -A ca.pem -K server.key -C server.pem -v
</code></p>

<p>When you connect your browser to https://localhost:7681 after accepting the
selfsigned server cert, your browser will pop up a prompt to send the server
your client cert (the -v switch enables this).  The server will only accept
a client cert that has been signed by ca.pem.</p>

<p>@section sssl Using SSL on the server side</p>

<p>To test it using SSL/WSS, just run the test server with
<code>
    $ libwebsockets-test-server --ssl
</code>
and use the URL
<code>
    https://127.0.0.1:7681
</code>
The connection will be entirely encrypted using some generated
certificates that your browser will not accept, since they are
not signed by any real Certificate Authority.  Just accept the
certificates in the browser and the connection will proceed
in first https and then websocket wss, acting exactly the
same.</p>

<p><a href="../test-apps/test-server.c">test-server.c</a> is all that is needed to use libwebsockets for
serving both the script html over http and websockets.</p>

<p>@section lwstsdynvhost Dynamic Vhosts</p>

<p>You can send libwebsockets-test-server or libwebsockets-test-server-v2.0 a SIGUSR1
to toggle the creation and destruction of an identical second vhost on port + 1.</p>

<p>This is intended as a test and demonstration for how to bring up and remove
vhosts dynamically.</p>

<p>@section unixskt Testing Unix Socket Server support</p>

<p>Start the test server with -U and the path to create the unix domain socket</p>

<p><code>
 $ libwebsockets-test-server -U /tmp/uds
</code></p>

<p>On exit, lws will delete the socket inode.</p>

<p>To test the client side, eg</p>

<p><code>
 $ nc -C -U /tmp/uds -i 30
</code></p>

<p>and type</p>

<p><code>GET / HTTP/1.1</code></p>

<p>followed by two ENTER.  The contents of test.html should be returned.</p>

<p>@section wscl Testing websocket client support</p>

<p>If you run the test server as described above, you can also
connect to it using the test client as well as a browser.</p>

<p><code>
    $ libwebsockets-test-client localhost
</code></p>

<p>will by default connect to the test server on localhost:7681
and print the dumb increment number from the server at the
same time as drawing random circles in the mirror protocol;
if you connect to the test server using a browser at the
same time you will be able to see the circles being drawn.</p>

<p>The test client supports SSL too, use</p>

<p><code>
    $ libwebsockets-test-client localhost --ssl -s
</code></p>

<p>the -s tells it to accept the default self-signed cert from the server,
otherwise it will strictly fail the connection if there is no CA cert to
validate the server's certificate.</p>

<p>@section choosingts Choosing between test server variations</p>

<p>If you will be doing standalone serving with lws, ideally you should avoid
making your own server at all, and use lwsws with your own protocol plugins.</p>

<p>The second best option is follow test-server-v2.0.c, which uses a mount to
autoserve a directory, and lws protocol plugins for ws, without needing any
user callback code (other than what's needed in the protocol plugin).</p>

<p>For those two options libuv is needed to support the protocol plugins, if
that's not possible then the other variations with their own protocol code
should be considered.</p>

<p>@section tassl Testing SSL on the client side</p>

<p>To test SSL/WSS client action, just run the client test with
<code>
    $ libwebsockets-test-client localhost --ssl
</code>
By default the client test applet is set to accept self-signed
certificates used by the test server, this is indicated by the
<code>use_ssl</code> var being set to <code>2</code>.  Set it to <code>1</code> to reject any server
certificate that it doesn't have a trusted CA cert for.</p>

<p>@section taping Using the websocket ping utility</p>

<p>libwebsockets-test-ping connects as a client to a remote
websocket server and pings it like the
normal unix ping utility.
<code>
    $ libwebsockets-test-ping localhost
    handshake OK for protocol lws-mirror-protocol
    Websocket PING localhost.localdomain (127.0.0.1) 64 bytes of data.
    64 bytes from localhost: req=1 time=0.1ms
    64 bytes from localhost: req=2 time=0.1ms
    64 bytes from localhost: req=3 time=0.1ms
    64 bytes from localhost: req=4 time=0.2ms
    64 bytes from localhost: req=5 time=0.1ms
    64 bytes from localhost: req=6 time=0.2ms
    64 bytes from localhost: req=7 time=0.2ms
    64 bytes from localhost: req=8 time=0.1ms
    ^C
    --- localhost.localdomain websocket ping statistics ---
    8 packets transmitted, 8 received, 0% packet loss, time 7458ms
    rtt min/avg/max = 0.110/0.185/0.218 ms
    $
</code>
By default it sends 64 byte payload packets using the 04
PING packet opcode type.  You can change the payload size
using the <code>-s=</code> flag, up to a maximum of 125 mandated by the
04 standard.</p>

<p>Using the lws-mirror protocol that is provided by the test
server, libwebsockets-test-ping can also use larger payload
sizes up to 4096 is BINARY packets; lws-mirror will copy
them back to the client and they appear as a PONG.  Use the
<code>-m</code> flag to select this operation.</p>

<p>The default interval between pings is 1s, you can use the -i=
flag to set this, including fractions like <code>-i=0.01</code> for 10ms
interval.</p>

<p>Before you can even use the PING opcode that is part of the
standard, you must complete a handshake with a specified
protocol.  By default lws-mirror-protocol is used which is
supported by the test server.  But if you are using it on
another server, you can specify the protocol to handshake with
by <code>--protocol=protocolname</code></p>

<p>@section ta fraggle Fraggle test app</p>

<p>By default it runs in server mode
<code>
    $ libwebsockets-test-fraggle
    libwebsockets test fraggle
    (C) Copyright 2010-2011 Andy Green &lt;andy@warmcat.com&gt; licensed under LGPL2.1
     Compiled with SSL support, not using it
     Listening on port 7681
    server sees client connect
    accepted v06 connection
    Spamming 360 random fragments
    Spamming session over, len = 371913. sum = 0x2D3C0AE
    Spamming 895 random fragments
    Spamming session over, len = 875970. sum = 0x6A74DA1
    ...
</code>
You need to run a second session in client mode, you have to
give the <code>-c</code> switch and the server address at least:
<code>
    $ libwebsockets-test-fraggle -c localhost
    libwebsockets test fraggle
    (C) Copyright 2010-2011 Andy Green &lt;andy@warmcat.com&gt; licensed under LGPL2.1
     Client mode
    Connecting to localhost:7681
    denied deflate-stream extension
    handshake OK for protocol fraggle-protocol
    client connects to server
    EOM received 371913 correctly from 360 fragments
    EOM received 875970 correctly from 895 fragments
    EOM received 247140 correctly from 258 fragments
    EOM received 695451 correctly from 692 fragments
    ...
</code>
The fraggle test sends a random number up to 1024 fragmented websocket frames
each of a random size between 1 and 2001 bytes in a single message, then sends
a checksum and starts sending a new randomly sized and fragmented message.</p>

<p>The fraggle test client receives the same message fragments and computes the
same checksum using websocket framing to see when the message has ended.  It
then accepts the server checksum message and compares that to its checksum.</p>

<p>@section taproxy proxy support</p>

<p>The http_proxy environment variable is respected by the client
connection code for both <code>ws://</code> and <code>wss://</code>.  It doesn't support
authentication.</p>

<p>You use it like this
<code>
    $ export http_proxy=myproxy.com:3128
    $ libwebsockets-test-client someserver.com
</code></p>

<p>@section talog debug logging</p>

<p>By default logging of severity "notice", "warn" or "err" is enabled to stderr.</p>

<p>Again by default other logging is compiled in but disabled from printing.</p>

<p>By default debug logs below "notice" in severity are not compiled in.  To get
them included, add this option in CMAKE</p>

<p><code>
    $ cmake .. -DCMAKE_BUILD_TYPE=DEBUG
</code></p>

<p>If you want to see more detailed debug logs, you can control a bitfield to
select which logs types may print using the <code>lws_set_log_level()</code> api, in the
test apps you can use <code>-d &lt;number&gt;</code> to control this.  The types of logging
available are (OR together the numbers to select multiple)</p>

<ul>
<li>1   ERR</li>
<li>2   WARN</li>
<li>4   NOTICE</li>
<li>8   INFO</li>
<li>16  DEBUG</li>
<li>32  PARSER</li>
<li>64  HEADER</li>
<li>128 EXTENSION</li>
<li>256 CLIENT</li>
<li>512 LATENCY</li>
</ul>

<p>@section ws13 Websocket version supported</p>

<p>The final IETF standard is supported for both client and server, protocol
version 13.</p>

<p>@section latency Latency Tracking</p>

<p>Since libwebsockets runs using <code>poll()</code> and a single threaded approach, any
unexpected latency coming from system calls would be bad news.  There's now
a latency tracking scheme that can be built in with <code>-DLWS_WITH_LATENCY=1</code> at
cmake, logging the time taken for system calls to complete and if
the whole action did complete that time or was deferred.</p>

<p>You can see the detailed data by enabling logging level 512 (eg, <code>-d 519</code> on
the test server to see that and the usual logs), however even without that
the "worst" latency is kept and reported to the logs with NOTICE severity
when the context is destroyed.</p>

<p>Some care is needed interpreting them, if the action completed the first figure
(in us) is the time taken for the whole action, which may have retried through
the poll loop many times and will depend on network roundtrip times.  High
figures here don't indicate a problem.  The figure in us reported after "lat"
in the logging is the time taken by this particular attempt.  High figures
here may indicate a problem, or if you system is loaded with another app at
that time, such as the browser, it may simply indicate the OS gave preferential
treatment to the other app during that call.</p>

<p>@section autobahn Autobahn Test Suite</p>

<p>Lws can be tested against the autobahn websocket fuzzer in both client and
server modes</p>

<p>1) pip install autobahntestsuite</p>

<p>2) From your build dir:</p>

<p><code>
 $ cmake .. -DLWS_WITHOUT_EXTENSIONS=0 -DLWS_WITH_MINIMAL_EXAMPLES=1 &amp;&amp; make
</code></p>

<p>3) ../scripts/autobahn-test.sh</p>

<p>4) In a browser go to the directory you ran wstest in (eg, /projects/libwebsockets)</p>

<p>file:///projects/libwebsockets/build/reports/clients/index.html</p>

<p>to see the results</p>

<p>@section autobahnnotes Autobahn Test Notes</p>

<p>1) Two of the tests make no sense for Libwebsockets to support and we fail them.</p>

<ul>
<li>Tests 2.10 + 2.11: sends multiple pings on one connection.  Lws policy is to
only allow one active ping in flight on each connection, the rest are dropped.
The autobahn test itself admits this is not part of the standard, just someone's
random opinion about how they think a ws server should act.  So we will fail
this by design and it is no problem about RFC6455 compliance.</li>
</ul>

<p>2) Currently two parts of autobahn are broken and we skip them</p>

<p>https://github.com/crossbario/autobahn-testsuite/issues/71</p>

<h2>Unix Domain Sockets Reverse Proxy</h2>

<h3>Introduction</h3>

<p>lws is able to use a mount to place reverse proxies into the URL space.</p>

<p>These are particularly useful when using Unix Domain Sockets, basically
files in the server filesystem, to communicate between lws and a separate
server process and integrate the result into a coherent URL namespace on
the lws side.  It's also possible to proxy using tcp sockets.</p>

<p><img src="../doc-assets/http-proxy-overview.svg" alt="overview" title="" /></p>

<p>This has the advantage that the actual web server that forwards the
data from the unix socket owner is in a different process than the server
that serves on the unix socket.  If it has problems, they do not affect
the actual public-facing web server.  The unix domain socket server may
be in a completely different language than the web server.</p>

<p>Compared to CGI, there are no forks to make a connection to the unix
domain socket server.</p>

<h3>Mount origin format</h3>

<p>Unix Domain Sockets are effectively "files" in the server filesystem, and
are defined by their filepath.  The "server" side that is to be proxied opens
the socket and listens on it, which creates a file in the server filesystem.
The socket understands either http or https protocol.</p>

<p>Lws can be told to act as a proxy for that at a mountpoint in the lws vhost
url space.</p>

<p>If your mount is expressed in C code, then the mount type is LWSMPRO<em>HTTP or
LWSMPRO</em>HTTPS depending on the protocol the unix socket understands, and the
origin address has the form <code>+/path/to/unix/socket:/path/inside/mount</code>.</p>

<p>The + at the start indicates it is a local unix socket we are proxying, and
the ':' acts as a delimiter for the socket path, since unlike other addresses
the unix socket path can contain '/' itself.</p>

<h3>Connectivity rules and translations</h3>

<p>Onward proxy connections from lws to the Unix Domain Socket happen using
http/1.1.  That implies <code>transfer-encoding: chunking</code> in the case that the
length of the output is not known beforehand.</p>

<p>Lws takes care of stripping any chunking (which is illegal in h2) and
translating between h1 and h2 header formats if the return connection is
actually in http/2.</p>

<p>The h1 onward proxy connection translates the following headers from the return
connection, which may be h1 or h2:</p>

<p>Header|Function
---|---
host|Which vhost
etag|Information on any etag the client has cached for this URI
if-modified-since|Information on the freshness of any etag the client has cached for this URI
accept-language|Which languages the return path client prefers
accept-encoding|Which compression encodings the client can accept
cache-control|Information from the return path client about cache acceptability
x-forwarded-for|The IP address of the return path client</p>

<p>This implies that the proxied connection can</p>

<ul>
<li><p>return 301 etc to say the return path client's etag is still valid</p></li>
<li><p>choose to compress using an acceptable content-encoding</p></li>
</ul>

<p>The following headers are translated from the headers replied via the onward
connection (always h1) back to the return path (which may be h1 or h2)</p>

<p>Header|Function
---|---
content-length|If present, an assertion of how much payload is expected
content-type|The mimetype of the payload
etag|The canonical etag for the content at this URI
accept-language|This is returned to the return path client because there is no easy way for the return path client to know what it sent originally.  It allows clientside selection of i18n.
content-encoding|Any compression format on the payload (selected from what the client sent in accept-encoding, if anything)
cache-control|The onward server's response about cacheability of its payload</p>

<h3>h1 -> h2 conversion</h3>

<p>Chunked encoding that may have been used on the outgoing proxy client connection
is removed for h2 return connections (chunked encoding is illegal for h2).</p>

<p>Headers are converted to all lower-case and hpack format for h2 return connections.</p>

<p>Header and payload proxying is staged according to when the return connection
(which may be an h2 child stream) is writable.</p>

<h3>Behaviour if unix domain socket server unavailable</h3>

<p>If the server that listens on the unix domain socket is down or being restarted,
lws understands that it couldn't connect to it and returns a clean 503 response
<code>HTTP_STATUS_SERVICE_UNAVAILABLE</code> along with a brief human-readable explanation.</p>

<p>The generated status page produced will try to bring in a stylesheet
<code>/error.css</code>.  This allows you to produce a styled error pages with logos,
graphics etc.  See <a href="https://libwebsockets.org/git/badrepo">this</a> for an example of what you can do with it.</p>

<h2>Vulnerability Reporting</h2>

<p>If you become aware of an issue with lws that has a security
dimension for users, please contact <code>andy@warmcat.com</code> by
direct email.</p>

<h2>Procedure for announcing vulnerability fixes</h2>

<p>The problem and fixed versions will be announced on the
libwebsockets mailing list and a note added to the master
README.md.</p>
